 [
  {
  "title": "Recursion – Fundamentals, When to Use It, Pros and Cons",
  "content": [
    "Recursion is a technique where a function calls itself to solve smaller instances of the same problem.",
    "This post explains what recursion is, how it works, when it is useful, and how it affects time and space complexity."
  ],
  "images": [],
  "description": [
    "## What is recursion?",
    "Recursion is a way of defining a function, algorithm or data structure in terms of **smaller versions of itself**.",
    "",
    "In code, a recursive function is a function that calls itself:",
    "- On a **smaller subproblem** (for example `f(n-1)` instead of `f(n)`),",
    "- Until it reaches a **base case** that can be solved directly without further recursion.",
    "",
    "A typical recursive pattern:",
    "- **Base case:** handles the smallest, simplest input directly (for example `n == 0`).",
    "- **Recursive case:** reduces the problem to one or more smaller subproblems and calls the same function on them.",
    "",
    "Without a correct base case or with a wrong reduction step, recursion can lead to infinite loops or stack overflows.",
    "",
    "## Direct vs indirect recursion",
    "There are two common forms:",
    "",
    "- **Direct recursion:** a function directly calls itself.",
    "  - Example: `factorial(n)` calls `factorial(n - 1)`. ",
    "",
    "- **Indirect recursion:** a function calls another function, which eventually calls the first function again.",
    "  - Example: `even(n)` calls `odd(n-1)` and `odd(n)` calls `even(n-1)`. ",
    "",
    "Most algorithmic problems use **direct recursion**, but complex systems or grammars sometimes use indirect recursion.",
    "",
    "## Typical use cases",
    "Recursion is especially natural when the problem itself has a **recursive structure**:",
    "",
    "- **Tree and graph traversals:**",
    "  - Preorder, inorder, postorder traversal of binary trees.",
    "  - Depth-first search (DFS) on graphs.",
    "",
    "- **Divide-and-conquer algorithms:**",
    "  - Merge sort, quicksort, binary search.",
    "  - Algorithms that split a problem into halves or into subranges.",
    "",
    "- **Backtracking and search:**",
    "  - Solving mazes, Sudoku, N-Queens, subset search.",
    "  - Exploring all combinations or permutations under constraints.",
    "",
    "- **Mathematical recurrences and definitions:**",
    "  - Fibonacci numbers, factorial, Catalan numbers.",
    "  - Many combinatorial counting problems.",
    "",
    "## Advantages of recursion",
    "- **Natural expression of recursive structure:**",
    "  - Tree-like or divide-and-conquer problems often mirror their own definition when written recursively.",
    "",
    "- **Cleaner and shorter code:**",
    "  - Recursive implementations can be much easier to read than equivalent iterative versions, especially for trees and backtracking.",
    "",
    "- **Direct mapping from mathematical recurrence to code:**",
    "  - If you already have a recurrence relation, recursive code often follows it almost line by line.",
    "",
    "- **Good for exploration algorithms:**",
    "  - Backtracking and DFS are often clearer and less error-prone when written recursively.",
    "",
    "## Disadvantages of recursion",
    "- **Call stack overhead:**",
    "  - Each recursive call consumes stack space. Deep recursion can lead to **stack overflow** if the recursion depth is large.",
    "",
    "- **Potentially worse performance than iterative solutions:**",
    "  - Function call overhead and repeated argument passing can be slower than a simple loop.",
    "",
    "- **Harder to reason about for beginners:**",
    "  - Understanding the flow of control and unwinding of recursive calls can be tricky.",
    "",
    "- **Risk of exponential blow-up:**",
    "  - A naive recursive solution (for example naïve Fibonacci) can have **exponential time complexity** if it recomputes the same subproblems many times.",
    "",
    "## Recursion and the call stack",
    "Every recursive call creates a new **stack frame** that stores:",
    "- The function's parameters,",
    "- Local variables,",
    "- The return address (where to continue after the function returns).",
    "",
    "The **recursion depth** (the maximum number of active recursive calls at once) directly affects space usage:",
    "- If the maximum depth is `d`, the call stack typically uses **O(d)** extra space.",
    "- For example:",
    "  - Recursive DFS on a tree of height `h` uses O(h) stack space.",
    "  - Recursive binary search uses O(log n) stack space on an array of size n.",
    "",
    "If `d` becomes too large (for example recursion on a linked list with millions of elements), you can hit a stack overflow and should consider rewriting the algorithm iteratively.",
    "",
    "## Time and space complexity",
    "Recursion itself does not magically change complexity — it is just a different way to **organize the same operations**. The complexity comes from:",
    "",
    "- **How many recursive calls** you make overall.",
    "- **How much work** you do in each call.",
    "",
    "Space complexity:",
    "- **Call stack:** O(depth) extra space.",
    "- Plus any additional data structures the algorithm uses.",
    "",
    "In some cases, you can convert a recursive algorithm to an iterative one that:",
    "- Keeps the same time complexity,",
    "- But reduces stack usage from O(depth) to O(1), or uses an explicit stack that you control.",
    "",
    "## Recursion vs iteration",
    "- **Iteration (loops):**",
    "  - Uses constructs like `for` and `while`.",
    "  - State is kept in variables; no additional call stack frames are created.",
    "",
    "- **Recursion:**",
    "  - Uses function calls to move forward through the problem.",
    "  - State for each step is stored in the call stack.",
    "",
    "In theory, any recursive algorithm can be transformed into an iterative one (using an explicit stack or other data structures). In practice:",
    "- Choose **recursion** when it makes the algorithm much easier to understand (trees, backtracking, divide-and-conquer).",
    "- Choose **iteration** when you need tight control over performance and stack usage, or when the recursion depth would be too large.",
    "",
    "## Summary",
    "Recursion is a powerful way to define algorithms in terms of smaller versions of the same problem. It shines for tree-structured data, divide-and-conquer algorithms and backtracking, often resulting in short and elegant code. However, recursion uses the call stack, which costs extra space and can cause stack overflows at large depths. Understanding how recursion maps to the call stack and to recurrence relations is key to writing correct and efficient recursive algorithms — and to knowing when an iterative approach or dynamic programming might be a better choice."
  ],
  "date": "2025-12-10",
  "pinned": true
}
,

  {
    "title": "Calculating the Nth Fibonacci Number Using Recursion",
    
    "content": [
        "This Python script demonstrates how to calculate the Nth Fibonacci number using a recursive approach."
    ],
    
    "images": [
        "algorithms_pics/recursive_fibonacci.png"
    ],
    
    "description": [
        "### Key Features of the Script:",
        
        "1. **Fibonacci Sequence:**",
        "   - The Fibonacci sequence starts with 0 and 1, and each subsequent number is the sum of the previous two numbers.",
        
        "2. **Recursive Approach:**",
        "   - The function calls itself recursively to compute the Fibonacci number at position `n`.",
        "   - The base cases are defined: `gertNthFib(1) = 0` and `gertNthFib(2) = 1`.",
        "   - For `n > 2`, the function returns `gertNthFib(n-1) + gertNthFib(n-2)`, simulating the Fibonacci sequence.",
        
        "3. **Output:**",
        "   - The function returns the Nth Fibonacci number as specified by the input.",
        
        "### Complexity Analysis:",
        
        "**Time Complexity:**",
        "- Each call to `gertNthFib(n)` results in two additional recursive calls until the base case is reached.",
        "- This results in an **exponential time complexity of O(2^n)**, making it inefficient for large values of `n`.",
        
        "**Space Complexity:**",
        "- The recursive approach uses a call stack proportional to `n`, leading to a space complexity of **O(n)** in the worst case.",
        "- Since no additional data structures are used, only recursive stack memory is required."
    ],
    
    "date": "2025-01-07"
},
  {
    "title": "Finding the Nth Fibonacci Number Using Iteration",
    
    "content": [
        "This Python script calculates the Nth Fibonacci number using an iterative approach to ensure efficiency and simplicity."
    ],
    
    "images": [
        "algorithms_pics/nth_fibonacci.png"
    ],
    
    "description": [
        "### Key Features of the Script:",
        
        "1. **Fibonacci Sequence:**",
        "   - The Fibonacci sequence starts with 0 and 1, and each subsequent number is the sum of the previous two numbers.",
        
        "2. **Iterative Calculation:**",
        "   - Instead of using recursion, the script uses a loop to calculate the sequence iteratively.",
        "   - This approach avoids excessive memory usage or stack overflow issues.",
        
        "3. **Logic Flow:**",
        "   - For the first Fibonacci number (`n = 1`), it returns 0.",
        "   - For the second Fibonacci number (`n = 2`), it returns 1.",
        "   - For `n > 2`, the script calculates the sequence by summing the last two numbers until the Nth number is reached.",
        
        "4. **Output:**",
        "   - The function returns the Nth Fibonacci number as specified by the input.",
        
        "### Complexity Analysis:",
        
        "**Time Complexity:**",
        "- The function iterates through the sequence using a single loop.",
        "- Since the loop runs `n-2` times, the overall time complexity is **O(n)**.",
        
        "**Space Complexity:**",
        "- The function only uses two integer variables (`prev` and `curr`).",
        "- Since no additional lists or recursive calls are used, the space complexity is **O(1)**."
    ],
    
    "date": "2025-01-08"
}
,
{
    "title": "Calculating Product Sums of Nested Arrays in Python",
    
    "content": [
        "This Python script computes the product sum of a nested array. The product sum is calculated by summing all elements of the array, with elements inside nested arrays being multiplied by their depth."
    ],
    
    "images": [
        "algorithms_pics/product_sum.png"
    ],
    
    "description": [
        "### Key Features of the Product Sum Script:",
        
        "1. **Recursive Approach:**",
        "   - The function `productSum()` uses recursion to handle nested arrays. When an element is a list, the function calls itself with an incremented depth.",
        
        "2. **Depth Multiplier:**",
        "   - For every level of nesting, the sum of elements is multiplied by the current depth. This adds weight to elements that are deeper in the array structure.",
        
        "3. **Handling Mixed Structures:**",
        "   - The function can handle arrays with a mix of integers and nested arrays, processing them seamlessly.",
        
        "### How It Works:",
        
        "1. The script initializes the `result` to 0 and iterates over the elements of the input array.",
        "2. If an element is a list, the function recursively calculates its product sum with an incremented depth.",
        "3. If an element is an integer, it is added directly to the `result`.",
        "4. After iterating through the array, the cumulative sum is multiplied by the current depth and returned.",
        
        "### Complexity Analysis:",
        
        "**Time Complexity:**",
        "- The function processes every element (integers + nested lists) exactly once.",
        "- Since every element contributes to the total sum, the time complexity is **O(E)**, where `E` is the total number of elements, including both integers and nested lists.",
        
        "**Space Complexity:**",
        "- The recursive calls require a stack proportional to the depth `d` of the nested list.",
        "- In the worst case, where the nesting depth is maximum (e.g., a deeply nested list), the space complexity is **O(d)**."
    ],
    
    "date": "2025-01-09"
},
  {
"title": "Generating All Permutations (Recursive Build with Slicing)",
"content": [
"This Python routine produces every permutation of an input array using a clean recursive strategy that builds the current permutation while shrinking the remaining pool of elements."
],
"images": ["algorithms_pics/permutations_recursive.png"],
"description": [
"### Problem Statement:",
"- Given an array of distinct (or even non-distinct) values, generate **all permutations**.",
"- Return them as a list of lists, where each inner list is one ordering of the original elements.",
"",
"---",
"### How the Algorithm Works:",
"1. **Driver:** `getPermutations(array)` initializes a result list and calls `permutationsHelper(array, [], permutations)`.",
"",
"2. **State Representation:**",
"   - `array`: the pool of elements **not yet used**.",
"   - `currentPermutation`: the **partial permutation** being built.",
"   - `permutations`: the **output collector**.",
"",
"3. **Base Case:**",
"   - `if not len(array) and len(currentPermutation):`",
"   - When there’s nothing left to choose (`array` empty), the current build is a **complete permutation** → append it.",
"",
"4. **Recursive Step:**",
"   - Iterate `i` through the remaining elements.",
"   - Choose `array[i]`, form:",
"     - `newArray = array[:i] + array[i + 1:]` (all remaining except the chosen one),",
"     - `newPermutation = currentPermutation + [array[i]]` (extend the path).",
"   - Recurse on `(newArray, newPermutation)`; this explores the subtree where `array[i]` occupies the **next position**.",
"",
"---",
"### Why It Enumerates Everything Exactly Once:",
"- Each level fixes one more position in the permutation.",
"- Slicing removes the chosen item, so deeper calls **cannot reuse** it.",
"- The tree has branching factor equal to the remaining items count: `n, n-1, ..., 1` → exactly `n!` leaves.",
"",
"---",
"### Complexity:",
"- **Output size:** There are `n!` permutations; any correct algorithm must output them all.",
"- **Time (rough):** `O(n · n!)` to visit leaves and build each permutation of length `n`.",
"- **Time (with slicing overhead):** Due to `array[:i] + array[i+1:]` creating a fresh list at each step, the **upper bound** is `O(n^2 · n!)`.",
"- **Space:** `O(n · n!)` for storing results; auxiliary recursion depth is `O(n)` plus temporary lists from slicing."
],
"date": "2025-11-10"
},
  {
"title": "In-Place Permutations via Backtracking (Swap-Based DFS)",
"content": [
"This Python implementation generates all permutations of an array **in place** by fixing positions left-to-right and exploring choices via swaps, then undoing each swap (backtracking)."
],
"images": ["algorithms_pics/permutations_inplace.png"],
"description": [
"### What the Code Does",
"- `getPermutations(array)` returns a list of all permutations.",
"- `permutationsHelper(i, array, permutations)` fixes the element at index `i` and recursively permutes the suffix.",
"- `swap(array, i, j)` exchanges two positions so we can try a choice without extra arrays."
,
"---",
"### How It Works (Backtracking)",
"1. **Fix prefix:** At depth `i`, the first `i` elements are already chosen.",
"2. **Enumerate choices:** For `j` from `i` to `len(array)-1`, swap `array[i]` with `array[j]`. Now the element at `i` is the next choice.",
"3. **Recurse:** Call `permutationsHelper(i+1, ...)` to permute the remaining suffix.",
"4. **Backtrack:** Swap back (`swap(array, i, j)`) to restore the array before trying the next `j`.",
"5. **Leaf:** When `i == len(array)-1`, we’ve fixed all positions; append a copy `array[:]` to results."
,
"---",
"### Tiny Walkthrough (array = [1,2,3])",
"- At `i=0`, try `j=0` (no-op), recurse to `i=1`: produce `[1,2,3]`, `[1,3,2]`.",
"- Backtrack to `i=0`, try `j=1` (swap → `[2,1,3]`), recurse: produce `[2,1,3]`, `[2,3,1]`.",
"- Backtrack to `i=0`, try `j=2` (swap → `[3,2,1]`), recurse: produce `[3,2,1]`, `[3,1,2]`.",
"- All `3!` permutations are explored systematically."
,
"---",
"### Why It’s Correct",
"- **Completeness:** For each position `i`, the loop tries **every** remaining element at that position; recursion covers all suffix orders.",
"- **No duplicates from position reuse:** Swapping fixes one element per depth; backtracking restores state so future choices start from the same clean prefix.",
"- **State restoration:** The second swap undoes the first, keeping the array valid for the next branch."
,
"---",
"### Complexity",
"- **Time:** `O(n · n!)` — there are `n!` leaves and copying each permutation costs `O(n)`.",
"- **Space:** `O(n)` auxiliary for recursion depth (the array is reused in place). Result storage is `O(n · n!)` by definition."
,
"---",
"### Practical Notes",
"- Works with any comparable elements.",
"- This swap-based approach avoids allocating new subarrays at each step, making it faster and more memory-friendly than slice-and-build methods."
],
"date": "2025-11-11"
},
{
  "title": "Generating a Power Set (Iterative Build-Up vs. Recursion with Index)",
  "content": [
    "This post explains two classic approaches to generate the power set (all subsets) of an array: an iterative expansion method and a recursive variant that avoids slicing by using an index.",
    "Both algorithms generate exactly 2^n subsets and are foundational for combination and backtracking problems."
  ],
  "images": [
    "algorithms_pics/powerset.png"
  ],
  "description": [
    "## Problem Statement",
    "Given an array of values, generate its **power set** — meaning **all possible subsets**, including the empty subset `[]` and the full set.",
    "",
    "**Example:**",
    "- Input: `[1, 2]`",
    "- Output: `[[], [1], [2], [1, 2]]` (order may vary)",
    "",
    "---",
    "## Key Idea Behind Every Power Set Algorithm",
    "For each element in the array, every subset has exactly two options:",
    "1. The subset **does not** contain the element",
    "2. The subset **does** contain the element",
    "",
    "This binary decision repeated for `n` elements creates `2^n` subsets.",
    "",
    "---",
    "## 1) Iterative Power Set (Growing the List of Subsets)",
    "The iterative method starts with one subset: the empty subset `[]`.",
    "Then, for each element `ele`, it duplicates the current subset collection by appending `ele` to every existing subset.",
    "",
    "**Mental model:**",
    "- Before processing an element, you have some list of subsets.",
    "- After processing it, you have all old subsets **plus** all old subsets with the new element added.",
    "",
    "**Mini walkthrough for `[1, 2, 3]`:**",
    "- Start: `[[]]`",
    "- Add `1` → `[[], [1]]`",
    "- Add `2` → `[[], [1], [2], [1,2]]`",
    "- Add `3` → `[[], [1], [2], [1,2], [3], [1,3], [2,3], [1,2,3]]`",
    "",
    "---",
    "## 2) Recursive Power Set (No Slicing, Just an Index)",
    "The recursive version uses an index (`idx`) that moves from the end of the array toward the start.",
    "Instead of creating subarrays (like `array[:idx]`), it keeps the original array untouched and only changes which index is currently being processed.",
    "",
    "### Why avoiding slicing matters",
    "In Python, slicing like `array[:idx]` creates a new list — that’s an extra **O(n)** operation per call.",
    "Using an index avoids that overhead and keeps the recursion focused on subset construction.",
    "",
    "### Base case intuition",
    "When the recursion moves past the first element (i.e. `idx < 0`), there is only one valid subset left:",
    "- the empty subset: `[[]]`",
    "",
    "Returning `[[]]` (not `[]`) is crucial, because it gives the algorithm a starting point that can be extended step by step.",
    "",
    "### Recursive build idea",
    "At each recursive step for `ele = array[idx]`:",
    "1. Get all subsets created so far (from the smaller problem `idx - 1`)",
    "2. Duplicate them by creating the versions **with** `ele` appended",
    "",
    "This exactly matches the power set rule:",
    "- Every subset either includes the current element or it doesn't.",
    "",
    "---",
    "## Complexity Analysis (The Real Cost Comes From the Output Size)",
    "Let `n = len(array)`.",
    "",
    "### Number of subsets",
    "- There are exactly `2^n` subsets.",
    "",
    "### Total number of elements across all subsets",
    "A useful fact for power sets:",
    "- Each of the `n` elements appears in **half** of all subsets.",
    "- So total element count stored across all subsets is:",
    "  - `n * 2^(n-1)`",
    "",
    "This means the *average* subset length is `n/2`.",
    "Even though the average is `n/2`, it still scales linearly with `n`, so it converges to `Θ(n)` in growth terms.",
    "",
    "### Time Complexity: `O(n · 2^n)`",
    "Even if you ignore loop overhead, you must *materialize* all subsets.",
    "Since the total output contains `Θ(n · 2^n)` elements across all subset lists, generating them is inherently `O(n · 2^n)`.",
    "",
    "### Space Complexity: `O(n · 2^n)`",
    "The output itself dominates space usage:",
    "- storing all subsets costs `Θ(n · 2^n)`",
    "",
    "**Additional recursion stack (recursive version only):** `O(n)`",
    "- recursion depth is proportional to `n`",
    "",
    "---",
    "## Iteration vs Recursion — Which Should You Prefer?",
    "✅ **Iterative version** is often the simplest:",
    "- No recursion depth issues",
    "- Straightforward expansion logic",
    "",
    "✅ **Recursive version** is great for building recursion intuition:",
    "- Mirrors the “include vs exclude” decision pattern",
    "- Avoids slicing by using an index, keeping the recursion efficient",
    "",
    "---",
    "## Common Pitfalls",
    "- **Forgetting the empty subset:** the power set must include `[]`.",
    "- **Iterating over a changing list:** the algorithm must loop only over the subset count *at the start of the step*, not after appending new subsets.",
    "- **Wrong recursion base case:** returning `[]` instead of `[[]]` breaks the construction.",
    "",
    "---",
    "## Summary",
    "Both approaches generate the power set by repeatedly duplicating subsets:",
    "- **Iterative:** expand subset list element by element",
    "- **Recursive (index-based):** expand subsets via recursion without slicing",
    "",
    "Their runtime and memory usage are dominated by the unavoidable output size: `Θ(n · 2^n)`."
  ],
  "date": "2026-01-25"
},
  {
  "title": "Phone Number Mnemonics (Backtracking with Digit-to-Letter Mapping)",
  "content": [
    "This post covers a classic backtracking problem: generating every possible letter mnemonic for a phone number using the old mobile keypad mapping.",
    "The solution uses recursion with an index and builds the current mnemonic in-place to avoid unnecessary string copying."
  ],
  "images": [
    "algorithms_pics/phone_number_mnemonics.png"
  ],
  "description": [
    "## Problem Statement",
    "You are given a phone number as a string, for example `\"1905\"`.",
    "Each digit maps to a set of possible letters (similar to the old T9 keypad).",
    "Your task is to generate **all possible mnemonics** (strings of the same length).",
    "",
    "**Example idea:**",
    "- Input: `\"23\"`",
    "- Output (partial): `[\"ad\", \"ae\", \"af\", \"bd\", ... , \"cf\"]`",
    "",
    "---",
    "## Digit → Letters Mapping",
    "The core of the problem is a dictionary that maps each digit to its corresponding letters.",
    "A key detail is that `0` and `1` map to themselves, since they don’t represent letters on a keypad.",
    "",
    "This mapping determines the branching factor of the recursion:",
    "- mostly **3** letters (`2, 3, 4, 5, 6, 8`)",
    "- sometimes **4** letters (`7, 9`)",
    "- and only **1** option for `0` and `1`",
    "",
    "---",
    "## High-Level Idea",
    "We traverse the phone number from left to right using an index `idx`.",
    "At each position, we try every possible letter for the current digit, place it into a working array, and recurse to the next index.",
    "",
    "**State tracked by the recursion:**",
    "- `idx`: the current position in the phone number",
    "- `currentMnemonic`: a list of length `n` that is filled in-place",
    "- `mnemonicsFound`: an output list collecting all completed results",
    "",
    "---",
    "## Base Case",
    "When `idx == len(phoneNumber)`, we have built a complete mnemonic.",
    "At that point we convert the working list into a string using `\"\".join(currentMnemonic)` and store it.",
    "",
    "### Why `join()` only at the end?",
    "`join()` takes **O(n)** time, so we want to do it **only once per finished mnemonic**.",
    "During recursion, each step only updates a single position in `currentMnemonic`, which is **O(1)**.",
    "",
    "---",
    "## Recursive Step (Backtracking)",
    "For the recursive step:",
    "1. Read the current digit: `digit = phoneNumber[idx]`",
    "2. Get its possible letters: `letters = DIGIT_LETTERS[digit]`",
    "3. For each letter in `letters`:",
    "   - set `currentMnemonic[idx] = letter`",
    "   - recurse into `idx + 1`",
    "",
    "This is classic backtracking behavior:",
    "- pick a choice",
    "- explore deeper",
    "- return",
    "- try the next choice",
    "",
    "Because we reuse the same list, we can simply overwrite `currentMnemonic[idx]` for each branch.",
    "",
    "---",
    "## Why `currentMnemonic` Is a List (Not a String)",
    "Python strings are immutable.",
    "If you build mnemonics by concatenating strings at each recursion step, you create many intermediate copies.",
    "",
    "Using a list gives two big advantages:",
    "- **O(1)** updates per recursion step (`currentMnemonic[idx] = ...`)",
    "- only **one** string construction per final result (`join` at the leaf)",
    "",
    "---",
    "## Complexity Analysis",
    "Let `n = len(phoneNumber)`.",
    "",
    "### Number of results",
    "The number of generated mnemonics depends on the digits.",
    "In the worst case, every digit is `7` or `9` (4 choices each):",
    "- **Total mnemonics:** `4^n`",
    "",
    "If most digits have 3 letters, the count is closer to `3^n`.",
    "",
    "### Time Complexity",
    "For each completed mnemonic we run a `join()`, which costs `O(n)`.",
    "So in the worst case:",
    "- **Time:** `O(n · 4^n)`",
    "",
    "### Space Complexity",
    "The output dominates memory usage because all mnemonics must be stored:",
    "- **Output space:** `O(n · 4^n)`",
    "",
    "Additional overhead:",
    "- **Recursion stack:** `O(n)`",
    "- **Working array (`currentMnemonic`):** `O(n)`",
    "",
    "---",
    "## Common Pitfalls",
    "- Forgetting to include mappings for `0` and `1` (causes missing keys or wrong output length).",
    "- Incorrect base case (for example using `idx > len(...)` instead of `==`).",
    "- Building strings on every recursion step (unnecessary copying and slower runtime).",
    "",
    "---",
    "## Summary",
    "Phone number mnemonics are a clean demonstration of recursion + backtracking:",
    "- `idx` moves forward one digit at a time",
    "- each digit fans out into multiple letter choices",
    "- finished mnemonics are stored only at the leaves",
    "",
    "By building the mnemonic in-place using a list, the algorithm stays efficient even though the number of combinations grows exponentially."
  ],
  "date": "2026-01-26"
},
  {
  "title": "Staircase Traversal: From Exponential Recursion to O(n) Dynamic Programming",
  "content": [
    "Staircase Traversal is a great problem for learning how the same recurrence can be implemented in multiple ways: naive recursion, recursion with memoization, bottom-up tabulation, and an optimized sliding-window DP.",
    "This post walks through the core recurrence and explains why each improvement speeds things up—without repeating the code (see the two images for the full implementations)."
  ],
  "images": [
    "algorithms_pics/staircase_traversal_recursion_and_memoization.png",
    "algorithms_pics/staircase_traversal_tabulation_and_sliding_window.png"
  ],
  "description": [
    "## Problem Statement",
    "You are climbing a staircase of `height` steps. You can climb at most `maxSteps` steps at a time.",
    "How many distinct ways are there to reach the top?",
    "",
    "A “way” is an ordered sequence of jumps (so `[1,2]` and `[2,1]` are different).",
    "",
    "---",
    "## The Core Recurrence",
    "Let `ways(h)` be the number of ways to reach step `h`.",
    "To arrive at `h`, your last jump could have been `1, 2, ..., maxSteps` (but never more than `h`).",
    "",
    "So the recurrence is:",
    "- `ways(h) = sum(ways(h - step))` for `step = 1..min(maxSteps, h)`",
    "",
    "Base cases commonly used in these solutions:",
    "- `ways(0) = 1` (one way to be at the start: do nothing)",
    "- `ways(1) = 1`",
    "",
    "---",
    "## Algorithm 1: Naive Recursion (Image 1)",
    "The naive recursive approach directly implements the recurrence by branching on every possible step size at each height.",
    "",
    "### Why it’s slow",
    "The same subproblems are recomputed many times (e.g. `ways(10)` gets recalculated in multiple branches).",
    "This creates an exponential blow-up.",
    "",
    "### Complexity",
    "- **Time:** exponential (roughly `O(k^n)` in the worst case, where `n = height`, `k = maxSteps`)",
    "- **Space:** `O(n)` recursion depth",
    "",
    "---",
    "## Algorithm 2: Recursion + Memoization (Image 1)",
    "Memoization fixes the core issue: repeated work.",
    "Whenever `ways(h)` is computed once, it is stored in a dictionary and reused the next time it’s needed.",
    "",
    "### What improves",
    "Each height `h` is computed at most once, and computing it requires summing up to `maxSteps` previous results.",
    "",
    "### Complexity",
    "- **Time:** `O(n · k)`",
    "- **Space:** `O(n)` for the memo table + `O(n)` recursion stack",
    "",
    "---",
    "## Algorithm 3: Bottom-Up Tabulation (Image 2)",
    "Tabulation is the iterative version of the memoized idea: build `waysToTop` from `0` up to `height`.",
    "For each `currentHeight`, you sum contributions from the previous `step` positions.",
    "",
    "### Why it’s useful",
    "- No recursion stack",
    "- Predictable iteration order",
    "- Often simpler to optimize further",
    "",
    "### Complexity",
    "- **Time:** `O(n · k)`",
    "- **Space:** `O(n)` for the table",
    "",
    "---",
    "## Algorithm 4: Sliding Window Optimization (Image 2)",
    "Notice that the recurrence only needs the last `k` values:",
    "- `ways(h) = ways(h-1) + ways(h-2) + ... + ways(h-k)`",
    "",
    "Instead of recomputing that sum from scratch each time, you maintain a running sum of the last `k` entries (a “window”).",
    "",
    "### How the window works",
    "When moving from height `h` to `h+1`:",
    "- add the newest value entering the window",
    "- subtract the oldest value leaving the window",
    "",
    "This turns the inner loop into O(1) maintenance per height.",
    "",
    "### Complexity",
    "- **Time:** `O(n)`",
    "- **Space:** `O(n)` in the shown implementation (it stores all `waysToTop` values)",
    "  - Note: with a queue/circular buffer you can reduce auxiliary storage to `O(k)` if you only need the final answer.",
    "",
    "---",
    "## When to Use Which Version",
    "- **Naive recursion:** mainly for learning the recurrence (too slow for large inputs).",
    "- **Memoization:** great when you want to keep the recursive structure but avoid recomputation.",
    "- **Tabulation:** clean iterative DP, usually preferred in production/interviews.",
    "- **Sliding window:** the most efficient when `maxSteps` is large and you want `O(n)` time.",
    "",
    "---",
    "## Summary",
    "All four solutions compute the same recurrence—what changes is how much repeated work they do:",
    "- exponential recursion → repeated subproblems everywhere",
    "- memoization/tabulation → each subproblem once (`O(n · k)`)",
    "- sliding window → reuse the rolling sum to get `O(n)` time"
  ],
  "date": "2026-01-28"
},
  {
  "title": "Blackjack Bust Probability with Recursion + Memoization",
  "content": [
    "This post explains a recursive, memoized solution that computes the probability of busting in a simplified Blackjack model.",
    "The key idea is to treat each possible current hand total as a state, compute its bust probability once, and reuse it via memoization."
  ],
  "images": [
    "algorithms_pics/blackjack_probability.png"
  ],
  "description": [
    "## Problem Setup (Simplified Blackjack)",
    "We want the probability that a player eventually **busts** (goes over a target total) if they keep drawing cards.",
    "The function takes:",
    "- `target`: the maximum allowed total (e.g. 21)",
    "- `startingHand`: the current total you already have",
    "",
    "Assumptions used in this implementation:",
    "- Each draw is uniformly random from values `1..10` (probability `0.1` each).",
    "- The player draws again unless they are close enough to the target that they would stop (explained below).",
    "",
    "---",
    "## The State: `currentHand`",
    "The helper function computes:",
    "- `calculateProbability(currentHand, target, memo)` → probability of eventually busting starting from `currentHand`.",
    "",
    "This works because the future outcome depends only on the current total, not on how you reached it.",
    "",
    "---",
    "## Base Cases",
    "There are two terminal conditions:",
    "",
    "### 1) Bust",
    "If `currentHand > target`, the player already busted:",
    "- probability is `1`.",
    "",
    "### 2) Stand Zone",
    "If `currentHand + 4 >= target`, the function returns `0`.",
    "This encodes the strategy used in this variant: **stand when you are within 4 points of the target**.",
    "So from that state, you stop drawing and cannot bust.",
    "",
    "---",
    "## The Recurrence",
    "If neither base case applies, you draw one more card.",
    "There are 10 equally likely outcomes (`1..10`), so the bust probability is the average over all next states:",
    "",
    "- `P(h) = 0.1 * sum(P(h + c))` for `c = 1..10`",
    "",
    "In code, this is implemented by looping over `drawnCard` and accumulating `0.1 * P(nextState)`.",
    "",
    "---",
    "## Why Memoization Matters",
    "Without caching, the recursion would recompute the same totals many times.",
    "Memoization ensures each hand total is solved once, then reused.",
    "",
    "---",
    "## Complexity Analysis",
    "Let `T = target` and `S = startingHand`.",
    "",
    "### Number of distinct states",
    "The function only needs to compute probabilities for totals from `S` up to the point where it stops recursing.",
    "Since recursion ends once `currentHand + 4 >= T`, the last non-terminal total is about `T - 5`.",
    "So the number of computed states is:",
    "- `O((T - 4) - S)` → **`O(T - S)`**",
    "",
    "### Time Complexity: `O(T - S)`",
    "Each computed state performs a constant loop over 10 possible draws:",
    "- `O(10)` work per state",
    "- `O(T - S)` states",
    "",
    "So overall:",
    "- **Time:** `O(T - S)`",
    "",
    "### Space Complexity: `O(T - S)`",
    "The memo table stores one value per computed total:",
    "- **Memo space:** `O(T - S)`",
    "",
    "The recursion stack depth is also bounded by how many times you can add at least `1` before reaching the stand/bust region:",
    "- **Stack space:** `O(T - S)`",
    "",
    "So:",
    "- **Space:** `O(T - S)`",
    "",
    "In the worst case (small `S`), both simplify to **`O(T)`**.",
    "",
    "---",
    "## Summary",
    "This solution is dynamic programming expressed recursively:",
    "- define the bust probability from a total",
    "- stop immediately if you bust or if you would stand",
    "- average over all equally likely next draws",
    "- cache results to avoid exponential recomputation",
    "",
    "With memoization, the algorithm runs in **`O(target - startingHand)`** time and space."
  ],
  "date": "2026-01-30"
},
  {
  "title": "Minesweeper Reveal (DFS Flood Fill with Neighbor Counting)",
  "content": [
    "This post explains a common Minesweeper operation: revealing a cell and recursively expanding into neighboring cells when there are no adjacent mines.",
    "The implementation uses depth-first search (DFS) style recursion (a flood fill) and a helper that enumerates all valid neighboring coordinates."
  ],
  "images": [
    "algorithms_pics/reveal_minesweeper.png"
  ],
  "description": [
    "## Problem Statement",
    "You are given a Minesweeper board and a position `(row, column)` to reveal.",
    "Cells are represented with characters:",
    "- `\"M\"` = mine (hidden)",
    "- `\"H\"` = hidden, safe cell",
    "- `\"X\"` = revealed mine (game over state)",
    "- `\"0\"` = revealed safe cell with **0** adjacent mines",
    "- `\"1\"..\"8\"` = revealed safe cell with that many adjacent mines",
    "",
    "When you reveal a cell:",
    "1. If it’s a mine, it becomes `\"X\"` and you stop.",
    "2. Otherwise, you count how many adjacent mines it has (including diagonals).",
    "3. If the count is > 0, you write that number and stop.",
    "4. If the count is 0, you write `\"0\"` and recursively reveal all neighboring hidden safe cells.",
    "",
    "---",
    "## High-Level Approach",
    "This solution is essentially a **flood fill** (like paint-bucket in image editors), implemented with DFS recursion:",
    "- reveal the current cell",
    "- if it is a zero-cell, expand to its neighbors",
    "",
    "The key detail is that the function updates the board **in-place**, turning visited hidden cells (`\"H\"`) into revealed cells (`\"0\"` or a number).",
    "That prevents revisiting the same cell repeatedly.",
    "",
    "---",
    "## Step 1: Mine Hit Case",
    "The first check is straightforward:",
    "- if the clicked cell is `\"M\"`, mark it as `\"X\"` and return immediately.",
    "",
    "This matches Minesweeper behavior: clicking a mine ends the game.",
    "",
    "---",
    "## Step 2: Enumerate Neighbors",
    "Minesweeper adjacency includes 8 directions:",
    "- up, down, left, right",
    "- plus the 4 diagonals",
    "",
    "The helper `getNeighbors(...)` uses a `directions` list and filters out-of-bounds coordinates.",
    "This keeps the main algorithm clean and avoids repeated boundary checks scattered across the code.",
    "",
    "---",
    "## Step 3: Count Adjacent Mines",
    "Once neighbors are known, the algorithm counts how many are mines (`\"M\"`).",
    "This count determines what to reveal:",
    "- count > 0 → reveal the number and stop",
    "- count == 0 → reveal `\"0\"` and expand outward",
    "",
    "This is the heart of Minesweeper: numbers act as borders that stop the flood fill.",
    "",
    "---",
    "## Step 4: Flood Fill Expansion (DFS)",
    "If a cell has **zero** adjacent mines, it behaves like an empty region.",
    "The algorithm:",
    "- writes `\"0\"` into the current cell",
    "- recursively reveals every neighbor that is still hidden (`\"H\"`)",
    "",
    "Why only recurse into `\"H\"` cells?",
    "- because revealed cells are already processed",
    "- and this prevents infinite recursion loops",
    "",
    "---",
    "## Correctness Intuition",
    "This approach is correct because:",
    "- every revealed cell is updated from `\"H\"` to a final value (`\"0\"` or a number)",
    "- a cell is only expanded if its adjacent mine count is 0",
    "- and the recursion explores the entire connected zero-region plus its bordering number cells",
    "",
    "---",
    "## Complexity Analysis",
    "Let the board have width `w` and height `h` (so `w * h` total cells).",
    "",
    "### Time Complexity: `O(w · h)`",
    "In the worst case (no mines), revealing one cell triggers a flood fill that visits every cell once.",
    "For each visited cell, we check up to 8 neighbors (constant factor), so overall runtime is linear in the number of cells:",
    "- **Time:** `O(w · h)`",
    "",
    "### Space Complexity: `O(w · h)`",
    "The algorithm uses recursion, so the call stack can grow with the size of the revealed region.",
    "In the worst case, that region can include the whole board:",
    "- **Space (stack):** `O(w · h)`",
    "",
    "---",
    "## Practical Notes",
    "- On very large boards, recursion depth can become an issue in Python (recursion limit).",
    "  - A common alternative is an explicit stack or queue (iterative DFS/BFS).",
    "- Returning the board is mostly for convenience; the board is modified in-place either way.",
    "",
    "---",
    "## Summary",
    "This Minesweeper reveal function combines two simple ideas:",
    "- count adjacent mines (local information)",
    "- if the count is zero, expand recursively (global region reveal)",
    "",
    "It’s a clean example of DFS flood fill on a grid with constant-degree neighbor expansion."
  ],
  "date": "2026-01-31"
}








]
