[
{
  "title": "Turning an Old PC into a Go + PostgreSQL Cloud Lab",
  "content": [
    "This project is my first real step into the world of backend development, cloud-like setups, and databases using Go. I took an old i3 PC with 4GB RAM, installed Ubuntu Server on it, and turned it into a small home lab that exposes a JSON API built with Go and backed by a PostgreSQL database.",
    "The main goal was not just to get something working, but to really understand what each piece does: Linux as a server, PostgreSQL as a database server, Go as the HTTP backend, and how they all talk to each other over TCP, HTTP, and SQL."
  ],
  "images": [],
  "description": [
    "### Goal & Overview",
    "- **Goal:** Turn an old PC into a small backend \"cloud lab\" with Go and PostgreSQL, and use it to learn how HTTP servers, databases, and contexts work together.",
    "- **Tech stack:**",
    "  - Ubuntu LTS on a repurposed i3 desktop as a headless server",
    "  - PostgreSQL as the database server",
    "  - Go (`net/http` + `database/sql` + `pgx` driver) as the HTTP API backend",
    "",
    "---",
    "### 1. Hardware & Linux Setup",
    {
      "type": "image",
      "src": "go_pics/server-ssh-setup.png",
      "alt": "SSH connection to the Ubuntu Go server"
    },
    "- I reused an old i3 PC with ~4GB RAM and installed **Ubuntu Server LTS** instead of a desktop environment.",
    "- The idea: keep it headless and manage everything over **SSH** from my main machine.",
    "- Steps:",
    "  - Create a bootable USB stick with the Ubuntu LTS ISO.",
    "  - Install Ubuntu with no GUI, only OpenSSH server enabled.",
    "  - Give the server a static IP or make sure I can consistently reach it via `ssh user@server-ip`.",
    "- Result: I can now power on the \"server PC\", and from my main computer connect only via SSH – no screen, no keyboard needed on the server itself.",
    "",
    "---",
    "### 2. PostgreSQL as the Database Server",
    {
      "type": "image",
      "src": "go_pics/psql-todos-table.png",
      "alt": "psql view of the todos table in the cloudlab database"
    },
    "- On the Ubuntu server, I installed PostgreSQL and created:",
    "  - a **user** (role) for my Go app,",
    "  - a **database** called `cloudlab`,",
    "  - and a **table** called `todos`.",
    "- The `todos` table has four columns:",
    "  - `id` (integer primary key),",
    "  - `title` (text),",
    "  - `done` (boolean, default `false`),",
    "  - `created_at` (timestamp with timezone, default `NOW()`).",
    "- I tested everything directly in `psql` by inserting a couple of rows and running `SELECT * FROM todos;` to see the result.",
    "",
    "---",
    "### 3. Go Project Structure & Database Connection",
    {
      "type": "image",
      "src": "go_pics/go-code-part1.png",
      "alt": "First part of the Go code: imports, Todo struct, main and database setup"
    },
    {
      "type": "image",
      "src": "go_pics/go-code-part2.png",
      "alt": "Second part of the Go code: getTodosHandler with context, query, loop and JSON response"
    },
    "- On the Go side, I created a small project with a single `main.go` file.",
    "- At the top there is the usual `package main` and an import block that pulls in:",
    "  - `net/http` for the web server,",
    "  - `database/sql` for database access,",
    "  - `encoding/json` to send JSON responses,",
    "  - `context` and `time` for timeouts,",
    "  - and the `pgx` driver via `_ \"github.com/jackc/pgx/v5/stdlib\"`.",
    "- I defined a `Todo` struct that mirrors the database columns (`id`, `title`, `done`, `created_at`) and added JSON tags so that the JSON field names match what I want to expose in the API.",
    "- The database handle is a global `var db *sql.DB`, which in Go represents a connection **pool** that `database/sql` manages for me (not just a single connection).",
    "",
    "---",
    "### 4. DSN, `sql.Open` and `db.Ping()`",
    "- To connect Go to PostgreSQL, I use a DSN (data source name) URL that looks like:",
    "  - `postgres://user:password@host:5432/cloudlab?sslmode=disable`",
    "- In `main()` I call `sql.Open(\"pgx\", dsn)` to initialize the DB handle using the `pgx` driver.",
    "- I immediately follow that with `db.Ping()` to actively check that the connection really works (credentials, host, port, database name).",
    "- If either step fails, the program logs the error and exits, so I know early that something is wrong with the setup.",
    "",
    "---",
    "### 5. HTTP Server, Routing and Handlers",
    "- For the HTTP side I use the standard library's `net/http` package.",
    "- In `main()` I register the `/todos` route using `http.HandleFunc(\"/todos\", getTodosHandler)`. This tells Go:",
    "  - \"Whenever a request comes in on `/todos`, call `getTodosHandler` and pass it a `ResponseWriter` plus the `*Request`.\"",
    "- Finally, `http.ListenAndServe(\":8080\", nil)` starts the HTTP server on port 8080 and blocks:",
    "  - It listens for incoming TCP connections,",
    "  - parses HTTP requests,",
    "  - and forwards them to the correct handler based on the path.",
    "",
    "---",
    "### 6. Request Handling, Context and Database Query",
    "- The core of the API is the `getTodosHandler` function (shown in the second Go screenshot above). The rough flow is:",
    "  1. Create a context with a timeout using `context.WithTimeout(r.Context(), 5*time.Second)`. That way, the database query will be cancelled if it takes too long or the client disconnects.",
    "  2. Call `db.QueryContext(ctx, \"SELECT id, title, done, created_at FROM todos ORDER BY id\")` to fetch all todos from the database using that context.",
    "  3. Loop over the returned rows with `rows.Next()` and use `rows.Scan(&t.ID, &t.Title, &t.Done, &t.CreatedAt)` to fill a `Todo` struct for each row.",
    "  4. Append each `Todo` to a slice until there are no more rows and also check `rows.Err()` for any errors that happened during iteration.",
    "  5. Set the response header `Content-Type` to `application/json`.",
    "  6. Use `json.NewEncoder(w).Encode(todos)` to encode the slice of todos as JSON and stream it directly into the HTTP response body.",
    "- The handler does its own error handling at each step and returns appropriate HTTP status codes if something goes wrong (e.g. `500 Internal Server Error` for DB or JSON issues).",
    "",
    "---",
    "### 7. JSON API Endpoint in the Browser",
    {
      "type": "image",
      "src": "go_pics/todos-endpoint-browser.png",
      "alt": "Browser showing the JSON response from the /todos endpoint"
    },
    "- With the Go server running, a simple GET request to `/todos` returns a JSON array of todo objects.",
    "- The screenshot above shows the JSON response in the browser: each object has `id`, `title`, `done` and `created_at` fields coming directly from the database via the Go handler.",
    "- This output can be consumed by anything: a frontend app, `curl`, Postman, or even another service.",
    "",
    "---",
    "### 8. Learning Takeaways",
    "- From this small project I learned:",
    "  - How to turn an old PC into a headless Ubuntu server and manage it via SSH.",
    "  - The difference between PostgreSQL as a **database server**, a **database** (e.g. `cloudlab`) and a **table** (e.g. `todos`).",
    "  - How Go's `database/sql` package uses a driver (`pgx`) and a DSN to connect to PostgreSQL.",
    "  - How HTTP handlers work in Go (`http.HandleFunc`, `ResponseWriter`, `*Request`).",
    "  - What a `context.Context` is, and how timeouts and cancellation signals flow through to database queries.",
    "  - How to stream query results into Go structs and return them as clean JSON to a browser or API client.",
    "",
    "- This is just the starting point. From here I can extend the API with `POST /todos`, authentication, more tables, or even deploy a similar Go + PostgreSQL setup on a real cloud provider later."
  ],
  "date": "2025-12-06"
}
,
{
  "title": "Adding Login, bcrypt and Sessions to My Go + PostgreSQL Cloud Lab",
  "content": [
    "This post builds on top of my first Go + PostgreSQL cloud lab, where I exposed a /todos endpoint backed by a Postgres database.",
    "Here I turn that open endpoint into a simple authenticated mini-app: I add a users table, hash passwords with bcrypt, create sessions with secure random IDs and cookies, protect /todos so it only works after login, and add a basic logout route."
  ],
  "images": [
    "go_pics/go_login_overview.png"
  ],
  "description": [
    "### Context: From Open `/todos` to a Real Login",
    "In the first version of my Go cloud lab, `/todos` was completely open: if you knew the server IP and port, you could just call `/todos` and get the JSON list of todos.",
    "That was okay for a private learning setup, but not for anything that even remotely looks like a real app.",
    "In this iteration I added:",
    "- A `users` table in PostgreSQL",
    "- Password hashing using bcrypt (no more plaintext passwords in the DB)",
    "- A `/login` handler in Go that checks username + password",
    "- A tiny in-memory session store using a map",
    "- A `session_id` cookie that the browser sends with every request",
    "- A `/logout` route that kills the session and clears the cookie.",
    "The hero screenshot at the top of the post (`go_login_overview.png`) shows my setup: VS Code with `main.go` on the left and the login page running in the browser on the right.",

    "---",
    "### 1. Users Table and Password Hashes",
    "First, I added a `users` table to my existing `cloudlab` database. The important part is that I store a password hash, not the raw password.",
    "The screenshot below shows the users table in `psql`: the table definition with `id`, `username`, `password_hash`, `created_at`, plus one row for the user `fynn` with a long bcrypt hash in the `password_hash` column.",

    {
      "type": "image",
      "src": "go_pics/users_table_psql.png",
      "alt": "psql screenshot showing the users table with id, username and password_hash columns and one row for user fynn"
    },

    "To generate these hashes I wrote a tiny helper program in Go. It takes a string password, calls bcrypt to hash it and prints the result. I run this once, copy the output and paste it into the `password_hash` column in PostgreSQL.",
    "The next screenshot shows this helper file in VS Code:",

    {
      "type": "image",
      "src": "go_pics/bcrypt_helper_code.png",
      "alt": "VS Code screenshot of a small Go program that imports bcrypt, defines a password, calls GenerateFromPassword and prints the resulting hash"
    },

    "Inside my main Go server, I had to pull in bcrypt as a new dependency. In the import block of `main.go` I added one extra line for the bcrypt package, which is highlighted in the following screenshot:",

    {
      "type": "image",
      "src": "go_pics/bcrypt0.png",
      "alt": "VS Code screenshot of the import block in main.go with the golang.org/x/crypto/bcrypt import highlighted"
    },

    "In the login handler I then use bcrypt to compare the password the user typed with the stored hash from the database. Instead of comparing plain strings, the handler now calls `bcrypt.CompareHashAndPassword`. If that returns an error, the login fails.",
    "The bcrypt comparison is visible in this snippet from the POST branch of the login handler (highlighted in red in the screenshot):",

    {
      "type": "image",
      "src": "go_pics/bcrypt1.png",
      "alt": "VS Code screenshot of the login handler section where bcrypt.CompareHashAndPassword is called to verify the password"
    },

    "---",
    "### 2. Login Page: HTML, CSS and Routing",
    "For the UI I kept things minimal: a simple HTML form served from `static/login.html` plus a small CSS file for styling.",
    "The HTML file defines a basic page with a title, a link to `static/login.css` and a form that posts to `/login` using the POST method. The form has two fields (`username` and `password`) and a submit button.",
    "The next screenshot shows the relevant part of `login.html` in VS Code:",

    {
      "type": "image",
      "src": "go_pics/login_html_code.png",
      "alt": "VS Code screenshot of login.html showing the Cloud Login title and the POST form with username and password inputs"
    },

    "When I point my browser at `/login`, I see the styled login box with two input fields and a login button, as shown here:",

    {
      "type": "image",
      "src": "go_pics/login_page_browser.png",
      "alt": "Browser screenshot of the Cloud Login page with username and password fields and a blue login button"
    },

    "On the Go side, I needed to wire the static files and the new `/login` route into `main()`. I use `http.FileServer` to serve everything under `./static` and then register three handlers: `/login`, `/todos` and `/logout`.",
    "The screenshot below shows the part of `main()` where the file server and the three routes are registered. The new lines are highlighted:",

    {
      "type": "image",
      "src": "go_pics/login0.png",
      "alt": "VS Code screenshot of main.go showing the http.FileServer for ./static and the HandleFunc registrations for /login, /todos and /logout, with this block highlighted"
    },

    "The core logic for handling logins lives in `loginPageHandler`. It acts as both a GET and a POST handler:",
    "- `GET /login` serves the HTML file.",
    "- `POST /login` reads the form fields, queries the `users` table and then runs the bcrypt check.",
    "The next screenshot shows the upper part of `loginPageHandler`: the method switch, the GET branch that serves `static/login.html` and the POST branch that parses the form, reads `username` and `password` and performs the database query. This is all highlighted so you can see how the handler is structured:",

    {
      "type": "image",
      "src": "go_pics/login1.png",
      "alt": "VS Code screenshot of the upper part of loginPageHandler showing the method switch, the GET branch and the POST branch that parses the form and queries the users table"
    },

    "At the end of the POST branch, once the password has been verified, the handler creates a session and sets a cookie before redirecting to `/todos`. That session and cookie logic is part of the next section, but you can already see it in context here:",

    {
      "type": "image",
      "src": "go_pics/login2.png",
      "alt": "VS Code screenshot of the lower part of loginPageHandler showing the code that generates a session ID, stores it in the map, sets the session_id cookie and redirects to /todos"
    },

    "---",
    "### 3. Sessions and Cookies in Go",
    "To remember that a client is logged in, I added a very small in-memory session store and a helper to generate secure random session IDs.",
    "First, I pulled in two extra packages in the import block of `main.go`: `crypto/rand` for secure random bytes and `encoding/hex` to turn them into a human-readable string. These imports are highlighted in the following screenshot:",

    {
      "type": "image",
      "src": "go_pics/cookies&sessions0.png",
      "alt": "VS Code screenshot of the imports in main.go with crypto/rand and encoding/hex highlighted"
    },

    "Then I declared a global map `sessions` and added a function `generateSessionID()` which uses `rand.Read` to fill a 32-byte slice with random data and encodes it as a hex string. This gives me a random session ID that is hard to guess.",
    "The next screenshot shows the new global `sessions` map and the `generateSessionID` helper directly under the `Todo` struct. The new code is outlined in red:",

    {
      "type": "image",
      "src": "go_pics/cookies&sessions1.png",
      "alt": "VS Code screenshot showing the global sessions map and the generateSessionID function highlighted under the Todo struct"
    },

    "The final step is to create a session after a successful login and send it back to the browser in a cookie. In the POST branch of `loginPageHandler`, after bcrypt has accepted the password, I:",
    "- call `generateSessionID()` to get a new ID,",
    "- store `sessionID -> userID` in the `sessions` map,",
    "- and send a `session_id` cookie with `HttpOnly` set to true.",
    "The screenshot below shows this block of code inside the login handler, with the new session-related lines highlighted:",

    {
      "type": "image",
      "src": "go_pics/cookies&sessions2.png",
      "alt": "VS Code screenshot of loginPageHandler where the session ID is generated, stored in the sessions map, and written into an HttpOnly session_id cookie, all highlighted"
    },

    "From this point on, every request from that browser will carry the `session_id` cookie. The next step is to protect `/todos` using that information.",

    "---",
    "### 4. Protecting `/todos` with a Session Check",
    "Originally, `/todos` was wide open: anyone who knew the URL could hit it and see the JSON response. Now I want it to only work for logged-in users who have a valid session.",
    "To achieve that, I added a session check at the very top of `getTodosHandler`:",
    "- It tries to read the `session_id` cookie from the request.",
    "- If there is no cookie, it redirects to `/login`.",
    "- If there is a cookie, it looks up the session ID in the `sessions` map.",
    "- If the session ID is unknown, it also redirects to `/login`.",
    "Only if both checks pass does the handler continue with the existing database query and JSON response.",
    "The next screenshot shows the top of `getTodosHandler`: the new cookie and session checks are highlighted in red, with the existing database and JSON code visible underneath for context:",

    {
      "type": "image",
      "src": "go_pics/protecttodos.png",
      "alt": "VS Code screenshot of getTodosHandler showing the new session_id cookie lookup and sessions map check highlighted above the existing database query and JSON response code"
    },

    "In practice this means: if I open a fresh browser (no cookies) and try to access `/todos` directly, the server responds with a redirect to `/login`. Only after logging in and receiving a valid `session_id` cookie can I successfully call `/todos`.",

    "---",
    "### 5. Logout: Killing the Session and Clearing the Cookie",
    "To avoid staying logged in forever in one browser session, I added a simple `/logout` route that cleans up both the server-side session and the client-side cookie.",
    "First, I registered the new route in `main()` alongside the existing `/login` and `/todos` handlers. The highlighted line in the next screenshot shows the `HandleFunc` call for `/logout`:",

    {
      "type": "image",
      "src": "go_pics/logout0.png",
      "alt": "VS Code screenshot of main.go with the http.HandleFunc call that registers the /logout route highlighted"
    },

    "The actual logic lives in `logoutHandler`. It does three things:",
    "- Tries to read the `session_id` cookie from the request.",
    "- If it exists, removes the corresponding entry from the `sessions` map.",
    "- Sends a new `session_id` cookie with an empty value and `MaxAge: -1` so that the browser deletes it.",
    "The screenshot below shows the whole `logoutHandler` function, with its core logic clearly visible:",

    {
      "type": "image",
      "src": "go_pics/logout1.png",
      "alt": "VS Code screenshot of logoutHandler showing how the session_id cookie is read, the sessions entry deleted, a new empty cookie with MaxAge -1 set, and a redirect to /login performed"
    },

    "After visiting `/logout` in the browser, I am redirected back to `/login`. Any further request to `/todos` behaves as if I had never logged in: the handler checks the cookie and the sessions map, finds nothing valid and responds with another redirect to `/login`.",

    "---",
    "### 6. Limitations & Next Steps",
    "This is still a learning project, so there are a few things I am aware of:",
    "- Sessions are stored in memory. When I restart the Go server, all sessions are gone and existing cookies become invalid.",
    "- I don't use HTTPS yet. For something exposed to the public internet I would put a reverse proxy (like Caddy or Nginx) with TLS in front and set the `Secure` flag on the cookie.",
    "- There is no rate limiting, CSRF protection or per-user todos yet.",
    "",
    "But for a personal cloud lab running on an old Linux box, this setup already feels much more like a real app compared to the original open `/todos` endpoint:",
    "- passwords are hashed with bcrypt,",
    "- `/todos` is only reachable after a successful login,",
    "- and I can explicitly log out to drop the session.",
    "",
    "In the next iteration I might:",
    "- build a small HTML dashboard that consumes the `/todos` JSON and shows it nicely,",
    "- add per-user todos by linking the `todos` table to `users`,",
    "- and move sessions from the in-memory map into the database."
  ],
  "date": "2025-12-09"
},
  {
  "title": "Running my Go Cloudlab as a systemd Service",
  "content": [
    "After building my first Go + PostgreSQL cloud lab, I still had to start the server manually with `go run .` or by running the binary. In this mini step I turned my Go program into a proper systemd service so it starts automatically when the server boots.",
    "Now I can just press the power button on my old Ubuntu box and my Go backend comes up on port 8080 without any manual login."
  ],
  "images": [
    "go_pics/cloudlab_service_status.png"
  ],
  "description": [
    "### Goal",
    "- Make the Go HTTP server start automatically on boot, just like PostgreSQL.",
    "- Run it as a normal Linux service managed by **systemd**, not as a random process started in an SSH session.",
    "",
    "---",
    "### 1. Build the Go binary",
    "On the server I went into my Go project folder and built a binary called `cloudlab`:",
    "- `cd ~/go-playground`",
    "- `go build -o cloudlab`",
    "- Quick test with `./cloudlab` to make sure it still runs on `:8080`.",
    "",
    "---",
    "### 2. Create the systemd unit file",
    {
      "type": "image",
      "src": "go_pics/cloudlab_service_unit.png",
      "alt": "nano showing the cloudlab.service systemd unit file"
    },
    "Then I created `/etc/systemd/system/cloudlab.service` with the following structure:",
    "- `[Unit]` section: description and dependencies, e.g. `After=network-online.target postgresql.service` so the database and network are ready.",
    "- `[Service]` section:",
    "  - `User=fynn` – run the service as my normal user.",
    "  - `WorkingDirectory=/home/fynn/go-playground` – where the binary lives.",
    "  - `ExecStart=/home/fynn/go-playground/cloudlab` – the actual Go server binary.",
    "  - `Restart=on-failure` – systemd restarts it if it crashes.",
    "- `[Install]` section: `WantedBy=multi-user.target` so it participates in the normal multi-user boot target.",
    "",
    "---",
    "### 3. Tell systemd about it and start it",
    "After saving the unit file, I ran:",
    "- `sudo systemctl daemon-reload` – let systemd re-read unit files.",
    "- `sudo systemctl start cloudlab.service` – start the service once.",
    "- `sudo systemctl status cloudlab.service` – check that it's `active (running)`.",
    "",
    {
      "type": "image",
      "src": "go_pics/cloudlab_service_status.png",
      "alt": "terminal output showing cloudlab.service active (running) and listening on :8080"
    },
    "Seeing it green and running feels much more like a \"real\" backend than just a `go run` process in a shell.",
    "",
    "---",
    "### 4. Enable autostart on boot",
    "To make the service come up after every reboot I enabled it:",
    "- `sudo systemctl enable cloudlab.service`",
    "",
    "This creates a symlink so that when the system reaches the `multi-user` target during boot, systemd automatically starts `cloudlab.service`.",
    "",
    "---",
    "### 5. Result",
    "- Now the flow is:",
    "  1. Press the power button on my old server PC.",
    "  2. Ubuntu boots, PostgreSQL starts, then `cloudlab.service` starts.",
    "  3. From my main machine I can go straight to `http://SERVER_IP:8080/login` without logging into the server first.",
    "- When I want to update the backend, I rebuild the binary and restart the service:",
    "  - `go build -o cloudlab`",
    "  - `sudo systemctl restart cloudlab.service`",
    "",
    "It’s a small change, but it makes the whole project feel much closer to how real services are run on servers."
  ],
  "date": "2025-12-11"
},
 {
  "title": "File Browser Foundation: A Filesystem-Backed Browser for My Go Cloud",
  "content": [
    "In my previous Go + PostgreSQL cloud lab posts I ended up with a small authenticated mini-app: a /login page, bcrypt password hashes, in-memory sessions, and a protected /todos endpoint backed by Postgres.",
    "In this post I move away from purely database-backed data and start treating my Linux server like a tiny private cloud: I pick a storage folder on disk, expose it via a new GET /api/files endpoint in Go, and build a simple /cloud page that lists folders and files. It’s still read-only, but it’s a real filesystem browser running over HTTP.",
    "The hero screenshot at the top of the post shows what I’m aiming for here: a dark-themed /cloud page with a toolbar and a list of folders and files (code, photos, notes.txt, readme.txt) coming directly from my storage directory on the server."
  ],
  "images": [
    "go_pics/cloud_files_ui.png"
  ],
  "description": [
    "### Context: From `/todos` JSON to a Filesystem Browser",
    "Up to now my Go lab was mostly about the database side: a /todos endpoint, a users table in PostgreSQL, bcrypt password hashing, sessions, and a login + logout flow. All of that is nice, but it doesn’t yet feel like the file-based \"cloud drive\" I actually want to build.",
    "For this step I decided to ignore the database for a moment and treat a plain directory on my Ubuntu server as the root of a future cloud drive. The Go server should:",
    "- treat a fixed directory like `/home/fynn/cloud-storage` as a storage root,",
    "- expose a GET /api/files?path=/... endpoint that returns JSON,",
    "- protect it with the same session/cookie mechanism I already use for /todos,",
    "- and render a small /cloud page that consumes this JSON and shows a list of entries.",
    {
      "type": "image",
      "src": "go_pics/cloud_files_ui.png",
      "alt": "Browser screenshot of the /cloud page showing the dark themed toolbar and file list loaded from the Go backend"
    },
    "The screenshot above (`go_pics/cloud_files_ui.png`) shows the result: the browser is on /cloud, the toolbar is at the top, and the list below is populated from the Go backend calling into the filesystem.",

    "---",
    "### 1. Storage Root and the `FileEntry` Type",
    "First I picked a folder on the server that should act as the root of my little cloud. On my Ubuntu box that is:",
    "- `/home/fynn/cloud-storage`",
    "I created it once on the server and then referenced it in Go as a constant right next to my global `db` and `sessions` variables.",
    "At the same time I introduced a simple struct that describes a single directory entry for the frontend: `FileEntry`. It has four fields: name, path, type (file or dir) and size in bytes.",
    "The screenshot below shows the relevant part of `main.go` in my editor: the `FileEntry` struct with JSON tags and the `storageRoot` constant underneath it.",

    {
      "type": "image",
      "src": "go_pics/cloud_fileentry_storage_root.png",
      "alt": "Editor screenshot showing the FileEntry struct with Name, Path, Type and Size fields plus JSON tags, and the storageRoot constant set to /home/fynn/cloud-storage underneath the global db and sessions variables"
    },

    "The JSON tags on `FileEntry` ensure that the JSON response has lower-case field names (`name`, `path`, `type`, `size`), which is more idiomatic for APIs. The `Path` field is always relative to the storage root, starting with a single leading slash, for example `/photos/cat.png`.",

    "---",
    "### 2. Implementing `GET /api/files` in Go",
    "With the struct and storage root in place, the next step is the core backend endpoint: GET /api/files. The idea is simple:",
    "- the client passes a `path` query parameter that is always relative to the storage root,",
    "- the handler resolves that path under `storageRoot`,",
    "- it reads the directory entries using `os.ReadDir`,",
    "- and it returns a JSON array of `FileEntry` objects.",
    "Because the same server already hosts a login feature, I reuse the session logic from there: /api/files is only reachable if the request carries a valid `session_id` cookie that exists in the in-memory `sessions` map.",
    "The first half of `apiFilesHandler` deals with authentication, HTTP method checking and path sanitizing. The screenshot below shows this upper half of the handler in my editor:",

    {
      "type": "image",
      "src": "go_pics/cloud_apifileshandler_top.png",
      "alt": "Editor screenshot showing the upper half of apiFilesHandler: it reads the session_id cookie, checks the sessions map, rejects non-GET methods, reads the path query parameter, normalizes it with filepath.Clean and blocks any paths that contain .. segments before joining it with storageRoot"
    },
    {
      "type": "image",
      "src": "go_pics/cloud_apifileshandler_bottom.png",
      "alt": "Editor screenshot showing the lower half of apiFilesHandler: it calls os.ReadDir on the computed fullPath, iterates over entries, calls entry.Info(), decides between type file or dir, builds the relative path, appends FileEntry values to a slice and finally encodes the slice as JSON with the application/json Content-Type set"
    },

    "The handler starts by reading the `session_id` cookie from the request and checking the ID in the `sessions` map. If there is no cookie or the ID is unknown, it simply redirects back to /login. That way, the filesystem API is only usable after a successful login.",
    "Then it enforces that only GET is allowed, because this endpoint is purely for reading. Any other HTTP method gets a 405 Method Not Allowed.",
    "The next interesting bit is the path handling. The handler reads the `path` query parameter from the URL (for example `/`, `/photos`, `/code/snippets`) and normalizes it with `filepath.Clean`. Internally, an empty path or `/` is mapped to `.` to represent the storage root. To avoid path traversal attacks, the code explicitly rejects any path that equals `..`, starts with `../` or contains `/../` anywhere.",
    "Only after this cleaning step does the handler join `storageRoot` and the cleaned relative path using `filepath.Join`, giving it a safe absolute path on disk.",
    "Once the absolute path is known, the lower half of the handler calls `os.ReadDir` to list directory contents. For each entry it calls `entry.Info()` to obtain metadata, checks `entry.IsDir()` to decide the `type` field (`file` or `dir`), calculates the relative path under the storage root, and appends a `FileEntry` value to a slice. At the end the handler sets `Content-Type: application/json` and uses `json.NewEncoder(w).Encode(files)` to stream the slice to the client as JSON.",

    "---",
    "### 3. Cloud Page Handler and Static Files",
    "To turn the filesystem API into something nice to look at, I added a new route `/cloud`. This route does not return JSON; it simply serves an HTML file that lives under `static/cloud.html` and contains a minimal frontend.",
    "In `main()` I already had a file server for everything under `./static` and routes for `/login`, `/todos` and `/logout`. I added another handler registration:",
    "- `/api/files` → `apiFilesHandler` (the JSON API),",
    "- `/cloud` → `cloudPageHandler` (the HTML UI).",
    "The `cloudPageHandler` itself is intentionally small: it only allows GET, checks the `session_id` cookie using the same `sessions` map logic as other handlers, and then calls `http.ServeFile` to return `static/cloud.html`.",
    "The screenshot below shows the full `cloudPageHandler` function in my editor:",

    {
      "type": "image",
      "src": "go_pics/cloud_page_handler.png",
      "alt": "Editor screenshot of cloudPageHandler showing the GET method check, the session_id cookie lookup and sessions map validation, and the final http.ServeFile call that serves static/cloud.html"
    },

    "By protecting `/cloud` with the same session logic as `/api/files`, I make sure that both the HTML UI and the JSON API are only usable for logged-in users. After fixing my login redirect to point to `/cloud` instead of `/todos`, a successful login drops me straight onto the new cloud view.",

    "---",
    "### 4. Inspecting `/api/files` Directly in the Browser",
    "Before wiring up any frontend JavaScript I like to test backend endpoints directly in the browser. Because `/api/files` returns JSON and is protected by the session cookie, it is perfect for that.",
    "After logging in, I can manually navigate to `/api/files?path=/` and see the JSON response for the root of my storage directory. It contains one object per file or folder, with the fields defined by `FileEntry`.",
    "The screenshot below shows this JSON response in the browser: it lists my `code` and `photos` folders plus `notes.txt` and `readme.txt` as files, each with a `name`, `path`, `type` and `size` field.",

    {
      "type": "image",
      "src": "go_pics/cloud_api_files_json.png",
      "alt": "Browser screenshot of the /api/files?path=/ endpoint showing a prettified JSON array with entries for code, notes.txt, photos and readme.txt including name, path, type and size fields"
    },

    "This direct view is especially helpful while debugging path handling and permissions: if something is wrong with my path cleaning or filesystem permissions, I immediately see an error instead of an empty UI.",

    "---",
    "### 5. A Simple `/cloud` UI on Top of the API",
    "With `/api/files` working and `/cloud` serving an HTML shell, I added a very small frontend on top:",
    "- `static/cloud.html` defines the basic layout: a dark header with the current path label (for now I keep the technical \"Path: /\" look), two buttons for future features (Upload File, Refresh), and an empty container for the file list.",
    "- `static/cloud.css` gives it a simple modern look: dark background, rounded bars for each row, subtle hover effects.",
    "- `static/cloud.js` contains a tiny amount of vanilla JavaScript that calls GET /api/files?path=/ when the page loads, parses the JSON and renders one row per `FileEntry`. Double-clicking on a directory row calls /api/files with the corresponding path to navigate deeper.",
    "Because this series is primarily about Go and backend concepts, I’m not showing the full HTML/CSS/JS code here. The important part is that the /cloud UI is just a thin layer on top of the Go endpoint: all file information comes from `/api/files`, and all access control logic still lives on the server.",
    "The screenshot above is exactly this UI in action: each row in the list corresponds to a `FileEntry` produced by the Go handler, and the text `Path: /` is driven by the current path that the JavaScript passes into the endpoint.",

    "---",
    "### 6. Limitations and Next Steps",
    "Right now, my little cloud is purely a filesystem viewer:",
    "- `/api.files` only supports GET and only lists entries,",
    "- there is no way to upload, download, rename or delete anything yet,",
    "- and there is no thumbnail generation for images or any kind of preview mode.",
    "That’s intentional: I wanted a solid, well-understood foundation first. I now have:",
    "- a dedicated storage root on disk,",
    "- a simple `FileEntry` model,",
    "- a secure, session-protected JSON API for listing directories,",
    "- and a `/cloud` page that consumes this API and shows real files from my server.",
    "From here the path is clear. In future posts I plan to build on this file browser foundation and add:",
    "- a POST /api/upload endpoint plus download links,",
    "- a grid layout with thumbnails and a simple image preview overlay,",
    "- endpoints and UI actions for mkdir, rename and move,",
    "- and eventually a trash system and multi-select to make my Go cloud feel more like a real, personal drive."
  ],
  "date": "2025-12-12"
},
  {
  "title": "File Uploads & Downloads in My Go-Powered Cloud",
  "content": [
    "In the last post I built a read-only file browser for my Go + PostgreSQL cloud lab: a session-protected `/cloud` page and a `GET /api/files` endpoint that lists real files and folders from my `cloud-storage` directory on the server.",
    "In this post I finally turn that browser into a real cloud by adding file transfers: a `GET /api/download` endpoint for downloading files and a `POST /api/upload` endpoint for uploading new files into whatever folder I’m currently viewing in the UI. Both routes reuse the same session + path-safety logic from the previous post."
  ],
  "images": [],
  "description": [
    "### Context: From Read-Only Listing to Real File Transfers",
    "My first step toward a \"cloud drive\" was just listing files: the `/cloud` page called `GET /api/files?path=/...` and rendered whatever `FileEntry` structs the Go backend returned. That already felt nice, because I could navigate through a filesystem via HTTP and a simple UI.",
    "But a cloud that can only *see* files isn’t very useful. I now wanted two basic actions:",
    "- **Download** a file from the server to my browser.",
    "- **Upload** one or more local files into the directory I’m currently viewing.",
    "Everything should still be protected by my login system (session cookie + in-memory `sessions` map), and all paths should stay safely inside my `storageRoot` directory.",
    "",
    "---",
    "### 1. Downloading Files: `GET /api/download`",
    "The first new route is a download endpoint. The idea is simple:",
    "- the client calls `GET /api/download?path=/photos/cat.png`,",
    "- the server checks the session, cleans the path and verifies that it is a real file inside `storageRoot`,",
    "- and then streams the file with `http.ServeFile`.",
    "The screenshot below shows the complete `downloadHandler` in my `main.go`. At the top it performs the usual session check and enforces that only `GET` is allowed. Then it reads the `path` query parameter, normalizes it with `filepath.Clean`, strips any leading slash to get a relative path, blocks any `..` segments to prevent path traversal, joins it with `storageRoot`, and finally uses `os.Stat` to ensure the target exists and is not a directory. If everything looks good, it calls `http.ServeFile(w, r, fullPath)` to send the file back to the browser.",
    {
      "type": "image",
      "src": "go_pics/cloud_downloadhandler.png",
      "alt": "Editor screenshot of the full downloadHandler in Go, showing the session check, HTTP method check, path cleaning with filepath.Clean, path traversal protection, os.Stat call to verify the file, and final http.ServeFile call"
    },
    "A few important details:",
    "- I reuse the **session check** from other handlers: if the `session_id` cookie is missing or the ID is not in the `sessions` map, the handler redirects to `/login`.",
    "- I enforce `GET` with `if r.Method != http.MethodGet` so the endpoint is clearly read-only.",
    "- I treat the `path` parameter as a **logical cloud path** (like `/photos/cat.png`), then turn it into a relative path under `storageRoot` by cleaning it and trimming the leading slash.",
    "- I explicitly reject paths that equal `..`, start with `../` or contain `/../` anywhere, to avoid ever leaving the cloud directory.",
    "- I use `os.Stat` to decide between user errors and server errors: `os.IsNotExist(err)` becomes a 404 Not Found, other errors become a 500 Internal Server Error.",
    "",
    "One subtle but interesting point: I simply call `http.ServeFile` without setting a `Content-Disposition: attachment` header. That means the browser decides what to do with the file based on the `Content-Type`. For images and text files it usually opens a viewer in the tab; for unknown or binary types it tends to offer a download. For now that’s perfectly fine for my little lab.",
    "",
    "---",
    "### 2. Designing the Upload API: `POST /api/upload`",
    "For uploads I wanted something that fits well with a browser and is easy to reason about:",
    "- The request should be `multipart/form-data` (the standard for file uploads from HTML/JS).",
    "- There should be a **text field** called `path` that tells the server in which cloud folder to put the files.",
    "- There should be one or more **file fields** called `file` that contain the actual files.",
    "The high-level flow in the upload handler looks like this:",
    "1. Check session and enforce `POST` only.",
    "2. Parse the multipart form (`r.ParseMultipartForm`).",
    "3. Read the `path` form field, clean it and validate it (no `..`, no escaping `storageRoot`).",
    "4. Compute the target directory and ensure it exists (`os.MkdirAll`).",
    "5. Loop over all uploaded files, sanitize their names, skip existing files, and save the rest to disk.",
    "6. Respond with HTTP 204 No Content if everything went fine.",
    "The first half of the handler is responsible for authentication, parsing and path handling:",
    {
      "type": "image",
      "src": "go_pics/cloud_uploadhandler_top.png",
      "alt": "Editor screenshot of the upper half of uploadHandler: session and method checks, ParseMultipartForm call with a 32 MB memory limit, nil check for r.MultipartForm, reading the path form field, normalizing it with filepath.Clean, mapping / and . to the cloud root, blocking any .. segments, and joining the result with storageRoot to form uploadDir, plus MkdirAll to ensure the directory exists"
    },
    {
      "type": "image",
      "src": "go_pics/cloud_uploadhandler_bottom.png",
      "alt": "Editor screenshot of the lower half of uploadHandler: retrieving r.MultipartForm.File[\"file\"], looping over each FileHeader, using filepath.Base to sanitize the filename, opening the uploaded file as src, checking with os.Stat if the destination file already exists and skipping it if so, creating the destination file with os.Create, copying data with io.Copy, closing both files, and finally writing a 204 No Content status"
    },
    "Some key ideas in this handler:",
    "- **Session + method check**: just like `/api/files` and `/api/download`, `/api/upload` starts by checking the `session_id` cookie and restricting the method to `POST`. No anonymous uploads allowed.",
    "- **Multipart parsing**: `r.ParseMultipartForm(32 << 20)` tells Go to parse the `multipart/form-data` body and use up to 32 MiB of RAM for form data, spilling larger parts to temporary disk files. Afterwards, `r.FormValue(\"path\")` gives me the target folder and `r.MultipartForm.File[\"file\"]` gives me the list of uploaded files.",
    "- **Path normalization**: I treat an empty `path` or `/` as the cloud root (`\".\"` internally) and then run everything through `filepath.Clean`. If the cleaned path is just `/` I map it back to `\".\"`, and I reject anything with `..` segments. Finally, `filepath.Join(storageRoot, rel)` gives me a safe, absolute filesystem path that always stays under `storageRoot`.",
    "- **Ensuring the directory exists**: `os.MkdirAll(uploadDir, 0755)` is a safety net. If the target directory or any of its parents are missing, it creates them. If everything already exists, it does nothing. This makes the upload path more robust and plays nicely with future features like \"new folder\".",
    "",
    "---",
    "### 3. Saving Uploaded Files Safely",
    "The second half of `uploadHandler` actually moves bytes from the HTTP request into real files on disk. For each `*multipart.FileHeader` in `files := r.MultipartForm.File[\"file\"]` I do:",
    "- Get a clean filename with `filepath.Base(fh.Filename)` so I ignore any path components a browser or client might include. Only the final name like `cat.png` or `notes.txt` is allowed.",
    "- Skip weird or empty names such as `\"\"`, `\".\"` or `\"..\"`.",
    "- Call `fh.Open()` to get a `src` reader for the uploaded file contents.",
    "- Build a destination path `dstPath := filepath.Join(uploadDir, filename)`.",
    "- Use `os.Stat(dstPath)` to check if a file already exists there. If it does, I log a message and skip that upload instead of overwriting it.",
    "- Create the destination file with `os.Create(dstPath)` and get a writer `dst`.",
    "- Stream data from `src` to `dst` using `io.Copy(dst, src)`.",
    "- Close both `dst` and `src` when done.",
    "At the very end of the handler I send a `204 No Content` response:",
    "- No JSON body, no HTML, just a status that says: \"Upload succeeded.\"",
    "- On the frontend side I simply check `res.ok` and then call `loadFiles(currentPath)` to refresh the file list in the UI.",
    "",
    "---",
    "### 4. Wiring the Frontend: Upload Button & Click-to-Open",
    "On the frontend I only had to make relatively small changes to my existing `/cloud` page:",
    "- The HTML now contains a visible \"Upload File\" button and a hidden `<input type=\"file\" id=\"file-input\" multiple>` element.",
    "- When I click the button, JavaScript triggers `fileInput.click()`, which opens the standard file chooser dialog.",
    "- In the `change` event of the file input, I create a `FormData` instance, append the current cloud path under the `path` key, append each selected file under the `file` key, and send it to `POST /api/upload` using `fetch`. On success I reload the current folder with `loadFiles(currentPath)`, so the freshly uploaded files appear immediately.",
    "- For downloads, I attach a click handler to each file row that sets `window.location.href = \"/api/download?path=\" + encodeURIComponent(file.path)`.",
    "I still keep the frontend very small and focused: no progress bars, no drag & drop, no fancy previews yet. The point of this post is to understand how the Go handlers work and how the browser talks to them, not to build a perfect UI.",
    "",
    "---",
    "### 5. Security and Safety Considerations",
    "Even though this runs on an old home server and is only meant for my personal use, I tried to keep the upload and download paths reasonably safe:",
    "- All routes involved (`/api/files`, `/api/download`, `/api/upload`, `/cloud`) are protected by the same session cookie check that I use for `/todos`.",
    "- Every path the client sends is treated as a **relative cloud path**, cleaned with `filepath.Clean`, stripped of any leading slash and validated against `..` segments before it is joined with `storageRoot`.",
    "- Uploads cannot escape the cloud directory and cannot overwrite existing files (I explicitly skip any file where `os.Stat` finds an existing entry at that path).",
    "- The `MkdirAll` call only ever creates directories under `storageRoot`, never outside of it.",
    "This is not production-grade security yet (there is still no HTTPS, no per-user isolation for files and no rate limiting), but it’s already a good exercise in thinking about what can go wrong when you let users send you paths and files over HTTP.",
    "",
    "---",
    "### 6. Where I Want to Go Next",
    "With upload and download in place, my Go cloud finally feels like a tiny but real drive:",
    "- I can browse folders under `/home/fynn/cloud-storage` from `/cloud`.",
    "- I can upload new text files and images into any folder I have open in the UI.",
    "- I can click a file to open or download it through `/api/download`.",
    "The next steps are all about making this *nice* to use:",
    "- a grid layout for files and folders, more like Google Drive’s card view,",
    "- a preview overlay for images on double click,",
    "- a context menu per file/dir with options like Download, Rename, Move and Trash,",
    "- backend endpoints for mkdir, rename, move and trash,",
    "- and eventually a trash system plus multi-select.",
    "But for now I’m happy: my little Go server has evolved from a toy `/todos` JSON API into a session-protected, filesystem-backed cloud where files can actually move in and out."
  ],
  "date": "2025-12-14"
},
  {
  "title": "Adding \"New Folder\" to My Go Cloud File Browser",
  "content": [
    "In my Go cloud project I already have the basics in place: a login system with bcrypt and sessions, a protected /cloud page that talks to a filesystem-backed storage root, and upload/download endpoints wired into the UI.",
    "In this post I add one essential feature: creating folders directly from the browser. I introduce a small JSON payload for create-folder requests, a POST /api/mkdir endpoint in Go that validates paths and folder names, and a simple \"New Folder\" action in the /cloud toolbar.",
    "The hero screenshot at the top shows the result: a blue \"+ New\" button in the top-right corner of the cloud UI. Clicking it opens a dropdown where the first option is \"New Folder\", which then creates a directory inside whatever path the UI is currently showing."
  ],
  "images": [
    "go_pics/cloud_new_folder_menu.png"
  ],
  "description": [
    "### 1. Context: From Read-Only Listing to Basic File Management",
    "Until now my Go cloud behaved more like a read-only viewer: the backend could list files from the storage directory, and I added upload and download so I could move data in and out. But as long as I could not create folders from the browser, I still had to SSH into the server if I wanted to organize things properly.",
    "The goal of this step is simple: make it possible to create new folders directly from the /cloud page, while still keeping the backend strict about paths so everything stays inside `/home/fynn/cloud-storage` and cannot escape that root.",

    "---",
    "### 2. New Folder in the UI",
    "On the frontend the new feature starts with the toolbar. I extended the existing \"+ New\" button so that it opens a dropdown menu with three entries:",
    "- New Folder",
    "- Upload File",
    "- Upload Folder (planned for later)",
    "The screenshot below shows the dropdown in action inside my cloud UI:",
    {
      "type": "image",
      "src": "go_pics/cloud_new_folder_menu.png",
      "alt": "Screenshot of the Go cloud UI showing a blue + New button with a dropdown menu containing New Folder, Upload File and Upload Folder"
    },
    "When I click \"New Folder\" the menu closes and the browser displays a prompt asking me for the folder name. This is deliberately very minimal for now: a simple text input where I type something like `testfolder` and confirm. The next screenshot shows that prompt:",
    {
      "type": "image",
      "src": "go_pics/cloud_new_folder_prompt.png",
      "alt": "Browser prompt dialog asking for Folder name with an example name testfolder written into the input field"
    },
    "If I cancel the prompt, nothing happens. If I confirm a non-empty name, the frontend sends a small JSON request to the Go server containing two fields: the current path in the UI and the folder name I just entered.",

    "---",
    "### 3. Request Model: `mkdirRequest`",
    "On the Go side I added a tiny struct called `mkdirRequest` that describes exactly what the frontend sends in that JSON body. It has two string fields:",
    "- `Path`: the current folder shown in the UI, for example `/`, `/photos` or `/code/snippets`,",
    "- `Name`: the desired name for the new folder, such as `wallpapers`.",
    "The struct has JSON tags so that the server expects the keys `path` and `name` in the request body. When the handler receives a POST /api/mkdir, it uses a JSON decoder to read the request body directly into a `mkdirRequest` value.",
    "If the JSON is malformed or missing required fields, the decoder returns an error and the handler responds with a `400 Bad Request` status to signal that the client sent invalid data.",

    "---",
    "### 4. The `/api/mkdir` Handler: Path and Name Validation",
    "The core logic for creating folders lives in a new handler function `apiMkdirHandler`. It follows the same security patterns as my other API endpoints:",
    "- It only accepts the HTTP POST method.",
    "- It reads the `session_id` cookie and checks the in-memory sessions map; if there is no valid session, it returns `401 Unauthorized`.",
    "- It decodes the JSON body into a `mkdirRequest` instance.",
    "- It normalizes and validates the requested parent path before touching the filesystem.",
    "The first screenshot of the handler shows exactly these steps: session checks, JSON decoding, cleaning the path with `filepath.Clean`, mapping an empty path or `/` to the storage root, and rejecting any path that tries to use `..` segments to escape the cloud root:",
    {
      "type": "image",
      "src": "go_pics/cloud_mkdir_handler_top.png",
      "alt": "Editor screenshot showing the upper part of apiMkdirHandler with POST method enforcement, session_id cookie checks, decoding of the JSON body into mkdirRequest, and normalization and validation of the requested path including rejecting .. segments"
    },
    "Once the path is safe, the handler validates the folder name. It trims surrounding whitespace and then rejects names that are empty, equal to `.` or `..`, or that contain slashes or backslashes. This prevents strange or dangerous folder names and keeps the structure clean.",
    "Next the handler computes the absolute parent directory by joining the cleaned path with `storageRoot` and uses `os.Stat` to make sure that this parent directory actually exists and is a directory, not a file. If the parent does not exist, the handler responds with `400 Bad Request`.",
    "The second screenshot shows the rest of the logic: building the full target directory path, checking whether something with that name already exists, logging unexpected errors during `os.Stat`, and finally calling `os.Mkdir` to create the directory with standard 0755 permissions. On success it sends back a `204 No Content` response without any body:",
    {
      "type": "image",
      "src": "go_pics/cloud_mkdir_handler_bottom.png",
      "alt": "Editor screenshot showing the lower part of apiMkdirHandler where the parent directory is checked with os.Stat, the target folder path is built, existing folders cause a conflict error, and os.Mkdir is called to create the directory followed by a 204 No Content response"
    },
    "The HTTP status codes are chosen to be meaningful:",
    "- 400 for invalid JSON, invalid paths or invalid names,",
    "- 401 if there is no valid session,",
    "- 409 if a folder with that name already exists,",
    "- 500 if an unexpected filesystem error occurs,",
    "- 204 if the folder was successfully created.",

    "---",
    "### 5. Registering the Route in `main()`",
    "To make the new handler reachable, I registered another route in `main()` alongside my existing file endpoints. All filesystem actions now live under the `/api` prefix:",
    "- `/api/files` for listing directory contents,",
    "- `/api/download` for sending files to the browser,",
    "- `/api/upload` for receiving files from a form upload,",
    "- `/api/mkdir` for creating new folders.",
    "This keeps the whole file API nicely grouped and reuses the same session and path-handling strategy everywhere.",

    "---",
    "### 6. Frontend: Calling `/api/mkdir` and Refreshing the View",
    "In `cloud.js` the menu item for \"New Folder\" is wired up to an asynchronous click handler. When the user selects it:",
    "- the dropdown menu is hidden,",
    "- a prompt asks for the folder name,",
    "- if there is a name, the script sends a POST request to `/api/mkdir` with a JSON body containing the current `path` from the UI and the `name` from the prompt.",
    "When the response comes back:",
    "- if the server returns `401 Unauthorized`, the script redirects the browser to `/login`,",
    "- if the status code is not OK for any other reason, an alert shows a simple error message,",
    "- and if everything is fine (status 204), the script calls the same `loadFiles(currentPath)` function that is used elsewhere to refresh the current directory view.",
    "The result is a smooth interaction: I click \"+ New → New Folder\", type a name, and a moment later a new folder card appears in the grid inside the current path.",

    "---",
    "### 7. Result and Next Steps",
    "With the \"New Folder\" feature implemented, my Go cloud has taken another step towards feeling like a real personal drive:",
    "- I can create folders directly from the browser,",
    "- the Go backend enforces that all operations stay inside the configured storage root,",
    "- and the feature reuses the existing session and JSON infrastructure rather than inventing something special just for folders.",
    "The frontend is still intentionally simple, using a basic prompt dialog and a minimal dropdown menu, but the underlying backend is robust and ready for more advanced UI on top. In the next steps I plan to add more file operations such as renaming and moving items, and later on a trash system and multi-select so I can manage larger photo collections and code snippets more comfortably inside this self-hosted Go cloud."
  ],
  "date": "2025-12-15"
}



]
