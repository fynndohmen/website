[
{
  "title": "Turning an Old PC into a Go + PostgreSQL Cloud Lab",
  "content": [
    "This project is my first real step into the world of backend development, cloud-like setups, and databases using Go. I took an old i3 PC with 4GB RAM, installed Ubuntu Server on it, and turned it into a small home lab that exposes a JSON API built with Go and backed by a PostgreSQL database.",
    "The main goal was not just to get something working, but to really understand what each piece does: Linux as a server, PostgreSQL as a database server, Go as the HTTP backend, and how they all talk to each other over TCP, HTTP, and SQL."
  ],
  "images": [],
  "description": [
    "### Goal & Overview",
    "- **Goal:** Turn an old PC into a small backend \"cloud lab\" with Go and PostgreSQL, and use it to learn how HTTP servers, databases, and contexts work together.",
    "- **Tech stack:**",
    "  - Ubuntu LTS on a repurposed i3 desktop as a headless server",
    "  - PostgreSQL as the database server",
    "  - Go (`net/http` + `database/sql` + `pgx` driver) as the HTTP API backend",
    "",
    "---",
    "### 1. Hardware & Linux Setup",
    {
      "type": "image",
      "src": "go_pics/server-ssh-setup.png",
      "alt": "SSH connection to the Ubuntu Go server"
    },
    "- I reused an old i3 PC with ~4GB RAM and installed **Ubuntu Server LTS** instead of a desktop environment.",
    "- The idea: keep it headless and manage everything over **SSH** from my main machine.",
    "- Steps:",
    "  - Create a bootable USB stick with the Ubuntu LTS ISO.",
    "  - Install Ubuntu with no GUI, only OpenSSH server enabled.",
    "  - Give the server a static IP or make sure I can consistently reach it via `ssh user@server-ip`.",
    "- Result: I can now power on the \"server PC\", and from my main computer connect only via SSH – no screen, no keyboard needed on the server itself.",
    "",
    "---",
    "### 2. PostgreSQL as the Database Server",
    {
      "type": "image",
      "src": "go_pics/psql-todos-table.png",
      "alt": "psql view of the todos table in the cloudlab database"
    },
    "- On the Ubuntu server, I installed PostgreSQL and created:",
    "  - a **user** (role) for my Go app,",
    "  - a **database** called `cloudlab`,",
    "  - and a **table** called `todos`.",
    "- The `todos` table has four columns:",
    "  - `id` (integer primary key),",
    "  - `title` (text),",
    "  - `done` (boolean, default `false`),",
    "  - `created_at` (timestamp with timezone, default `NOW()`).",
    "- I tested everything directly in `psql` by inserting a couple of rows and running `SELECT * FROM todos;` to see the result.",
    "",
    "---",
    "### 3. Go Project Structure & Database Connection",
    {
      "type": "image",
      "src": "go_pics/go-code-part1.png",
      "alt": "First part of the Go code: imports, Todo struct, main and database setup"
    },
    {
      "type": "image",
      "src": "go_pics/go-code-part2.png",
      "alt": "Second part of the Go code: getTodosHandler with context, query, loop and JSON response"
    },
    "- On the Go side, I created a small project with a single `main.go` file.",
    "- At the top there is the usual `package main` and an import block that pulls in:",
    "  - `net/http` for the web server,",
    "  - `database/sql` for database access,",
    "  - `encoding/json` to send JSON responses,",
    "  - `context` and `time` for timeouts,",
    "  - and the `pgx` driver via `_ \"github.com/jackc/pgx/v5/stdlib\"`.",
    "- I defined a `Todo` struct that mirrors the database columns (`id`, `title`, `done`, `created_at`) and added JSON tags so that the JSON field names match what I want to expose in the API.",
    "- The database handle is a global `var db *sql.DB`, which in Go represents a connection **pool** that `database/sql` manages for me (not just a single connection).",
    "",
    "---",
    "### 4. DSN, `sql.Open` and `db.Ping()`",
    "- To connect Go to PostgreSQL, I use a DSN (data source name) URL that looks like:",
    "  - `postgres://user:password@host:5432/cloudlab?sslmode=disable`",
    "- In `main()` I call `sql.Open(\"pgx\", dsn)` to initialize the DB handle using the `pgx` driver.",
    "- I immediately follow that with `db.Ping()` to actively check that the connection really works (credentials, host, port, database name).",
    "- If either step fails, the program logs the error and exits, so I know early that something is wrong with the setup.",
    "",
    "---",
    "### 5. HTTP Server, Routing and Handlers",
    "- For the HTTP side I use the standard library's `net/http` package.",
    "- In `main()` I register the `/todos` route using `http.HandleFunc(\"/todos\", getTodosHandler)`. This tells Go:",
    "  - \"Whenever a request comes in on `/todos`, call `getTodosHandler` and pass it a `ResponseWriter` plus the `*Request`.\"",
    "- Finally, `http.ListenAndServe(\":8080\", nil)` starts the HTTP server on port 8080 and blocks:",
    "  - It listens for incoming TCP connections,",
    "  - parses HTTP requests,",
    "  - and forwards them to the correct handler based on the path.",
    "",
    "---",
    "### 6. Request Handling, Context and Database Query",
    "- The core of the API is the `getTodosHandler` function (shown in the second Go screenshot above). The rough flow is:",
    "  1. Create a context with a timeout using `context.WithTimeout(r.Context(), 5*time.Second)`. That way, the database query will be cancelled if it takes too long or the client disconnects.",
    "  2. Call `db.QueryContext(ctx, \"SELECT id, title, done, created_at FROM todos ORDER BY id\")` to fetch all todos from the database using that context.",
    "  3. Loop over the returned rows with `rows.Next()` and use `rows.Scan(&t.ID, &t.Title, &t.Done, &t.CreatedAt)` to fill a `Todo` struct for each row.",
    "  4. Append each `Todo` to a slice until there are no more rows and also check `rows.Err()` for any errors that happened during iteration.",
    "  5. Set the response header `Content-Type` to `application/json`.",
    "  6. Use `json.NewEncoder(w).Encode(todos)` to encode the slice of todos as JSON and stream it directly into the HTTP response body.",
    "- The handler does its own error handling at each step and returns appropriate HTTP status codes if something goes wrong (e.g. `500 Internal Server Error` for DB or JSON issues).",
    "",
    "---",
    "### 7. JSON API Endpoint in the Browser",
    {
      "type": "image",
      "src": "go_pics/todos-endpoint-browser.png",
      "alt": "Browser showing the JSON response from the /todos endpoint"
    },
    "- With the Go server running, a simple GET request to `/todos` returns a JSON array of todo objects.",
    "- The screenshot above shows the JSON response in the browser: each object has `id`, `title`, `done` and `created_at` fields coming directly from the database via the Go handler.",
    "- This output can be consumed by anything: a frontend app, `curl`, Postman, or even another service.",
    "",
    "---",
    "### 8. Learning Takeaways",
    "- From this small project I learned:",
    "  - How to turn an old PC into a headless Ubuntu server and manage it via SSH.",
    "  - The difference between PostgreSQL as a **database server**, a **database** (e.g. `cloudlab`) and a **table** (e.g. `todos`).",
    "  - How Go's `database/sql` package uses a driver (`pgx`) and a DSN to connect to PostgreSQL.",
    "  - How HTTP handlers work in Go (`http.HandleFunc`, `ResponseWriter`, `*Request`).",
    "  - What a `context.Context` is, and how timeouts and cancellation signals flow through to database queries.",
    "  - How to stream query results into Go structs and return them as clean JSON to a browser or API client.",
    "",
    "- This is just the starting point. From here I can extend the API with `POST /todos`, authentication, more tables, or even deploy a similar Go + PostgreSQL setup on a real cloud provider later."
  ],
  "date": "2025-12-06"
}
,
{
  "title": "Adding Login, bcrypt and Sessions to My Go + PostgreSQL Cloud Lab",
  "content": [
    "This post builds on top of my first Go + PostgreSQL cloud lab, where I exposed a /todos endpoint backed by a Postgres database.",
    "Here I turn that open endpoint into a simple authenticated mini-app: I add a users table, hash passwords with bcrypt, create sessions with secure random IDs and cookies, protect /todos so it only works after login, and add a basic logout route."
  ],
  "images": [
    "go_pics/go_login_overview.png"
  ],
  "description": [
    "### Context: From Open `/todos` to a Real Login",
    "In the first version of my Go cloud lab, `/todos` was completely open: if you knew the server IP and port, you could just call `/todos` and get the JSON list of todos.",
    "That was okay for a private learning setup, but not for anything that even remotely looks like a real app.",
    "In this iteration I added:",
    "- A `users` table in PostgreSQL",
    "- Password hashing using bcrypt (no more plaintext passwords in the DB)",
    "- A `/login` handler in Go that checks username + password",
    "- A tiny in-memory session store using a map",
    "- A `session_id` cookie that the browser sends with every request",
    "- A `/logout` route that kills the session and clears the cookie.",
    "The hero screenshot at the top of the post (`go_login_overview.png`) shows my setup: VS Code with `main.go` on the left and the login page running in the browser on the right.",

    "---",
    "### 1. Users Table and Password Hashes",
    "First, I added a `users` table to my existing `cloudlab` database. The important part is that I store a password hash, not the raw password.",
    "The screenshot below shows the users table in `psql`: the table definition with `id`, `username`, `password_hash`, `created_at`, plus one row for the user `fynn` with a long bcrypt hash in the `password_hash` column.",

    {
      "type": "image",
      "src": "go_pics/users_table_psql.png",
      "alt": "psql screenshot showing the users table with id, username and password_hash columns and one row for user fynn"
    },

    "To generate these hashes I wrote a tiny helper program in Go. It takes a string password, calls bcrypt to hash it and prints the result. I run this once, copy the output and paste it into the `password_hash` column in PostgreSQL.",
    "The next screenshot shows this helper file in VS Code:",

    {
      "type": "image",
      "src": "go_pics/bcrypt_helper_code.png",
      "alt": "VS Code screenshot of a small Go program that imports bcrypt, defines a password, calls GenerateFromPassword and prints the resulting hash"
    },

    "Inside my main Go server, I had to pull in bcrypt as a new dependency. In the import block of `main.go` I added one extra line for the bcrypt package, which is highlighted in the following screenshot:",

    {
      "type": "image",
      "src": "go_pics/bcrypt0.png",
      "alt": "VS Code screenshot of the import block in main.go with the golang.org/x/crypto/bcrypt import highlighted"
    },

    "In the login handler I then use bcrypt to compare the password the user typed with the stored hash from the database. Instead of comparing plain strings, the handler now calls `bcrypt.CompareHashAndPassword`. If that returns an error, the login fails.",
    "The bcrypt comparison is visible in this snippet from the POST branch of the login handler (highlighted in red in the screenshot):",

    {
      "type": "image",
      "src": "go_pics/bcrypt1.png",
      "alt": "VS Code screenshot of the login handler section where bcrypt.CompareHashAndPassword is called to verify the password"
    },

    "---",
    "### 2. Login Page: HTML, CSS and Routing",
    "For the UI I kept things minimal: a simple HTML form served from `static/login.html` plus a small CSS file for styling.",
    "The HTML file defines a basic page with a title, a link to `static/login.css` and a form that posts to `/login` using the POST method. The form has two fields (`username` and `password`) and a submit button.",
    "The next screenshot shows the relevant part of `login.html` in VS Code:",

    {
      "type": "image",
      "src": "go_pics/login_html_code.png",
      "alt": "VS Code screenshot of login.html showing the Cloud Login title and the POST form with username and password inputs"
    },

    "When I point my browser at `/login`, I see the styled login box with two input fields and a login button, as shown here:",

    {
      "type": "image",
      "src": "go_pics/login_page_browser.png",
      "alt": "Browser screenshot of the Cloud Login page with username and password fields and a blue login button"
    },

    "On the Go side, I needed to wire the static files and the new `/login` route into `main()`. I use `http.FileServer` to serve everything under `./static` and then register three handlers: `/login`, `/todos` and `/logout`.",
    "The screenshot below shows the part of `main()` where the file server and the three routes are registered. The new lines are highlighted:",

    {
      "type": "image",
      "src": "go_pics/login0.png",
      "alt": "VS Code screenshot of main.go showing the http.FileServer for ./static and the HandleFunc registrations for /login, /todos and /logout, with this block highlighted"
    },

    "The core logic for handling logins lives in `loginPageHandler`. It acts as both a GET and a POST handler:",
    "- `GET /login` serves the HTML file.",
    "- `POST /login` reads the form fields, queries the `users` table and then runs the bcrypt check.",
    "The next screenshot shows the upper part of `loginPageHandler`: the method switch, the GET branch that serves `static/login.html` and the POST branch that parses the form, reads `username` and `password` and performs the database query. This is all highlighted so you can see how the handler is structured:",

    {
      "type": "image",
      "src": "go_pics/login1.png",
      "alt": "VS Code screenshot of the upper part of loginPageHandler showing the method switch, the GET branch and the POST branch that parses the form and queries the users table"
    },

    "At the end of the POST branch, once the password has been verified, the handler creates a session and sets a cookie before redirecting to `/todos`. That session and cookie logic is part of the next section, but you can already see it in context here:",

    {
      "type": "image",
      "src": "go_pics/login2.png",
      "alt": "VS Code screenshot of the lower part of loginPageHandler showing the code that generates a session ID, stores it in the map, sets the session_id cookie and redirects to /todos"
    },

    "---",
    "### 3. Sessions and Cookies in Go",
    "To remember that a client is logged in, I added a very small in-memory session store and a helper to generate secure random session IDs.",
    "First, I pulled in two extra packages in the import block of `main.go`: `crypto/rand` for secure random bytes and `encoding/hex` to turn them into a human-readable string. These imports are highlighted in the following screenshot:",

    {
      "type": "image",
      "src": "go_pics/cookies&sessions0.png",
      "alt": "VS Code screenshot of the imports in main.go with crypto/rand and encoding/hex highlighted"
    },

    "Then I declared a global map `sessions` and added a function `generateSessionID()` which uses `rand.Read` to fill a 32-byte slice with random data and encodes it as a hex string. This gives me a random session ID that is hard to guess.",
    "The next screenshot shows the new global `sessions` map and the `generateSessionID` helper directly under the `Todo` struct. The new code is outlined in red:",

    {
      "type": "image",
      "src": "go_pics/cookies&sessions1.png",
      "alt": "VS Code screenshot showing the global sessions map and the generateSessionID function highlighted under the Todo struct"
    },

    "The final step is to create a session after a successful login and send it back to the browser in a cookie. In the POST branch of `loginPageHandler`, after bcrypt has accepted the password, I:",
    "- call `generateSessionID()` to get a new ID,",
    "- store `sessionID -> userID` in the `sessions` map,",
    "- and send a `session_id` cookie with `HttpOnly` set to true.",
    "The screenshot below shows this block of code inside the login handler, with the new session-related lines highlighted:",

    {
      "type": "image",
      "src": "go_pics/cookies&sessions2.png",
      "alt": "VS Code screenshot of loginPageHandler where the session ID is generated, stored in the sessions map, and written into an HttpOnly session_id cookie, all highlighted"
    },

    "From this point on, every request from that browser will carry the `session_id` cookie. The next step is to protect `/todos` using that information.",

    "---",
    "### 4. Protecting `/todos` with a Session Check",
    "Originally, `/todos` was wide open: anyone who knew the URL could hit it and see the JSON response. Now I want it to only work for logged-in users who have a valid session.",
    "To achieve that, I added a session check at the very top of `getTodosHandler`:",
    "- It tries to read the `session_id` cookie from the request.",
    "- If there is no cookie, it redirects to `/login`.",
    "- If there is a cookie, it looks up the session ID in the `sessions` map.",
    "- If the session ID is unknown, it also redirects to `/login`.",
    "Only if both checks pass does the handler continue with the existing database query and JSON response.",
    "The next screenshot shows the top of `getTodosHandler`: the new cookie and session checks are highlighted in red, with the existing database and JSON code visible underneath for context:",

    {
      "type": "image",
      "src": "go_pics/protecttodos.png",
      "alt": "VS Code screenshot of getTodosHandler showing the new session_id cookie lookup and sessions map check highlighted above the existing database query and JSON response code"
    },

    "In practice this means: if I open a fresh browser (no cookies) and try to access `/todos` directly, the server responds with a redirect to `/login`. Only after logging in and receiving a valid `session_id` cookie can I successfully call `/todos`.",

    "---",
    "### 5. Logout: Killing the Session and Clearing the Cookie",
    "To avoid staying logged in forever in one browser session, I added a simple `/logout` route that cleans up both the server-side session and the client-side cookie.",
    "First, I registered the new route in `main()` alongside the existing `/login` and `/todos` handlers. The highlighted line in the next screenshot shows the `HandleFunc` call for `/logout`:",

    {
      "type": "image",
      "src": "go_pics/logout0.png",
      "alt": "VS Code screenshot of main.go with the http.HandleFunc call that registers the /logout route highlighted"
    },

    "The actual logic lives in `logoutHandler`. It does three things:",
    "- Tries to read the `session_id` cookie from the request.",
    "- If it exists, removes the corresponding entry from the `sessions` map.",
    "- Sends a new `session_id` cookie with an empty value and `MaxAge: -1` so that the browser deletes it.",
    "The screenshot below shows the whole `logoutHandler` function, with its core logic clearly visible:",

    {
      "type": "image",
      "src": "go_pics/logout1.png",
      "alt": "VS Code screenshot of logoutHandler showing how the session_id cookie is read, the sessions entry deleted, a new empty cookie with MaxAge -1 set, and a redirect to /login performed"
    },

    "After visiting `/logout` in the browser, I am redirected back to `/login`. Any further request to `/todos` behaves as if I had never logged in: the handler checks the cookie and the sessions map, finds nothing valid and responds with another redirect to `/login`.",

    "---",
    "### 6. Limitations & Next Steps",
    "This is still a learning project, so there are a few things I am aware of:",
    "- Sessions are stored in memory. When I restart the Go server, all sessions are gone and existing cookies become invalid.",
    "- I don't use HTTPS yet. For something exposed to the public internet I would put a reverse proxy (like Caddy or Nginx) with TLS in front and set the `Secure` flag on the cookie.",
    "- There is no rate limiting, CSRF protection or per-user todos yet.",
    "",
    "But for a personal cloud lab running on an old Linux box, this setup already feels much more like a real app compared to the original open `/todos` endpoint:",
    "- passwords are hashed with bcrypt,",
    "- `/todos` is only reachable after a successful login,",
    "- and I can explicitly log out to drop the session.",
    "",
    "In the next iteration I might:",
    "- build a small HTML dashboard that consumes the `/todos` JSON and shows it nicely,",
    "- add per-user todos by linking the `todos` table to `users`,",
    "- and move sessions from the in-memory map into the database."
  ],
  "date": "2025-12-09"
},
  {
  "title": "Running my Go Cloudlab as a systemd Service",
  "content": [
    "After building my first Go + PostgreSQL cloud lab, I still had to start the server manually with `go run .` or by running the binary. In this mini step I turned my Go program into a proper systemd service so it starts automatically when the server boots.",
    "Now I can just press the power button on my old Ubuntu box and my Go backend comes up on port 8080 without any manual login."
  ],
  "images": [
    "go_pics/cloudlab_service_status.png"
  ],
  "description": [
    "### Goal",
    "- Make the Go HTTP server start automatically on boot, just like PostgreSQL.",
    "- Run it as a normal Linux service managed by **systemd**, not as a random process started in an SSH session.",
    "",
    "---",
    "### 1. Build the Go binary",
    "On the server I went into my Go project folder and built a binary called `cloudlab`:",
    "- `cd ~/go-playground`",
    "- `go build -o cloudlab`",
    "- Quick test with `./cloudlab` to make sure it still runs on `:8080`.",
    "",
    "---",
    "### 2. Create the systemd unit file",
    {
      "type": "image",
      "src": "go_pics/cloudlab_service_unit.png",
      "alt": "nano showing the cloudlab.service systemd unit file"
    },
    "Then I created `/etc/systemd/system/cloudlab.service` with the following structure:",
    "- `[Unit]` section: description and dependencies, e.g. `After=network-online.target postgresql.service` so the database and network are ready.",
    "- `[Service]` section:",
    "  - `User=fynn` – run the service as my normal user.",
    "  - `WorkingDirectory=/home/fynn/go-playground` – where the binary lives.",
    "  - `ExecStart=/home/fynn/go-playground/cloudlab` – the actual Go server binary.",
    "  - `Restart=on-failure` – systemd restarts it if it crashes.",
    "- `[Install]` section: `WantedBy=multi-user.target` so it participates in the normal multi-user boot target.",
    "",
    "---",
    "### 3. Tell systemd about it and start it",
    "After saving the unit file, I ran:",
    "- `sudo systemctl daemon-reload` – let systemd re-read unit files.",
    "- `sudo systemctl start cloudlab.service` – start the service once.",
    "- `sudo systemctl status cloudlab.service` – check that it's `active (running)`.",
    "",
    {
      "type": "image",
      "src": "go_pics/cloudlab_service_status.png",
      "alt": "terminal output showing cloudlab.service active (running) and listening on :8080"
    },
    "Seeing it green and running feels much more like a \"real\" backend than just a `go run` process in a shell.",
    "",
    "---",
    "### 4. Enable autostart on boot",
    "To make the service come up after every reboot I enabled it:",
    "- `sudo systemctl enable cloudlab.service`",
    "",
    "This creates a symlink so that when the system reaches the `multi-user` target during boot, systemd automatically starts `cloudlab.service`.",
    "",
    "---",
    "### 5. Result",
    "- Now the flow is:",
    "  1. Press the power button on my old server PC.",
    "  2. Ubuntu boots, PostgreSQL starts, then `cloudlab.service` starts.",
    "  3. From my main machine I can go straight to `http://SERVER_IP:8080/login` without logging into the server first.",
    "- When I want to update the backend, I rebuild the binary and restart the service:",
    "  - `go build -o cloudlab`",
    "  - `sudo systemctl restart cloudlab.service`",
    "",
    "It’s a small change, but it makes the whole project feel much closer to how real services are run on servers."
  ],
  "date": "2025-12-11"
},
 {
  "title": "File Browser Foundation: A Filesystem-Backed Browser for My Go Cloud",
  "content": [
    "In my previous Go + PostgreSQL cloud lab posts I ended up with a small authenticated mini-app: a /login page, bcrypt password hashes, in-memory sessions, and a protected /todos endpoint backed by Postgres.",
    "In this post I move away from purely database-backed data and start treating my Linux server like a tiny private cloud: I pick a storage folder on disk, expose it via a new GET /api/files endpoint in Go, and build a simple /cloud page that lists folders and files. It’s still read-only, but it’s a real filesystem browser running over HTTP.",
    "The hero screenshot at the top of the post shows what I’m aiming for here: a dark-themed /cloud page with a toolbar and a list of folders and files (code, photos, notes.txt, readme.txt) coming directly from my storage directory on the server."
  ],
  "images": [
    "go_pics/cloud_files_ui.png"
  ],
  "description": [
    "### Context: From `/todos` JSON to a Filesystem Browser",
    "Up to now my Go lab was mostly about the database side: a /todos endpoint, a users table in PostgreSQL, bcrypt password hashing, sessions, and a login + logout flow. All of that is nice, but it doesn’t yet feel like the file-based \"cloud drive\" I actually want to build.",
    "For this step I decided to ignore the database for a moment and treat a plain directory on my Ubuntu server as the root of a future cloud drive. The Go server should:",
    "- treat a fixed directory like `/home/fynn/cloud-storage` as a storage root,",
    "- expose a GET /api/files?path=/... endpoint that returns JSON,",
    "- protect it with the same session/cookie mechanism I already use for /todos,",
    "- and render a small /cloud page that consumes this JSON and shows a list of entries.",
    {
      "type": "image",
      "src": "go_pics/cloud_files_ui.png",
      "alt": "Browser screenshot of the /cloud page showing the dark themed toolbar and file list loaded from the Go backend"
    },
    "The screenshot above (`go_pics/cloud_files_ui.png`) shows the result: the browser is on /cloud, the toolbar is at the top, and the list below is populated from the Go backend calling into the filesystem.",

    "---",
    "### 1. Storage Root and the `FileEntry` Type",
    "First I picked a folder on the server that should act as the root of my little cloud. On my Ubuntu box that is:",
    "- `/home/fynn/cloud-storage`",
    "I created it once on the server and then referenced it in Go as a constant right next to my global `db` and `sessions` variables.",
    "At the same time I introduced a simple struct that describes a single directory entry for the frontend: `FileEntry`. It has four fields: name, path, type (file or dir) and size in bytes.",
    "The screenshot below shows the relevant part of `main.go` in my editor: the `FileEntry` struct with JSON tags and the `storageRoot` constant underneath it.",

    {
      "type": "image",
      "src": "go_pics/cloud_fileentry_storage_root.png",
      "alt": "Editor screenshot showing the FileEntry struct with Name, Path, Type and Size fields plus JSON tags, and the storageRoot constant set to /home/fynn/cloud-storage underneath the global db and sessions variables"
    },

    "The JSON tags on `FileEntry` ensure that the JSON response has lower-case field names (`name`, `path`, `type`, `size`), which is more idiomatic for APIs. The `Path` field is always relative to the storage root, starting with a single leading slash, for example `/photos/cat.png`.",

    "---",
    "### 2. Implementing `GET /api/files` in Go",
    "With the struct and storage root in place, the next step is the core backend endpoint: GET /api/files. The idea is simple:",
    "- the client passes a `path` query parameter that is always relative to the storage root,",
    "- the handler resolves that path under `storageRoot`,",
    "- it reads the directory entries using `os.ReadDir`,",
    "- and it returns a JSON array of `FileEntry` objects.",
    "Because the same server already hosts a login feature, I reuse the session logic from there: /api/files is only reachable if the request carries a valid `session_id` cookie that exists in the in-memory `sessions` map.",
    "The first half of `apiFilesHandler` deals with authentication, HTTP method checking and path sanitizing. The screenshot below shows this upper half of the handler in my editor:",

    {
      "type": "image",
      "src": "go_pics/cloud_apifileshandler_top.png",
      "alt": "Editor screenshot showing the upper half of apiFilesHandler: it reads the session_id cookie, checks the sessions map, rejects non-GET methods, reads the path query parameter, normalizes it with filepath.Clean and blocks any paths that contain .. segments before joining it with storageRoot"
    },
    {
      "type": "image",
      "src": "go_pics/cloud_apifileshandler_bottom.png",
      "alt": "Editor screenshot showing the lower half of apiFilesHandler: it calls os.ReadDir on the computed fullPath, iterates over entries, calls entry.Info(), decides between type file or dir, builds the relative path, appends FileEntry values to a slice and finally encodes the slice as JSON with the application/json Content-Type set"
    },

    "The handler starts by reading the `session_id` cookie from the request and checking the ID in the `sessions` map. If there is no cookie or the ID is unknown, it simply redirects back to /login. That way, the filesystem API is only usable after a successful login.",
    "Then it enforces that only GET is allowed, because this endpoint is purely for reading. Any other HTTP method gets a 405 Method Not Allowed.",
    "The next interesting bit is the path handling. The handler reads the `path` query parameter from the URL (for example `/`, `/photos`, `/code/snippets`) and normalizes it with `filepath.Clean`. Internally, an empty path or `/` is mapped to `.` to represent the storage root. To avoid path traversal attacks, the code explicitly rejects any path that equals `..`, starts with `../` or contains `/../` anywhere.",
    "Only after this cleaning step does the handler join `storageRoot` and the cleaned relative path using `filepath.Join`, giving it a safe absolute path on disk.",
    "Once the absolute path is known, the lower half of the handler calls `os.ReadDir` to list directory contents. For each entry it calls `entry.Info()` to obtain metadata, checks `entry.IsDir()` to decide the `type` field (`file` or `dir`), calculates the relative path under the storage root, and appends a `FileEntry` value to a slice. At the end the handler sets `Content-Type: application/json` and uses `json.NewEncoder(w).Encode(files)` to stream the slice to the client as JSON.",

    "---",
    "### 3. Cloud Page Handler and Static Files",
    "To turn the filesystem API into something nice to look at, I added a new route `/cloud`. This route does not return JSON; it simply serves an HTML file that lives under `static/cloud.html` and contains a minimal frontend.",
    "In `main()` I already had a file server for everything under `./static` and routes for `/login`, `/todos` and `/logout`. I added another handler registration:",
    "- `/api/files` → `apiFilesHandler` (the JSON API),",
    "- `/cloud` → `cloudPageHandler` (the HTML UI).",
    "The `cloudPageHandler` itself is intentionally small: it only allows GET, checks the `session_id` cookie using the same `sessions` map logic as other handlers, and then calls `http.ServeFile` to return `static/cloud.html`.",
    "The screenshot below shows the full `cloudPageHandler` function in my editor:",

    {
      "type": "image",
      "src": "go_pics/cloud_page_handler.png",
      "alt": "Editor screenshot of cloudPageHandler showing the GET method check, the session_id cookie lookup and sessions map validation, and the final http.ServeFile call that serves static/cloud.html"
    },

    "By protecting `/cloud` with the same session logic as `/api/files`, I make sure that both the HTML UI and the JSON API are only usable for logged-in users. After fixing my login redirect to point to `/cloud` instead of `/todos`, a successful login drops me straight onto the new cloud view.",

    "---",
    "### 4. Inspecting `/api/files` Directly in the Browser",
    "Before wiring up any frontend JavaScript I like to test backend endpoints directly in the browser. Because `/api/files` returns JSON and is protected by the session cookie, it is perfect for that.",
    "After logging in, I can manually navigate to `/api/files?path=/` and see the JSON response for the root of my storage directory. It contains one object per file or folder, with the fields defined by `FileEntry`.",
    "The screenshot below shows this JSON response in the browser: it lists my `code` and `photos` folders plus `notes.txt` and `readme.txt` as files, each with a `name`, `path`, `type` and `size` field.",

    {
      "type": "image",
      "src": "go_pics/cloud_api_files_json.png",
      "alt": "Browser screenshot of the /api/files?path=/ endpoint showing a prettified JSON array with entries for code, notes.txt, photos and readme.txt including name, path, type and size fields"
    },

    "This direct view is especially helpful while debugging path handling and permissions: if something is wrong with my path cleaning or filesystem permissions, I immediately see an error instead of an empty UI.",

    "---",
    "### 5. A Simple `/cloud` UI on Top of the API",
    "With `/api/files` working and `/cloud` serving an HTML shell, I added a very small frontend on top:",
    "- `static/cloud.html` defines the basic layout: a dark header with the current path label (for now I keep the technical \"Path: /\" look), two buttons for future features (Upload File, Refresh), and an empty container for the file list.",
    "- `static/cloud.css` gives it a simple modern look: dark background, rounded bars for each row, subtle hover effects.",
    "- `static/cloud.js` contains a tiny amount of vanilla JavaScript that calls GET /api/files?path=/ when the page loads, parses the JSON and renders one row per `FileEntry`. Double-clicking on a directory row calls /api/files with the corresponding path to navigate deeper.",
    "Because this series is primarily about Go and backend concepts, I’m not showing the full HTML/CSS/JS code here. The important part is that the /cloud UI is just a thin layer on top of the Go endpoint: all file information comes from `/api/files`, and all access control logic still lives on the server.",
    "The screenshot above is exactly this UI in action: each row in the list corresponds to a `FileEntry` produced by the Go handler, and the text `Path: /` is driven by the current path that the JavaScript passes into the endpoint.",

    "---",
    "### 6. Limitations and Next Steps",
    "Right now, my little cloud is purely a filesystem viewer:",
    "- `/api.files` only supports GET and only lists entries,",
    "- there is no way to upload, download, rename or delete anything yet,",
    "- and there is no thumbnail generation for images or any kind of preview mode.",
    "That’s intentional: I wanted a solid, well-understood foundation first. I now have:",
    "- a dedicated storage root on disk,",
    "- a simple `FileEntry` model,",
    "- a secure, session-protected JSON API for listing directories,",
    "- and a `/cloud` page that consumes this API and shows real files from my server.",
    "From here the path is clear. In future posts I plan to build on this file browser foundation and add:",
    "- a POST /api/upload endpoint plus download links,",
    "- a grid layout with thumbnails and a simple image preview overlay,",
    "- endpoints and UI actions for mkdir, rename and move,",
    "- and eventually a trash system and multi-select to make my Go cloud feel more like a real, personal drive."
  ],
  "date": "2025-12-12"
},
  {
  "title": "File Uploads & Downloads in My Go-Powered Cloud",
  "content": [
    "In the last post I built a read-only file browser for my Go + PostgreSQL cloud lab: a session-protected `/cloud` page and a `GET /api/files` endpoint that lists real files and folders from my `cloud-storage` directory on the server.",
    "In this post I finally turn that browser into a real cloud by adding file transfers: a `GET /api/download` endpoint for downloading files and a `POST /api/upload` endpoint for uploading new files into whatever folder I’m currently viewing in the UI. Both routes reuse the same session + path-safety logic from the previous post."
  ],
  "images": [],
  "description": [
    "### Context: From Read-Only Listing to Real File Transfers",
    "My first step toward a \"cloud drive\" was just listing files: the `/cloud` page called `GET /api/files?path=/...` and rendered whatever `FileEntry` structs the Go backend returned. That already felt nice, because I could navigate through a filesystem via HTTP and a simple UI.",
    "But a cloud that can only *see* files isn’t very useful. I now wanted two basic actions:",
    "- **Download** a file from the server to my browser.",
    "- **Upload** one or more local files into the directory I’m currently viewing.",
    "Everything should still be protected by my login system (session cookie + in-memory `sessions` map), and all paths should stay safely inside my `storageRoot` directory.",
    "",
    "---",
    "### 1. Downloading Files: `GET /api/download`",
    "The first new route is a download endpoint. The idea is simple:",
    "- the client calls `GET /api/download?path=/photos/cat.png`,",
    "- the server checks the session, cleans the path and verifies that it is a real file inside `storageRoot`,",
    "- and then streams the file with `http.ServeFile`.",
    "The screenshot below shows the complete `downloadHandler` in my `main.go`. At the top it performs the usual session check and enforces that only `GET` is allowed. Then it reads the `path` query parameter, normalizes it with `filepath.Clean`, strips any leading slash to get a relative path, blocks any `..` segments to prevent path traversal, joins it with `storageRoot`, and finally uses `os.Stat` to ensure the target exists and is not a directory. If everything looks good, it calls `http.ServeFile(w, r, fullPath)` to send the file back to the browser.",
    {
      "type": "image",
      "src": "go_pics/cloud_downloadhandler.png",
      "alt": "Editor screenshot of the full downloadHandler in Go, showing the session check, HTTP method check, path cleaning with filepath.Clean, path traversal protection, os.Stat call to verify the file, and final http.ServeFile call"
    },
    "A few important details:",
    "- I reuse the **session check** from other handlers: if the `session_id` cookie is missing or the ID is not in the `sessions` map, the handler redirects to `/login`.",
    "- I enforce `GET` with `if r.Method != http.MethodGet` so the endpoint is clearly read-only.",
    "- I treat the `path` parameter as a **logical cloud path** (like `/photos/cat.png`), then turn it into a relative path under `storageRoot` by cleaning it and trimming the leading slash.",
    "- I explicitly reject paths that equal `..`, start with `../` or contain `/../` anywhere, to avoid ever leaving the cloud directory.",
    "- I use `os.Stat` to decide between user errors and server errors: `os.IsNotExist(err)` becomes a 404 Not Found, other errors become a 500 Internal Server Error.",
    "",
    "One subtle but interesting point: I simply call `http.ServeFile` without setting a `Content-Disposition: attachment` header. That means the browser decides what to do with the file based on the `Content-Type`. For images and text files it usually opens a viewer in the tab; for unknown or binary types it tends to offer a download. For now that’s perfectly fine for my little lab.",
    "",
    "---",
    "### 2. Designing the Upload API: `POST /api/upload`",
    "For uploads I wanted something that fits well with a browser and is easy to reason about:",
    "- The request should be `multipart/form-data` (the standard for file uploads from HTML/JS).",
    "- There should be a **text field** called `path` that tells the server in which cloud folder to put the files.",
    "- There should be one or more **file fields** called `file` that contain the actual files.",
    "The high-level flow in the upload handler looks like this:",
    "1. Check session and enforce `POST` only.",
    "2. Parse the multipart form (`r.ParseMultipartForm`).",
    "3. Read the `path` form field, clean it and validate it (no `..`, no escaping `storageRoot`).",
    "4. Compute the target directory and ensure it exists (`os.MkdirAll`).",
    "5. Loop over all uploaded files, sanitize their names, skip existing files, and save the rest to disk.",
    "6. Respond with HTTP 204 No Content if everything went fine.",
    "The first half of the handler is responsible for authentication, parsing and path handling:",
    {
      "type": "image",
      "src": "go_pics/cloud_uploadhandler_top.png",
      "alt": "Editor screenshot of the upper half of uploadHandler: session and method checks, ParseMultipartForm call with a 32 MB memory limit, nil check for r.MultipartForm, reading the path form field, normalizing it with filepath.Clean, mapping / and . to the cloud root, blocking any .. segments, and joining the result with storageRoot to form uploadDir, plus MkdirAll to ensure the directory exists"
    },
    {
      "type": "image",
      "src": "go_pics/cloud_uploadhandler_bottom.png",
      "alt": "Editor screenshot of the lower half of uploadHandler: retrieving r.MultipartForm.File[\"file\"], looping over each FileHeader, using filepath.Base to sanitize the filename, opening the uploaded file as src, checking with os.Stat if the destination file already exists and skipping it if so, creating the destination file with os.Create, copying data with io.Copy, closing both files, and finally writing a 204 No Content status"
    },
    "Some key ideas in this handler:",
    "- **Session + method check**: just like `/api/files` and `/api/download`, `/api/upload` starts by checking the `session_id` cookie and restricting the method to `POST`. No anonymous uploads allowed.",
    "- **Multipart parsing**: `r.ParseMultipartForm(32 << 20)` tells Go to parse the `multipart/form-data` body and use up to 32 MiB of RAM for form data, spilling larger parts to temporary disk files. Afterwards, `r.FormValue(\"path\")` gives me the target folder and `r.MultipartForm.File[\"file\"]` gives me the list of uploaded files.",
    "- **Path normalization**: I treat an empty `path` or `/` as the cloud root (`\".\"` internally) and then run everything through `filepath.Clean`. If the cleaned path is just `/` I map it back to `\".\"`, and I reject anything with `..` segments. Finally, `filepath.Join(storageRoot, rel)` gives me a safe, absolute filesystem path that always stays under `storageRoot`.",
    "- **Ensuring the directory exists**: `os.MkdirAll(uploadDir, 0755)` is a safety net. If the target directory or any of its parents are missing, it creates them. If everything already exists, it does nothing. This makes the upload path more robust and plays nicely with future features like \"new folder\".",
    "",
    "---",
    "### 3. Saving Uploaded Files Safely",
    "The second half of `uploadHandler` actually moves bytes from the HTTP request into real files on disk. For each `*multipart.FileHeader` in `files := r.MultipartForm.File[\"file\"]` I do:",
    "- Get a clean filename with `filepath.Base(fh.Filename)` so I ignore any path components a browser or client might include. Only the final name like `cat.png` or `notes.txt` is allowed.",
    "- Skip weird or empty names such as `\"\"`, `\".\"` or `\"..\"`.",
    "- Call `fh.Open()` to get a `src` reader for the uploaded file contents.",
    "- Build a destination path `dstPath := filepath.Join(uploadDir, filename)`.",
    "- Use `os.Stat(dstPath)` to check if a file already exists there. If it does, I log a message and skip that upload instead of overwriting it.",
    "- Create the destination file with `os.Create(dstPath)` and get a writer `dst`.",
    "- Stream data from `src` to `dst` using `io.Copy(dst, src)`.",
    "- Close both `dst` and `src` when done.",
    "At the very end of the handler I send a `204 No Content` response:",
    "- No JSON body, no HTML, just a status that says: \"Upload succeeded.\"",
    "- On the frontend side I simply check `res.ok` and then call `loadFiles(currentPath)` to refresh the file list in the UI.",
    "",
    "---",
    "### 4. Wiring the Frontend: Upload Button & Click-to-Open",
    "On the frontend I only had to make relatively small changes to my existing `/cloud` page:",
    "- The HTML now contains a visible \"Upload File\" button and a hidden `<input type=\"file\" id=\"file-input\" multiple>` element.",
    "- When I click the button, JavaScript triggers `fileInput.click()`, which opens the standard file chooser dialog.",
    "- In the `change` event of the file input, I create a `FormData` instance, append the current cloud path under the `path` key, append each selected file under the `file` key, and send it to `POST /api/upload` using `fetch`. On success I reload the current folder with `loadFiles(currentPath)`, so the freshly uploaded files appear immediately.",
    "- For downloads, I attach a click handler to each file row that sets `window.location.href = \"/api/download?path=\" + encodeURIComponent(file.path)`.",
    "I still keep the frontend very small and focused: no progress bars, no drag & drop, no fancy previews yet. The point of this post is to understand how the Go handlers work and how the browser talks to them, not to build a perfect UI.",
    "",
    "---",
    "### 5. Security and Safety Considerations",
    "Even though this runs on an old home server and is only meant for my personal use, I tried to keep the upload and download paths reasonably safe:",
    "- All routes involved (`/api/files`, `/api/download`, `/api/upload`, `/cloud`) are protected by the same session cookie check that I use for `/todos`.",
    "- Every path the client sends is treated as a **relative cloud path**, cleaned with `filepath.Clean`, stripped of any leading slash and validated against `..` segments before it is joined with `storageRoot`.",
    "- Uploads cannot escape the cloud directory and cannot overwrite existing files (I explicitly skip any file where `os.Stat` finds an existing entry at that path).",
    "- The `MkdirAll` call only ever creates directories under `storageRoot`, never outside of it.",
    "This is not production-grade security yet (there is still no HTTPS, no per-user isolation for files and no rate limiting), but it’s already a good exercise in thinking about what can go wrong when you let users send you paths and files over HTTP.",
    "",
    "---",
    "### 6. Where I Want to Go Next",
    "With upload and download in place, my Go cloud finally feels like a tiny but real drive:",
    "- I can browse folders under `/home/fynn/cloud-storage` from `/cloud`.",
    "- I can upload new text files and images into any folder I have open in the UI.",
    "- I can click a file to open or download it through `/api/download`.",
    "The next steps are all about making this *nice* to use:",
    "- a grid layout for files and folders, more like Google Drive’s card view,",
    "- a preview overlay for images on double click,",
    "- a context menu per file/dir with options like Download, Rename, Move and Trash,",
    "- backend endpoints for mkdir, rename, move and trash,",
    "- and eventually a trash system plus multi-select.",
    "But for now I’m happy: my little Go server has evolved from a toy `/todos` JSON API into a session-protected, filesystem-backed cloud where files can actually move in and out."
  ],
  "date": "2025-12-14"
},
  {
  "title": "Adding \"New Folder\" to My Go Cloud File Browser",
  "content": [
    "In the last posts I built a basic Go-powered cloud: a login system with bcrypt and sessions, a /cloud page that lists files from a filesystem-backed storage root, and simple upload/download endpoints with a grid-style UI and image preview.",
    "The next natural step is to let the UI create folders. In this post I add a small POST /api/mkdir endpoint in Go, wire it to the \"+ New → New Folder\" menu in my /cloud page, and make sure the server validates paths properly so users cannot escape the storage root or create weird folder names.",
    "The hero screenshot at the top shows the new \"+ New\" dropdown in my cloud UI: when I click \"New Folder\" a browser prompt asks for the folder name, and after submitting the fresh folder appears as a card in the grid."
  ],
  "images": [
    "go_pics/cloud_new_folder_menu.png"
  ],
  "description": [
    "### 1. New Folder in the UI: + New → New Folder",
    "On the frontend I extended the existing \"+ New\" button in the /cloud toolbar with a small dropdown menu. It now has three entries:",
    "- New Folder",
    "- Upload File",
    "- Upload Folder (placeholder for later)",
    "When I click the button, the menu opens directly under it, similar to how Google Drive behaves. The screenshot below shows the menu in my cloud UI:",
    {
      "type": "image",
      "src": "go_pics/cloud_new_folder_menu.png",
      "alt": "Screenshot of the Go cloud UI showing a blue + New button with a dropdown menu containing New Folder, Upload File and Upload Folder"
    },
    "Clicking \"New Folder\" closes the menu and opens a simple browser prompt asking for the new folder name. This is deliberately simple for now; a nicer custom dialog can come later. The screenshot below shows that prompt:",
    {
      "type": "image",
      "src": "go_pics/cloud_new_folder_prompt.png",
      "alt": "Browser prompt dialog asking for Folder name with an example name testfolder typed into the input"
    },
    "If I cancel the prompt, nothing happens. If I confirm it with a non-empty name, the frontend sends a small JSON body to the Go server using fetch, calling the new /api/mkdir endpoint. After the request succeeds, the current folder is reloaded so the new directory appears in the grid.",

    "---",
    "### 2. Request Shape: `mkdirRequest` Struct",
    "To describe a \"create folder\" request on the backend, I added a tiny struct in main.go next to my other types. It models exactly what the client sends as JSON:",
    "- `Path`: the current folder in the UI, for example `/`, `/photos` or `/code/snippets`.",
    "- `Name`: the name for the new folder, for example `wallpapers`.",
    "The Go type looks like this:",
    "```go",
    "type mkdirRequest struct {",
    "    Path string `json:\"path\"` // current folder in the UI, e.g. \"/\" or \"/photos\"",
    "    Name string `json:\"name\"` // new folder name, e.g. \"wallpapers\"",
    "}",
    "```",
    "The JSON tags make sure that the payload from the frontend,",
    "",
    "```json",
    "{\"path\":\"/photos\",\"name\":\"wallpapers\"}",
    "```",
    "",
    "lands in the right fields without any extra work.",

    "---",
    "### 3. The `/api/mkdir` Handler: Validating Paths and Names",
    "The main logic lives in a new handler function `apiMkdirHandler`. It accepts only POST requests, checks the session cookie (same mechanism as /api/files and /api/upload), decodes the JSON body into `mkdirRequest`, validates everything and finally creates a directory with `os.Mkdir`.",
    "The next two screenshots show the complete handler in my editor. The first one covers method and session checks plus JSON parsing and normalizing the parent path:",
    {
      "type": "image",
      "src": "go_pics/cloud_mkdir_handler_top.png",
      "alt": "Editor screenshot showing the upper half of apiMkdirHandler with method check for POST, session_id cookie validation, JSON decoding into mkdirRequest, and cleaning the requested path while preventing path traversal"
    },
    {
      "type": "image",
      "src": "go_pics/cloud_mkdir_handler_bottom.png",
      "alt": "Editor screenshot showing the lower half of apiMkdirHandler where the parent directory is checked with os.Stat, the target directory path is built, existing folders cause a conflict error, and os.Mkdir is called to create the new folder followed by a 204 No Content response"
    },
    "Walking through the key steps:",
    "- **Method + session check**: if the request is not POST or the `session_id` cookie is missing/invalid, the handler returns HTTP 401 Unauthorized or 405 Method Not Allowed.",
    "- **Decode JSON body**: `json.NewDecoder(r.Body).Decode(&req)` reads the JSON payload directly into a `mkdirRequest` value. If the JSON is malformed, the handler returns 400 Bad Request with the message `Invalid JSON body`.",
    "- **Normalize the parent path**:",
    "  - if `req.Path` is empty or `/`, I treat it as the storage root by mapping it to `\".\"`,",
    "  - otherwise I run `filepath.Clean` on it and then strip any leading `/` so that I can safely join it under `storageRoot`.",
    "- **Block path traversal**: if the cleaned path equals `..`, starts with `../` or contains `/../` anywhere, the handler immediately returns 400 with `Invalid path`. This prevents someone from trying to create folders outside of `/home/fynn/cloud-storage`.",
    "- **Validate folder name**: I call `strings.TrimSpace(req.Name)` to remove leading/trailing spaces and then reject names that are empty, `.` or `..`, or that contain `/` or `\\`. That keeps folder names simple and avoids odd or dangerous values.",
    "- **Check parent directory**: before creating anything, I call `os.Stat(parentDir)` and ensure that the parent actually exists and is a directory. If it does not exist, the handler returns 400 with `Parent directory does not exist`.",
    "- **Check if target already exists**: `os.Stat(targetDir)` is used again for the full path. If it returns `err == nil`, the folder (or a file with that name) already exists and the handler responds with 409 Conflict. If the error is something other than “does not exist”, I log it and respond with 500 Internal Server Error.",
    "- **Create the folder**: only when all checks pass, I call `os.Mkdir(targetDir, 0755)`. On success the handler responds with `w.WriteHeader(http.StatusNoContent)`, meaning the HTTP status is 204 No Content and the frontend does not get a response body.",

    "---",
    "### 4. Wiring It Up in `main()`",
    "To expose the new endpoint, I registered a route in `main()` alongside the other API handlers:",
    "```go",
    "http.HandleFunc(\"/api/files\", apiFilesHandler)",
    "http.HandleFunc(\"/api/download\", downloadHandler)",
    "http.HandleFunc(\"/api/upload\", uploadHandler)",
    "http.HandleFunc(\"/api/mkdir\", apiMkdirHandler)",
    "```",
    "This keeps the structure nice and consistent: all filesystem operations live under `/api/*` and share the same session logic and path-cleaning approach.",

    "---",
    "### 5. Frontend Wiring: Calling `/api/mkdir` from `cloud.js`",
    "On the JavaScript side, the `New Folder` menu item is hooked up to an async click handler. When I click it, the code:",
    "- closes the dropdown,",
    "- calls `prompt(\"Folder name:\")`,",
    "- and if the user entered a non-empty name, sends a POST request to `/api/mkdir` with a JSON body containing:",
    "  - `path`: the `currentPath` from the UI (like `/` or `/photos`),",
    "  - `name`: the folder name from the prompt.",
    "In pseudocode, the logic looks like this:",
    "```js",
    "menuNewFolder.addEventListener(\"click\", async () => {",
    "  newMenu.classList.add(\"hidden\");",
    "  const name = prompt(\"Folder name:\");",
    "  if (!name) return;",
    "",
    "  const res = await fetch(\"/api/mkdir\", {",
    "    method: \"POST\",",
    "    headers: { \"Content-Type\": \"application/json\" },",
    "    body: JSON.stringify({",
    "      path: currentPath,",
    "      name: name,",
    "    }),",
    "  });",
    "",
    "  if (res.status === 401) {",
    "    window.location.href = \"/login\";",
    "    return;",
    "  }",
    "",
    "  if (!res.ok) {",
    "    alert(\"Could not create folder (\" + res.status + \").\");",
    "    return;",
    "  }",
    "",
    "  await loadFiles(currentPath);",
    "});",
    "```",
    "Because the handler returns 204 No Content on success, the frontend simply reloads the file list for the current folder. The new directory appears as another card in the grid view.",

    "---",
    "### 6. Result and Next Steps",
    "With the `New Folder` feature in place, my Go cloud feels less like a static viewer and more like a real file manager:",
    "- I can create folder structures directly from the browser,",
    "- the Go backend guards paths carefully to keep everything inside `/home/fynn/cloud-storage`,",
    "- and the same session system protects this endpoint just like the others.",
    "The implementation is intentionally conservative: lots of validation, clear HTTP status codes, and a very simple frontend interaction via `prompt`. Later on I plan to replace the prompt with a styled modal dialog and add more file operations:",
    "- renaming files and folders,",
    "- moving entries between folders,",
    "- adding a trash system (soft delete instead of immediate removal),",
    "- and eventually multi-select plus drag & drop, similar to how Google Drive behaves.",
    "But even in this minimal form, \"New Folder\" closes an important gap: I can now organize my private Go-powered cloud directly from the web UI without ever SSHing into the server."
  ],
  "date": "2025-12-15"
}


]
