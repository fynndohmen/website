[
{
  "title": "Turning an Old PC into a Go + PostgreSQL Cloud Lab",
  "content": [
    "This project is my first real step into the world of backend development, cloud-like setups, and databases using Go. I took an old i3 PC with 4GB RAM, installed Ubuntu Server on it, and turned it into a small home lab that exposes a JSON API built with Go and backed by a PostgreSQL database.",
    "The main goal was not just to get something working, but to really understand what each piece does: Linux as a server, PostgreSQL as a database server, Go as the HTTP backend, and how they all talk to each other over TCP, HTTP, and SQL."
  ],
  "images": [],
  "description": [
    "### Goal & Overview",
    "- **Goal:** Turn an old PC into a small backend \"cloud lab\" with Go and PostgreSQL, and use it to learn how HTTP servers, databases, and contexts work together.",
    "- **Tech stack:**",
    "  - Ubuntu LTS on a repurposed i3 desktop as a headless server",
    "  - PostgreSQL as the database server",
    "  - Go (`net/http` + `database/sql` + `pgx` driver) as the HTTP API backend",
    "",
    "---",
    "### 1. Hardware & Linux Setup",
    {
      "type": "image",
      "src": "go_pics/server-ssh-setup.png",
      "alt": "SSH connection to the Ubuntu Go server"
    },
    "- I reused an old i3 PC with ~4GB RAM and installed **Ubuntu Server LTS** instead of a desktop environment.",
    "- The idea: keep it headless and manage everything over **SSH** from my main machine.",
    "- Steps:",
    "  - Create a bootable USB stick with the Ubuntu LTS ISO.",
    "  - Install Ubuntu with no GUI, only OpenSSH server enabled.",
    "  - Give the server a static IP or make sure I can consistently reach it via `ssh user@server-ip`.",
    "- Result: I can now power on the \"server PC\", and from my main computer connect only via SSH – no screen, no keyboard needed on the server itself.",
    "",
    "---",
    "### 2. PostgreSQL as the Database Server",
    {
      "type": "image",
      "src": "go_pics/psql-todos-table.png",
      "alt": "psql view of the todos table in the cloudlab database"
    },
    "- On the Ubuntu server, I installed PostgreSQL and created:",
    "  - a **user** (role) for my Go app,",
    "  - a **database** called `cloudlab`,",
    "  - and a **table** called `todos`.",
    "- The `todos` table has four columns:",
    "  - `id` (integer primary key),",
    "  - `title` (text),",
    "  - `done` (boolean, default `false`),",
    "  - `created_at` (timestamp with timezone, default `NOW()`).",
    "- I tested everything directly in `psql` by inserting a couple of rows and running `SELECT * FROM todos;` to see the result.",
    "",
    "---",
    "### 3. Go Project Structure & Database Connection",
    {
      "type": "image",
      "src": "go_pics/go-code-part1.png",
      "alt": "First part of the Go code: imports, Todo struct, main and database setup"
    },
    {
      "type": "image",
      "src": "go_pics/go-code-part2.png",
      "alt": "Second part of the Go code: getTodosHandler with context, query, loop and JSON response"
    },
    "- On the Go side, I created a small project with a single `main.go` file.",
    "- At the top there is the usual `package main` and an import block that pulls in:",
    "  - `net/http` for the web server,",
    "  - `database/sql` for database access,",
    "  - `encoding/json` to send JSON responses,",
    "  - `context` and `time` for timeouts,",
    "  - and the `pgx` driver via `_ \"github.com/jackc/pgx/v5/stdlib\"`.",
    "- I defined a `Todo` struct that mirrors the database columns (`id`, `title`, `done`, `created_at`) and added JSON tags so that the JSON field names match what I want to expose in the API.",
    "- The database handle is a global `var db *sql.DB`, which in Go represents a connection **pool** that `database/sql` manages for me (not just a single connection).",
    "",
    "---",
    "### 4. DSN, `sql.Open` and `db.Ping()`",
    "- To connect Go to PostgreSQL, I use a DSN (data source name) URL that looks like:",
    "  - `postgres://user:password@host:5432/cloudlab?sslmode=disable`",
    "- In `main()` I call `sql.Open(\"pgx\", dsn)` to initialize the DB handle using the `pgx` driver.",
    "- I immediately follow that with `db.Ping()` to actively check that the connection really works (credentials, host, port, database name).",
    "- If either step fails, the program logs the error and exits, so I know early that something is wrong with the setup.",
    "",
    "---",
    "### 5. HTTP Server, Routing and Handlers",
    "- For the HTTP side I use the standard library's `net/http` package.",
    "- In `main()` I register the `/todos` route using `http.HandleFunc(\"/todos\", getTodosHandler)`. This tells Go:",
    "  - \"Whenever a request comes in on `/todos`, call `getTodosHandler` and pass it a `ResponseWriter` plus the `*Request`.\"",
    "- Finally, `http.ListenAndServe(\":8080\", nil)` starts the HTTP server on port 8080 and blocks:",
    "  - It listens for incoming TCP connections,",
    "  - parses HTTP requests,",
    "  - and forwards them to the correct handler based on the path.",
    "",
    "---",
    "### 6. Request Handling, Context and Database Query",
    "- The core of the API is the `getTodosHandler` function (shown in the second Go screenshot above). The rough flow is:",
    "  1. Create a context with a timeout using `context.WithTimeout(r.Context(), 5*time.Second)`. That way, the database query will be cancelled if it takes too long or the client disconnects.",
    "  2. Call `db.QueryContext(ctx, \"SELECT id, title, done, created_at FROM todos ORDER BY id\")` to fetch all todos from the database using that context.",
    "  3. Loop over the returned rows with `rows.Next()` and use `rows.Scan(&t.ID, &t.Title, &t.Done, &t.CreatedAt)` to fill a `Todo` struct for each row.",
    "  4. Append each `Todo` to a slice until there are no more rows and also check `rows.Err()` for any errors that happened during iteration.",
    "  5. Set the response header `Content-Type` to `application/json`.",
    "  6. Use `json.NewEncoder(w).Encode(todos)` to encode the slice of todos as JSON and stream it directly into the HTTP response body.",
    "- The handler does its own error handling at each step and returns appropriate HTTP status codes if something goes wrong (e.g. `500 Internal Server Error` for DB or JSON issues).",
    "",
    "---",
    "### 7. JSON API Endpoint in the Browser",
    {
      "type": "image",
      "src": "go_pics/todos-endpoint-browser.png",
      "alt": "Browser showing the JSON response from the /todos endpoint"
    },
    "- With the Go server running, a simple GET request to `/todos` returns a JSON array of todo objects.",
    "- The screenshot above shows the JSON response in the browser: each object has `id`, `title`, `done` and `created_at` fields coming directly from the database via the Go handler.",
    "- This output can be consumed by anything: a frontend app, `curl`, Postman, or even another service.",
    "",
    "---",
    "### 8. Learning Takeaways",
    "- From this small project I learned:",
    "  - How to turn an old PC into a headless Ubuntu server and manage it via SSH.",
    "  - The difference between PostgreSQL as a **database server**, a **database** (e.g. `cloudlab`) and a **table** (e.g. `todos`).",
    "  - How Go's `database/sql` package uses a driver (`pgx`) and a DSN to connect to PostgreSQL.",
    "  - How HTTP handlers work in Go (`http.HandleFunc`, `ResponseWriter`, `*Request`).",
    "  - What a `context.Context` is, and how timeouts and cancellation signals flow through to database queries.",
    "  - How to stream query results into Go structs and return them as clean JSON to a browser or API client.",
    "",
    "- This is just the starting point. From here I can extend the API with `POST /todos`, authentication, more tables, or even deploy a similar Go + PostgreSQL setup on a real cloud provider later."
  ],
  "date": "2025-12-06"
}
,
{
  "title": "Adding Login, bcrypt and Sessions to My Go + PostgreSQL Cloud Lab",
  "content": [
    "This post builds on top of my first Go + PostgreSQL cloud lab, where I exposed a /todos endpoint backed by a Postgres database.",
    "Here I turn that open endpoint into a simple authenticated mini-app: I add a users table, hash passwords with bcrypt, create sessions with secure random IDs and cookies, protect /todos so it only works after login, and add a basic logout route."
  ],
  "images": [
    "go_pics/go_login_overview.png"
  ],
  "description": [
    "### Context: From Open `/todos` to a Real Login",
    "In the first version of my Go cloud lab, `/todos` was completely open: if you knew the server IP and port, you could just call `/todos` and get the JSON list of todos.",
    "That was okay for a private learning setup, but not for anything that even remotely looks like a real app.",
    "In this iteration I added:",
    "- A `users` table in PostgreSQL",
    "- Password hashing using bcrypt (no more plaintext passwords in the DB)",
    "- A `/login` handler in Go that checks username + password",
    "- A tiny in-memory session store using a map",
    "- A `session_id` cookie that the browser sends with every request",
    "- A `/logout` route that kills the session and clears the cookie.",
    "The hero screenshot at the top of the post (`go_login_overview.png`) shows my setup: VS Code with `main.go` on the left and the login page running in the browser on the right.",

    "---",
    "### 1. Users Table and Password Hashes",
    "First, I added a `users` table to my existing `cloudlab` database. The important part is that I store a password hash, not the raw password.",
    "The screenshot below shows the users table in `psql`: the table definition with `id`, `username`, `password_hash`, `created_at`, plus one row for the user `fynn` with a long bcrypt hash in the `password_hash` column.",

    {
      "type": "image",
      "src": "go_pics/users_table_psql.png",
      "alt": "psql screenshot showing the users table with id, username and password_hash columns and one row for user fynn"
    },

    "To generate these hashes I wrote a tiny helper program in Go. It takes a string password, calls bcrypt to hash it and prints the result. I run this once, copy the output and paste it into the `password_hash` column in PostgreSQL.",
    "The next screenshot shows this helper file in VS Code:",

    {
      "type": "image",
      "src": "go_pics/bcrypt_helper_code.png",
      "alt": "VS Code screenshot of a small Go program that imports bcrypt, defines a password, calls GenerateFromPassword and prints the resulting hash"
    },

    "Inside my main Go server, I had to pull in bcrypt as a new dependency. In the import block of `main.go` I added one extra line for the bcrypt package, which is highlighted in the following screenshot:",

    {
      "type": "image",
      "src": "go_pics/bcrypt0.png",
      "alt": "VS Code screenshot of the import block in main.go with the golang.org/x/crypto/bcrypt import highlighted"
    },

    "In the login handler I then use bcrypt to compare the password the user typed with the stored hash from the database. Instead of comparing plain strings, the handler now calls `bcrypt.CompareHashAndPassword`. If that returns an error, the login fails.",
    "The bcrypt comparison is visible in this snippet from the POST branch of the login handler (highlighted in red in the screenshot):",

    {
      "type": "image",
      "src": "go_pics/bcrypt1.png",
      "alt": "VS Code screenshot of the login handler section where bcrypt.CompareHashAndPassword is called to verify the password"
    },

    "---",
    "### 2. Login Page: HTML, CSS and Routing",
    "For the UI I kept things minimal: a simple HTML form served from `static/login.html` plus a small CSS file for styling.",
    "The HTML file defines a basic page with a title, a link to `static/login.css` and a form that posts to `/login` using the POST method. The form has two fields (`username` and `password`) and a submit button.",
    "The next screenshot shows the relevant part of `login.html` in VS Code:",

    {
      "type": "image",
      "src": "go_pics/login_html_code.png",
      "alt": "VS Code screenshot of login.html showing the Cloud Login title and the POST form with username and password inputs"
    },

    "When I point my browser at `/login`, I see the styled login box with two input fields and a login button, as shown here:",

    {
      "type": "image",
      "src": "go_pics/login_page_browser.png",
      "alt": "Browser screenshot of the Cloud Login page with username and password fields and a blue login button"
    },

    "On the Go side, I needed to wire the static files and the new `/login` route into `main()`. I use `http.FileServer` to serve everything under `./static` and then register three handlers: `/login`, `/todos` and `/logout`.",
    "The screenshot below shows the part of `main()` where the file server and the three routes are registered. The new lines are highlighted:",

    {
      "type": "image",
      "src": "go_pics/login0.png",
      "alt": "VS Code screenshot of main.go showing the http.FileServer for ./static and the HandleFunc registrations for /login, /todos and /logout, with this block highlighted"
    },

    "The core logic for handling logins lives in `loginPageHandler`. It acts as both a GET and a POST handler:",
    "- `GET /login` serves the HTML file.",
    "- `POST /login` reads the form fields, queries the `users` table and then runs the bcrypt check.",
    "The next screenshot shows the upper part of `loginPageHandler`: the method switch, the GET branch that serves `static/login.html` and the POST branch that parses the form, reads `username` and `password` and performs the database query. This is all highlighted so you can see how the handler is structured:",

    {
      "type": "image",
      "src": "go_pics/login1.png",
      "alt": "VS Code screenshot of the upper part of loginPageHandler showing the method switch, the GET branch and the POST branch that parses the form and queries the users table"
    },

    "At the end of the POST branch, once the password has been verified, the handler creates a session and sets a cookie before redirecting to `/todos`. That session and cookie logic is part of the next section, but you can already see it in context here:",

    {
      "type": "image",
      "src": "go_pics/login2.png",
      "alt": "VS Code screenshot of the lower part of loginPageHandler showing the code that generates a session ID, stores it in the map, sets the session_id cookie and redirects to /todos"
    },

    "---",
    "### 3. Sessions and Cookies in Go",
    "To remember that a client is logged in, I added a very small in-memory session store and a helper to generate secure random session IDs.",
    "First, I pulled in two extra packages in the import block of `main.go`: `crypto/rand` for secure random bytes and `encoding/hex` to turn them into a human-readable string. These imports are highlighted in the following screenshot:",

    {
      "type": "image",
      "src": "go_pics/cookies&sessions0.png",
      "alt": "VS Code screenshot of the imports in main.go with crypto/rand and encoding/hex highlighted"
    },

    "Then I declared a global map `sessions` and added a function `generateSessionID()` which uses `rand.Read` to fill a 32-byte slice with random data and encodes it as a hex string. This gives me a random session ID that is hard to guess.",
    "The next screenshot shows the new global `sessions` map and the `generateSessionID` helper directly under the `Todo` struct. The new code is outlined in red:",

    {
      "type": "image",
      "src": "go_pics/cookies&sessions1.png",
      "alt": "VS Code screenshot showing the global sessions map and the generateSessionID function highlighted under the Todo struct"
    },

    "The final step is to create a session after a successful login and send it back to the browser in a cookie. In the POST branch of `loginPageHandler`, after bcrypt has accepted the password, I:",
    "- call `generateSessionID()` to get a new ID,",
    "- store `sessionID -> userID` in the `sessions` map,",
    "- and send a `session_id` cookie with `HttpOnly` set to true.",
    "The screenshot below shows this block of code inside the login handler, with the new session-related lines highlighted:",

    {
      "type": "image",
      "src": "go_pics/cookies&sessions2.png",
      "alt": "VS Code screenshot of loginPageHandler where the session ID is generated, stored in the sessions map, and written into an HttpOnly session_id cookie, all highlighted"
    },

    "From this point on, every request from that browser will carry the `session_id` cookie. The next step is to protect `/todos` using that information.",

    "---",
    "### 4. Protecting `/todos` with a Session Check",
    "Originally, `/todos` was wide open: anyone who knew the URL could hit it and see the JSON response. Now I want it to only work for logged-in users who have a valid session.",
    "To achieve that, I added a session check at the very top of `getTodosHandler`:",
    "- It tries to read the `session_id` cookie from the request.",
    "- If there is no cookie, it redirects to `/login`.",
    "- If there is a cookie, it looks up the session ID in the `sessions` map.",
    "- If the session ID is unknown, it also redirects to `/login`.",
    "Only if both checks pass does the handler continue with the existing database query and JSON response.",
    "The next screenshot shows the top of `getTodosHandler`: the new cookie and session checks are highlighted in red, with the existing database and JSON code visible underneath for context:",

    {
      "type": "image",
      "src": "go_pics/protecttodos.png",
      "alt": "VS Code screenshot of getTodosHandler showing the new session_id cookie lookup and sessions map check highlighted above the existing database query and JSON response code"
    },

    "In practice this means: if I open a fresh browser (no cookies) and try to access `/todos` directly, the server responds with a redirect to `/login`. Only after logging in and receiving a valid `session_id` cookie can I successfully call `/todos`.",

    "---",
    "### 5. Logout: Killing the Session and Clearing the Cookie",
    "To avoid staying logged in forever in one browser session, I added a simple `/logout` route that cleans up both the server-side session and the client-side cookie.",
    "First, I registered the new route in `main()` alongside the existing `/login` and `/todos` handlers. The highlighted line in the next screenshot shows the `HandleFunc` call for `/logout`:",

    {
      "type": "image",
      "src": "go_pics/logout0.png",
      "alt": "VS Code screenshot of main.go with the http.HandleFunc call that registers the /logout route highlighted"
    },

    "The actual logic lives in `logoutHandler`. It does three things:",
    "- Tries to read the `session_id` cookie from the request.",
    "- If it exists, removes the corresponding entry from the `sessions` map.",
    "- Sends a new `session_id` cookie with an empty value and `MaxAge: -1` so that the browser deletes it.",
    "The screenshot below shows the whole `logoutHandler` function, with its core logic clearly visible:",

    {
      "type": "image",
      "src": "go_pics/logout1.png",
      "alt": "VS Code screenshot of logoutHandler showing how the session_id cookie is read, the sessions entry deleted, a new empty cookie with MaxAge -1 set, and a redirect to /login performed"
    },

    "After visiting `/logout` in the browser, I am redirected back to `/login`. Any further request to `/todos` behaves as if I had never logged in: the handler checks the cookie and the sessions map, finds nothing valid and responds with another redirect to `/login`.",

    "---",
    "### 6. Limitations & Next Steps",
    "This is still a learning project, so there are a few things I am aware of:",
    "- Sessions are stored in memory. When I restart the Go server, all sessions are gone and existing cookies become invalid.",
    "- I don't use HTTPS yet. For something exposed to the public internet I would put a reverse proxy (like Caddy or Nginx) with TLS in front and set the `Secure` flag on the cookie.",
    "- There is no rate limiting, CSRF protection or per-user todos yet.",
    "",
    "But for a personal cloud lab running on an old Linux box, this setup already feels much more like a real app compared to the original open `/todos` endpoint:",
    "- passwords are hashed with bcrypt,",
    "- `/todos` is only reachable after a successful login,",
    "- and I can explicitly log out to drop the session.",
    "",
    "In the next iteration I might:",
    "- build a small HTML dashboard that consumes the `/todos` JSON and shows it nicely,",
    "- add per-user todos by linking the `todos` table to `users`,",
    "- and move sessions from the in-memory map into the database."
  ],
  "date": "2025-12-09"
},
  {
  "title": "Running my Go Cloudlab as a systemd Service",
  "content": [
    "After building my first Go + PostgreSQL cloud lab, I still had to start the server manually with `go run .` or by running the binary. In this mini step I turned my Go program into a proper systemd service so it starts automatically when the server boots.",
    "Now I can just press the power button on my old Ubuntu box and my Go backend comes up on port 8080 without any manual login."
  ],
  "images": [
    "go_pics/cloudlab_service_status.png"
  ],
  "description": [
    "### Goal",
    "- Make the Go HTTP server start automatically on boot, just like PostgreSQL.",
    "- Run it as a normal Linux service managed by **systemd**, not as a random process started in an SSH session.",
    "",
    "---",
    "### 1. Build the Go binary",
    "On the server I went into my Go project folder and built a binary called `cloudlab`:",
    "- `cd ~/go-playground`",
    "- `go build -o cloudlab`",
    "- Quick test with `./cloudlab` to make sure it still runs on `:8080`.",
    "",
    "---",
    "### 2. Create the systemd unit file",
    {
      "type": "image",
      "src": "go_pics/cloudlab_service_unit.png",
      "alt": "nano showing the cloudlab.service systemd unit file"
    },
    "Then I created `/etc/systemd/system/cloudlab.service` with the following structure:",
    "- `[Unit]` section: description and dependencies, e.g. `After=network-online.target postgresql.service` so the database and network are ready.",
    "- `[Service]` section:",
    "  - `User=fynn` – run the service as my normal user.",
    "  - `WorkingDirectory=/home/fynn/go-playground` – where the binary lives.",
    "  - `ExecStart=/home/fynn/go-playground/cloudlab` – the actual Go server binary.",
    "  - `Restart=on-failure` – systemd restarts it if it crashes.",
    "- `[Install]` section: `WantedBy=multi-user.target` so it participates in the normal multi-user boot target.",
    "",
    "---",
    "### 3. Tell systemd about it and start it",
    "After saving the unit file, I ran:",
    "- `sudo systemctl daemon-reload` – let systemd re-read unit files.",
    "- `sudo systemctl start cloudlab.service` – start the service once.",
    "- `sudo systemctl status cloudlab.service` – check that it's `active (running)`.",
    "",
    {
      "type": "image",
      "src": "go_pics/cloudlab_service_status.png",
      "alt": "terminal output showing cloudlab.service active (running) and listening on :8080"
    },
    "Seeing it green and running feels much more like a \"real\" backend than just a `go run` process in a shell.",
    "",
    "---",
    "### 4. Enable autostart on boot",
    "To make the service come up after every reboot I enabled it:",
    "- `sudo systemctl enable cloudlab.service`",
    "",
    "This creates a symlink so that when the system reaches the `multi-user` target during boot, systemd automatically starts `cloudlab.service`.",
    "",
    "---",
    "### 5. Result",
    "- Now the flow is:",
    "  1. Press the power button on my old server PC.",
    "  2. Ubuntu boots, PostgreSQL starts, then `cloudlab.service` starts.",
    "  3. From my main machine I can go straight to `http://SERVER_IP:8080/login` without logging into the server first.",
    "- When I want to update the backend, I rebuild the binary and restart the service:",
    "  - `go build -o cloudlab`",
    "  - `sudo systemctl restart cloudlab.service`",
    "",
    "It’s a small change, but it makes the whole project feel much closer to how real services are run on servers."
  ],
  "date": "2025-12-11"
},
 {
  "title": "File Browser Foundation: A Filesystem-Backed Browser for My Go Cloud",
  "content": [
    "In my previous Go + PostgreSQL cloud lab posts I ended up with a small authenticated mini-app: a /login page, bcrypt password hashes, in-memory sessions, and a protected /todos endpoint backed by Postgres.",
    "In this post I move away from purely database-backed data and start treating my Linux server like a tiny private cloud: I pick a storage folder on disk, expose it via a new GET /api/files endpoint in Go, and build a simple /cloud page that lists folders and files. It’s still read-only, but it’s a real filesystem browser running over HTTP.",
    "The hero screenshot at the top of the post shows what I’m aiming for here: a dark-themed /cloud page with a toolbar and a list of folders and files (code, photos, notes.txt, readme.txt) coming directly from my storage directory on the server."
  ],
  "images": [
    "go_pics/cloud_files_ui.png"
  ],
  "description": [
    "### Context: From `/todos` JSON to a Filesystem Browser",
    "Up to now my Go lab was mostly about the database side: a /todos endpoint, a users table in PostgreSQL, bcrypt password hashing, sessions, and a login + logout flow. All of that is nice, but it doesn’t yet feel like the file-based \"cloud drive\" I actually want to build.",
    "For this step I decided to ignore the database for a moment and treat a plain directory on my Ubuntu server as the root of a future cloud drive. The Go server should:",
    "- treat a fixed directory like `/home/fynn/cloud-storage` as a storage root,",
    "- expose a GET /api/files?path=/... endpoint that returns JSON,",
    "- protect it with the same session/cookie mechanism I already use for /todos,",
    "- and render a small /cloud page that consumes this JSON and shows a list of entries.",
    {
      "type": "image",
      "src": "go_pics/cloud_files_ui.png",
      "alt": "Browser screenshot of the /cloud page showing the dark themed toolbar and file list loaded from the Go backend"
    },
    "The screenshot above (`go_pics/cloud_files_ui.png`) shows the result: the browser is on /cloud, the toolbar is at the top, and the list below is populated from the Go backend calling into the filesystem.",

    "---",
    "### 1. Storage Root and the `FileEntry` Type",
    "First I picked a folder on the server that should act as the root of my little cloud. On my Ubuntu box that is:",
    "- `/home/fynn/cloud-storage`",
    "I created it once on the server and then referenced it in Go as a constant right next to my global `db` and `sessions` variables.",
    "At the same time I introduced a simple struct that describes a single directory entry for the frontend: `FileEntry`. It has four fields: name, path, type (file or dir) and size in bytes.",
    "The screenshot below shows the relevant part of `main.go` in my editor: the `FileEntry` struct with JSON tags and the `storageRoot` constant underneath it.",

    {
      "type": "image",
      "src": "go_pics/cloud_fileentry_storage_root.png",
      "alt": "Editor screenshot showing the FileEntry struct with Name, Path, Type and Size fields plus JSON tags, and the storageRoot constant set to /home/fynn/cloud-storage underneath the global db and sessions variables"
    },

    "The JSON tags on `FileEntry` ensure that the JSON response has lower-case field names (`name`, `path`, `type`, `size`), which is more idiomatic for APIs. The `Path` field is always relative to the storage root, starting with a single leading slash, for example `/photos/cat.png`.",

    "---",
    "### 2. Implementing `GET /api/files` in Go",
    "With the struct and storage root in place, the next step is the core backend endpoint: GET /api/files. The idea is simple:",
    "- the client passes a `path` query parameter that is always relative to the storage root,",
    "- the handler resolves that path under `storageRoot`,",
    "- it reads the directory entries using `os.ReadDir`,",
    "- and it returns a JSON array of `FileEntry` objects.",
    "Because the same server already hosts a login feature, I reuse the session logic from there: /api/files is only reachable if the request carries a valid `session_id` cookie that exists in the in-memory `sessions` map.",
    "The first half of `apiFilesHandler` deals with authentication, HTTP method checking and path sanitizing. The screenshot below shows this upper half of the handler in my editor:",

    {
      "type": "image",
      "src": "go_pics/cloud_apifileshandler_top.png",
      "alt": "Editor screenshot showing the upper half of apiFilesHandler: it reads the session_id cookie, checks the sessions map, rejects non-GET methods, reads the path query parameter, normalizes it with filepath.Clean and blocks any paths that contain .. segments before joining it with storageRoot"
    },
    {
      "type": "image",
      "src": "go_pics/cloud_apifileshandler_bottom.png",
      "alt": "Editor screenshot showing the lower half of apiFilesHandler: it calls os.ReadDir on the computed fullPath, iterates over entries, calls entry.Info(), decides between type file or dir, builds the relative path, appends FileEntry values to a slice and finally encodes the slice as JSON with the application/json Content-Type set"
    },

    "The handler starts by reading the `session_id` cookie from the request and checking the ID in the `sessions` map. If there is no cookie or the ID is unknown, it simply redirects back to /login. That way, the filesystem API is only usable after a successful login.",
    "Then it enforces that only GET is allowed, because this endpoint is purely for reading. Any other HTTP method gets a 405 Method Not Allowed.",
    "The next interesting bit is the path handling. The handler reads the `path` query parameter from the URL (for example `/`, `/photos`, `/code/snippets`) and normalizes it with `filepath.Clean`. Internally, an empty path or `/` is mapped to `.` to represent the storage root. To avoid path traversal attacks, the code explicitly rejects any path that equals `..`, starts with `../` or contains `/../` anywhere.",
    "Only after this cleaning step does the handler join `storageRoot` and the cleaned relative path using `filepath.Join`, giving it a safe absolute path on disk.",
    "Once the absolute path is known, the lower half of the handler calls `os.ReadDir` to list directory contents. For each entry it calls `entry.Info()` to obtain metadata, checks `entry.IsDir()` to decide the `type` field (`file` or `dir`), calculates the relative path under the storage root, and appends a `FileEntry` value to a slice. At the end the handler sets `Content-Type: application/json` and uses `json.NewEncoder(w).Encode(files)` to stream the slice to the client as JSON.",

    "---",
    "### 3. Cloud Page Handler and Static Files",
    "To turn the filesystem API into something nice to look at, I added a new route `/cloud`. This route does not return JSON; it simply serves an HTML file that lives under `static/cloud.html` and contains a minimal frontend.",
    "In `main()` I already had a file server for everything under `./static` and routes for `/login`, `/todos` and `/logout`. I added another handler registration:",
    "- `/api/files` → `apiFilesHandler` (the JSON API),",
    "- `/cloud` → `cloudPageHandler` (the HTML UI).",
    "The `cloudPageHandler` itself is intentionally small: it only allows GET, checks the `session_id` cookie using the same `sessions` map logic as other handlers, and then calls `http.ServeFile` to return `static/cloud.html`.",
    "The screenshot below shows the full `cloudPageHandler` function in my editor:",

    {
      "type": "image",
      "src": "go_pics/cloud_page_handler.png",
      "alt": "Editor screenshot of cloudPageHandler showing the GET method check, the session_id cookie lookup and sessions map validation, and the final http.ServeFile call that serves static/cloud.html"
    },

    "By protecting `/cloud` with the same session logic as `/api/files`, I make sure that both the HTML UI and the JSON API are only usable for logged-in users. After fixing my login redirect to point to `/cloud` instead of `/todos`, a successful login drops me straight onto the new cloud view.",

    "---",
    "### 4. Inspecting `/api/files` Directly in the Browser",
    "Before wiring up any frontend JavaScript I like to test backend endpoints directly in the browser. Because `/api/files` returns JSON and is protected by the session cookie, it is perfect for that.",
    "After logging in, I can manually navigate to `/api/files?path=/` and see the JSON response for the root of my storage directory. It contains one object per file or folder, with the fields defined by `FileEntry`.",
    "The screenshot below shows this JSON response in the browser: it lists my `code` and `photos` folders plus `notes.txt` and `readme.txt` as files, each with a `name`, `path`, `type` and `size` field.",

    {
      "type": "image",
      "src": "go_pics/cloud_api_files_json.png",
      "alt": "Browser screenshot of the /api/files?path=/ endpoint showing a prettified JSON array with entries for code, notes.txt, photos and readme.txt including name, path, type and size fields"
    },

    "This direct view is especially helpful while debugging path handling and permissions: if something is wrong with my path cleaning or filesystem permissions, I immediately see an error instead of an empty UI.",

    "---",
    "### 5. A Simple `/cloud` UI on Top of the API",
    "With `/api/files` working and `/cloud` serving an HTML shell, I added a very small frontend on top:",
    "- `static/cloud.html` defines the basic layout: a dark header with the current path label (for now I keep the technical \"Path: /\" look), two buttons for future features (Upload File, Refresh), and an empty container for the file list.",
    "- `static/cloud.css` gives it a simple modern look: dark background, rounded bars for each row, subtle hover effects.",
    "- `static/cloud.js` contains a tiny amount of vanilla JavaScript that calls GET /api/files?path=/ when the page loads, parses the JSON and renders one row per `FileEntry`. Double-clicking on a directory row calls /api/files with the corresponding path to navigate deeper.",
    "Because this series is primarily about Go and backend concepts, I’m not showing the full HTML/CSS/JS code here. The important part is that the /cloud UI is just a thin layer on top of the Go endpoint: all file information comes from `/api/files`, and all access control logic still lives on the server.",
    "The screenshot above is exactly this UI in action: each row in the list corresponds to a `FileEntry` produced by the Go handler, and the text `Path: /` is driven by the current path that the JavaScript passes into the endpoint.",

    "---",
    "### 6. Limitations and Next Steps",
    "Right now, my little cloud is purely a filesystem viewer:",
    "- `/api.files` only supports GET and only lists entries,",
    "- there is no way to upload, download, rename or delete anything yet,",
    "- and there is no thumbnail generation for images or any kind of preview mode.",
    "That’s intentional: I wanted a solid, well-understood foundation first. I now have:",
    "- a dedicated storage root on disk,",
    "- a simple `FileEntry` model,",
    "- a secure, session-protected JSON API for listing directories,",
    "- and a `/cloud` page that consumes this API and shows real files from my server.",
    "From here the path is clear. In future posts I plan to build on this file browser foundation and add:",
    "- a POST /api/upload endpoint plus download links,",
    "- a grid layout with thumbnails and a simple image preview overlay,",
    "- endpoints and UI actions for mkdir, rename and move,",
    "- and eventually a trash system and multi-select to make my Go cloud feel more like a real, personal drive."
  ],
  "date": "2025-12-12"
},
  {
  "title": "File Uploads & Downloads in My Go-Powered Cloud",
  "content": [
    "In the last post I built a read-only file browser for my Go + PostgreSQL cloud lab: a session-protected `/cloud` page and a `GET /api/files` endpoint that lists real files and folders from my `cloud-storage` directory on the server.",
    "In this post I finally turn that browser into a real cloud by adding file transfers: a `GET /api/download` endpoint for downloading files and a `POST /api/upload` endpoint for uploading new files into whatever folder I’m currently viewing in the UI. Both routes reuse the same session + path-safety logic from the previous post."
  ],
  "images": [],
  "description": [
    "### Context: From Read-Only Listing to Real File Transfers",
    "My first step toward a \"cloud drive\" was just listing files: the `/cloud` page called `GET /api/files?path=/...` and rendered whatever `FileEntry` structs the Go backend returned. That already felt nice, because I could navigate through a filesystem via HTTP and a simple UI.",
    "But a cloud that can only *see* files isn’t very useful. I now wanted two basic actions:",
    "- **Download** a file from the server to my browser.",
    "- **Upload** one or more local files into the directory I’m currently viewing.",
    "Everything should still be protected by my login system (session cookie + in-memory `sessions` map), and all paths should stay safely inside my `storageRoot` directory.",
    "",
    "---",
    "### 1. Downloading Files: `GET /api/download`",
    "The first new route is a download endpoint. The idea is simple:",
    "- the client calls `GET /api/download?path=/photos/cat.png`,",
    "- the server checks the session, cleans the path and verifies that it is a real file inside `storageRoot`,",
    "- and then streams the file with `http.ServeFile`.",
    "The screenshot below shows the complete `downloadHandler` in my `main.go`. At the top it performs the usual session check and enforces that only `GET` is allowed. Then it reads the `path` query parameter, normalizes it with `filepath.Clean`, strips any leading slash to get a relative path, blocks any `..` segments to prevent path traversal, joins it with `storageRoot`, and finally uses `os.Stat` to ensure the target exists and is not a directory. If everything looks good, it calls `http.ServeFile(w, r, fullPath)` to send the file back to the browser.",
    {
      "type": "image",
      "src": "go_pics/cloud_downloadhandler.png",
      "alt": "Editor screenshot of the full downloadHandler in Go, showing the session check, HTTP method check, path cleaning with filepath.Clean, path traversal protection, os.Stat call to verify the file, and final http.ServeFile call"
    },
    "A few important details:",
    "- I reuse the **session check** from other handlers: if the `session_id` cookie is missing or the ID is not in the `sessions` map, the handler redirects to `/login`.",
    "- I enforce `GET` with `if r.Method != http.MethodGet` so the endpoint is clearly read-only.",
    "- I treat the `path` parameter as a **logical cloud path** (like `/photos/cat.png`), then turn it into a relative path under `storageRoot` by cleaning it and trimming the leading slash.",
    "- I explicitly reject paths that equal `..`, start with `../` or contain `/../` anywhere, to avoid ever leaving the cloud directory.",
    "- I use `os.Stat` to decide between user errors and server errors: `os.IsNotExist(err)` becomes a 404 Not Found, other errors become a 500 Internal Server Error.",
    "",
    "One subtle but interesting point: I simply call `http.ServeFile` without setting a `Content-Disposition: attachment` header. That means the browser decides what to do with the file based on the `Content-Type`. For images and text files it usually opens a viewer in the tab; for unknown or binary types it tends to offer a download. For now that’s perfectly fine for my little lab.",
    "",
    "---",
    "### 2. Designing the Upload API: `POST /api/upload`",
    "For uploads I wanted something that fits well with a browser and is easy to reason about:",
    "- The request should be `multipart/form-data` (the standard for file uploads from HTML/JS).",
    "- There should be a **text field** called `path` that tells the server in which cloud folder to put the files.",
    "- There should be one or more **file fields** called `file` that contain the actual files.",
    "The high-level flow in the upload handler looks like this:",
    "1. Check session and enforce `POST` only.",
    "2. Parse the multipart form (`r.ParseMultipartForm`).",
    "3. Read the `path` form field, clean it and validate it (no `..`, no escaping `storageRoot`).",
    "4. Compute the target directory and ensure it exists (`os.MkdirAll`).",
    "5. Loop over all uploaded files, sanitize their names, skip existing files, and save the rest to disk.",
    "6. Respond with HTTP 204 No Content if everything went fine.",
    "The first half of the handler is responsible for authentication, parsing and path handling:",
    {
      "type": "image",
      "src": "go_pics/cloud_uploadhandler_top.png",
      "alt": "Editor screenshot of the upper half of uploadHandler: session and method checks, ParseMultipartForm call with a 32 MB memory limit, nil check for r.MultipartForm, reading the path form field, normalizing it with filepath.Clean, mapping / and . to the cloud root, blocking any .. segments, and joining the result with storageRoot to form uploadDir, plus MkdirAll to ensure the directory exists"
    },
    {
      "type": "image",
      "src": "go_pics/cloud_uploadhandler_bottom.png",
      "alt": "Editor screenshot of the lower half of uploadHandler: retrieving r.MultipartForm.File[\"file\"], looping over each FileHeader, using filepath.Base to sanitize the filename, opening the uploaded file as src, checking with os.Stat if the destination file already exists and skipping it if so, creating the destination file with os.Create, copying data with io.Copy, closing both files, and finally writing a 204 No Content status"
    },
    "Some key ideas in this handler:",
    "- **Session + method check**: just like `/api/files` and `/api/download`, `/api/upload` starts by checking the `session_id` cookie and restricting the method to `POST`. No anonymous uploads allowed.",
    "- **Multipart parsing**: `r.ParseMultipartForm(32 << 20)` tells Go to parse the `multipart/form-data` body and use up to 32 MiB of RAM for form data, spilling larger parts to temporary disk files. Afterwards, `r.FormValue(\"path\")` gives me the target folder and `r.MultipartForm.File[\"file\"]` gives me the list of uploaded files.",
    "- **Path normalization**: I treat an empty `path` or `/` as the cloud root (`\".\"` internally) and then run everything through `filepath.Clean`. If the cleaned path is just `/` I map it back to `\".\"`, and I reject anything with `..` segments. Finally, `filepath.Join(storageRoot, rel)` gives me a safe, absolute filesystem path that always stays under `storageRoot`.",
    "- **Ensuring the directory exists**: `os.MkdirAll(uploadDir, 0755)` is a safety net. If the target directory or any of its parents are missing, it creates them. If everything already exists, it does nothing. This makes the upload path more robust and plays nicely with future features like \"new folder\".",
    "",
    "---",
    "### 3. Saving Uploaded Files Safely",
    "The second half of `uploadHandler` actually moves bytes from the HTTP request into real files on disk. For each `*multipart.FileHeader` in `files := r.MultipartForm.File[\"file\"]` I do:",
    "- Get a clean filename with `filepath.Base(fh.Filename)` so I ignore any path components a browser or client might include. Only the final name like `cat.png` or `notes.txt` is allowed.",
    "- Skip weird or empty names such as `\"\"`, `\".\"` or `\"..\"`.",
    "- Call `fh.Open()` to get a `src` reader for the uploaded file contents.",
    "- Build a destination path `dstPath := filepath.Join(uploadDir, filename)`.",
    "- Use `os.Stat(dstPath)` to check if a file already exists there. If it does, I log a message and skip that upload instead of overwriting it.",
    "- Create the destination file with `os.Create(dstPath)` and get a writer `dst`.",
    "- Stream data from `src` to `dst` using `io.Copy(dst, src)`.",
    "- Close both `dst` and `src` when done.",
    "At the very end of the handler I send a `204 No Content` response:",
    "- No JSON body, no HTML, just a status that says: \"Upload succeeded.\"",
    "- On the frontend side I simply check `res.ok` and then call `loadFiles(currentPath)` to refresh the file list in the UI.",
    "",
    "---",
    "### 4. Wiring the Frontend: Upload Button & Click-to-Open",
    "On the frontend I only had to make relatively small changes to my existing `/cloud` page:",
    "- The HTML now contains a visible \"Upload File\" button and a hidden `<input type=\"file\" id=\"file-input\" multiple>` element.",
    "- When I click the button, JavaScript triggers `fileInput.click()`, which opens the standard file chooser dialog.",
    "- In the `change` event of the file input, I create a `FormData` instance, append the current cloud path under the `path` key, append each selected file under the `file` key, and send it to `POST /api/upload` using `fetch`. On success I reload the current folder with `loadFiles(currentPath)`, so the freshly uploaded files appear immediately.",
    "- For downloads, I attach a click handler to each file row that sets `window.location.href = \"/api/download?path=\" + encodeURIComponent(file.path)`.",
    "I still keep the frontend very small and focused: no progress bars, no drag & drop, no fancy previews yet. The point of this post is to understand how the Go handlers work and how the browser talks to them, not to build a perfect UI.",
    "",
    "---",
    "### 5. Security and Safety Considerations",
    "Even though this runs on an old home server and is only meant for my personal use, I tried to keep the upload and download paths reasonably safe:",
    "- All routes involved (`/api/files`, `/api/download`, `/api/upload`, `/cloud`) are protected by the same session cookie check that I use for `/todos`.",
    "- Every path the client sends is treated as a **relative cloud path**, cleaned with `filepath.Clean`, stripped of any leading slash and validated against `..` segments before it is joined with `storageRoot`.",
    "- Uploads cannot escape the cloud directory and cannot overwrite existing files (I explicitly skip any file where `os.Stat` finds an existing entry at that path).",
    "- The `MkdirAll` call only ever creates directories under `storageRoot`, never outside of it.",
    "This is not production-grade security yet (there is still no HTTPS, no per-user isolation for files and no rate limiting), but it’s already a good exercise in thinking about what can go wrong when you let users send you paths and files over HTTP.",
    "",
    "---",
    "### 6. Where I Want to Go Next",
    "With upload and download in place, my Go cloud finally feels like a tiny but real drive:",
    "- I can browse folders under `/home/fynn/cloud-storage` from `/cloud`.",
    "- I can upload new text files and images into any folder I have open in the UI.",
    "- I can click a file to open or download it through `/api/download`.",
    "The next steps are all about making this *nice* to use:",
    "- a grid layout for files and folders, more like Google Drive’s card view,",
    "- a preview overlay for images on double click,",
    "- a context menu per file/dir with options like Download, Rename, Move and Trash,",
    "- backend endpoints for mkdir, rename, move and trash,",
    "- and eventually a trash system plus multi-select.",
    "But for now I’m happy: my little Go server has evolved from a toy `/todos` JSON API into a session-protected, filesystem-backed cloud where files can actually move in and out."
  ],
  "date": "2025-12-14"
},
  {
  "title": "Adding \"New Folder\" to My Go Cloud File Browser",
  "content": [
    "In my Go cloud project I already have the basics in place: a login system with bcrypt and sessions, a protected /cloud page that talks to a filesystem-backed storage root, and upload/download endpoints wired into the UI.",
    "In this post I add one essential feature: creating folders directly from the browser. I introduce a small JSON payload for create-folder requests, a POST /api/mkdir endpoint in Go that validates paths and folder names, and a simple \"New Folder\" action in the /cloud toolbar.",
    "The hero screenshot at the top shows the result: a blue \"+ New\" button in the top-right corner of the cloud UI. Clicking it opens a dropdown where the first option is \"New Folder\", which then creates a directory inside whatever path the UI is currently showing."
  ],
  "images": [
    "go_pics/cloud_new_folder_menu.png"
  ],
  "description": [
    "### 1. Context: From Read-Only Listing to Basic File Management",
    "Until now my Go cloud behaved more like a read-only viewer: the backend could list files from the storage directory, and I added upload and download so I could move data in and out. But as long as I could not create folders from the browser, I still had to SSH into the server if I wanted to organize things properly.",
    "The goal of this step is simple: make it possible to create new folders directly from the /cloud page, while still keeping the backend strict about paths so everything stays inside `/home/fynn/cloud-storage` and cannot escape that root.",

    "---",
    "### 2. New Folder in the UI",
    "On the frontend the new feature starts with the toolbar. I extended the existing \"+ New\" button so that it opens a dropdown menu with three entries:",
    "- New Folder",
    "- Upload File",
    "- Upload Folder (planned for later)",
    "The screenshot below shows the dropdown in action inside my cloud UI:",
    {
      "type": "image",
      "src": "go_pics/cloud_new_folder_menu.png",
      "alt": "Screenshot of the Go cloud UI showing a blue + New button with a dropdown menu containing New Folder, Upload File and Upload Folder"
    },
    "When I click \"New Folder\" the menu closes and the browser displays a prompt asking me for the folder name. This is deliberately very minimal for now: a simple text input where I type something like `testfolder` and confirm. The next screenshot shows that prompt:",
    {
      "type": "image",
      "src": "go_pics/cloud_new_folder_prompt.png",
      "alt": "Browser prompt dialog asking for Folder name with an example name testfolder written into the input field"
    },
    "If I cancel the prompt, nothing happens. If I confirm a non-empty name, the frontend sends a small JSON request to the Go server containing two fields: the current path in the UI and the folder name I just entered.",

    "---",
    "### 3. Request Model: `mkdirRequest`",
    "On the Go side I added a tiny struct called `mkdirRequest` that describes exactly what the frontend sends in that JSON body. It has two string fields:",
    "- `Path`: the current folder shown in the UI, for example `/`, `/photos` or `/code/snippets`,",
    "- `Name`: the desired name for the new folder, such as `wallpapers`.",
    "The struct has JSON tags so that the server expects the keys `path` and `name` in the request body. When the handler receives a POST /api/mkdir, it uses a JSON decoder to read the request body directly into a `mkdirRequest` value.",
    "If the JSON is malformed or missing required fields, the decoder returns an error and the handler responds with a `400 Bad Request` status to signal that the client sent invalid data.",

    "---",
    "### 4. The `/api/mkdir` Handler: Path and Name Validation",
    "The core logic for creating folders lives in a new handler function `apiMkdirHandler`. It follows the same security patterns as my other API endpoints:",
    "- It only accepts the HTTP POST method.",
    "- It reads the `session_id` cookie and checks the in-memory sessions map; if there is no valid session, it returns `401 Unauthorized`.",
    "- It decodes the JSON body into a `mkdirRequest` instance.",
    "- It normalizes and validates the requested parent path before touching the filesystem.",
    "The first screenshot of the handler shows exactly these steps: session checks, JSON decoding, cleaning the path with `filepath.Clean`, mapping an empty path or `/` to the storage root, and rejecting any path that tries to use `..` segments to escape the cloud root:",
    {
      "type": "image",
      "src": "go_pics/cloud_mkdir_handler_top.png",
      "alt": "Editor screenshot showing the upper part of apiMkdirHandler with POST method enforcement, session_id cookie checks, decoding of the JSON body into mkdirRequest, and normalization and validation of the requested path including rejecting .. segments"
    },
    "Once the path is safe, the handler validates the folder name. It trims surrounding whitespace and then rejects names that are empty, equal to `.` or `..`, or that contain slashes or backslashes. This prevents strange or dangerous folder names and keeps the structure clean.",
    "Next the handler computes the absolute parent directory by joining the cleaned path with `storageRoot` and uses `os.Stat` to make sure that this parent directory actually exists and is a directory, not a file. If the parent does not exist, the handler responds with `400 Bad Request`.",
    "The second screenshot shows the rest of the logic: building the full target directory path, checking whether something with that name already exists, logging unexpected errors during `os.Stat`, and finally calling `os.Mkdir` to create the directory with standard 0755 permissions. On success it sends back a `204 No Content` response without any body:",
    {
      "type": "image",
      "src": "go_pics/cloud_mkdir_handler_bottom.png",
      "alt": "Editor screenshot showing the lower part of apiMkdirHandler where the parent directory is checked with os.Stat, the target folder path is built, existing folders cause a conflict error, and os.Mkdir is called to create the directory followed by a 204 No Content response"
    },
    "The HTTP status codes are chosen to be meaningful:",
    "- 400 for invalid JSON, invalid paths or invalid names,",
    "- 401 if there is no valid session,",
    "- 409 if a folder with that name already exists,",
    "- 500 if an unexpected filesystem error occurs,",
    "- 204 if the folder was successfully created.",

    "---",
    "### 5. Registering the Route in `main()`",
    "To make the new handler reachable, I registered another route in `main()` alongside my existing file endpoints. All filesystem actions now live under the `/api` prefix:",
    "- `/api/files` for listing directory contents,",
    "- `/api/download` for sending files to the browser,",
    "- `/api/upload` for receiving files from a form upload,",
    "- `/api/mkdir` for creating new folders.",
    "This keeps the whole file API nicely grouped and reuses the same session and path-handling strategy everywhere.",

    "---",
    "### 6. Frontend: Calling `/api/mkdir` and Refreshing the View",
    "In `cloud.js` the menu item for \"New Folder\" is wired up to an asynchronous click handler. When the user selects it:",
    "- the dropdown menu is hidden,",
    "- a prompt asks for the folder name,",
    "- if there is a name, the script sends a POST request to `/api/mkdir` with a JSON body containing the current `path` from the UI and the `name` from the prompt.",
    "When the response comes back:",
    "- if the server returns `401 Unauthorized`, the script redirects the browser to `/login`,",
    "- if the status code is not OK for any other reason, an alert shows a simple error message,",
    "- and if everything is fine (status 204), the script calls the same `loadFiles(currentPath)` function that is used elsewhere to refresh the current directory view.",
    "The result is a smooth interaction: I click \"+ New → New Folder\", type a name, and a moment later a new folder card appears in the grid inside the current path.",

    "---",
    "### 7. Result and Next Steps",
    "With the \"New Folder\" feature implemented, my Go cloud has taken another step towards feeling like a real personal drive:",
    "- I can create folders directly from the browser,",
    "- the Go backend enforces that all operations stay inside the configured storage root,",
    "- and the feature reuses the existing session and JSON infrastructure rather than inventing something special just for folders.",
    "The frontend is still intentionally simple, using a basic prompt dialog and a minimal dropdown menu, but the underlying backend is robust and ready for more advanced UI on top. In the next steps I plan to add more file operations such as renaming and moving items, and later on a trash system and multi-select so I can manage larger photo collections and code snippets more comfortably inside this self-hosted Go cloud."
  ],
  "date": "2025-12-15"
},
  {
  "title": "Renaming Files and Folders in My Go Cloud with /api/rename",
  "content": [
    "My Go cloud now has a protected file browser, upload and download endpoints, and a simple \"New Folder\" action. The next natural step is to be able to rename files and folders directly from the browser.",
    "In this post I add a POST /api/rename endpoint on the backend and wire it to a small rename prompt in the UI. The Go handler validates paths and names, stays inside the storage root, and uses os.Rename under the hood to move the entry to its new name.",
    "The hero screenshot shows the result: after right-clicking on a file card in the cloud view, a prompt pops up with the current name prefilled so I can quickly rename it."
  ],
  "images": [],
  "description": [
    {
      "type": "image",
      "src": "go_pics/cloud_rename_prompt.png",
      "alt": "Browser prompt dialog showing the current file name bamboo_forest.JPG selected for renaming inside the Go cloud UI"
    },
    "### 1. Context: Making the File Browser Feel Real",
    "So far my self-hosted Go cloud can:",
    "- list files and folders from a fixed storage root,",
    "- upload new files into the current folder,",
    "- download files through a dedicated endpoint,",
    "- and create new folders via a POST /api/mkdir handler.",
    "But it still felt pretty basic: if I wanted to correct a typo in a filename or tidy up some image names, I had to drop back to the shell on the server. To make the browser experience feel more like a real drive, I needed a proper rename operation.",
    "The screenshot at the top of this post shows the new flow: I right-click on a file card inside the cloud UI, the browser opens a small prompt window with the current name highlighted, and I type the new name. Once I confirm, the frontend calls the new /api/rename endpoint in the Go backend.",
    "",
    "---",
    "### 2. Request Model: `renameRequest`",
    "On the backend I represent a rename operation with a tiny struct named `renameRequest`. It has two fields:",
    "- `OldPath`: the current path of the entry within the cloud, for example `/photos/bamboo_forest.JPG`,",
    "- `NewName`: the new name only, such as `bamboo_forest_01.JPG`.",
    "The important design choice here is that `NewName` is just a name, not a full path. The parent directory stays the same; only the last segment changes. That keeps the API simple and makes it harder for the client to accidentally move entries out of their current folder when it only wants to rename.",
    "On the wire the frontend sends JSON with the keys `old_path` and `new_name`, which the handler decodes directly into the struct.",
    "",
    "---",
    "### 3. Session Check, Method Guard and JSON Decode",
    "The core logic lives in a new handler function `apiRenameHandler`. It follows exactly the same patterns as my other JSON endpoints:",
    "- it only accepts POST requests,",
    "- it checks the `session_id` cookie and looks the ID up in the in-memory sessions map,",
    "- and it decodes the JSON request body into a `renameRequest` value using Go’s JSON decoder.",
    "If the HTTP method is wrong, the handler returns `405 Method Not Allowed`. If the cookie is missing or does not map to a stored session, it returns `401 Unauthorized`. If the JSON body cannot be parsed, the handler returns `400 Bad Request`.",
    "The first screenshot of the handler shows exactly this upper part: method check, session validation, JSON decoding, and the initial trimming and validation of `old_path` including a check that the client actually sent something:",
    {
      "type": "image",
      "src": "go_pics/cloud_rename_handler_top.png",
      "alt": "Editor screenshot of the upper part of apiRenameHandler with POST method enforcement, session_id cookie checks, JSON decoding into renameRequest, and validation and cleaning of the old_path field"
    },
    "",
    "---",
    "### 4. Cleaning and Validating the Old Path",
    "Once the handler has a non-empty `old_path`, it normalizes it with the same building blocks used elsewhere in the project:",
    "- `filepath.Clean` to collapse redundant segments,",
    "- a guard against renaming the storage root itself (paths like `.` or `/`),",
    "- a normalization step that ensures the path starts with a single `/`,",
    "- and `strings.TrimPrefix` to get a relative path without the leading slash.",
    "After that, the handler runs a familiar security check against path traversal:",
    "- it rejects a relative path that equals `..`,",
    "- or starts with `../`,",
    "- or contains `/../` anywhere in the middle.",
    "Only if the cleaned relative path passes these checks does the handler join it with the `storageRoot` constant to build the absolute source path on disk. It then calls `os.Stat` on that path to verify that the source exists. If the file or folder is not found, the handler returns `404 Not Found`; if there is another error when accessing the path, it logs the error and returns `500 Internal Server Error`.",
    "This full sequence — clean, normalize, reject `..` tricks, then check existence — is the same recipe I use for all file operations in this project.",
    "",
    "---",
    "### 5. Validating the New Name and Computing the Target Path",
    "Next the handler turns to `new_name`. It trims whitespace and enforces a couple of simple but important rules:",
    "- the name must not be empty,",
    "- it must not be `.` or `..`,",
    "- it must not contain `/` or `\\`.",
    "These rules prevent the client from sneaking additional path segments into the name or from trying to pick special directory markers. If any of these conditions fail, the handler returns `400 Bad Request`.",
    "To build the target path, the handler first figures out the parent directory of the old relative path by calling `filepath.Dir` and interpreting the result. If there is no real parent segment, the parent is treated as the root of the cloud, represented internally as `.`. That parent directory is then joined with `storageRoot`, and `os.Stat` is used again to confirm that this directory exists and is actually a directory.",
    "The second screenshot shows this middle portion of the handler in the editor: the trimming and validation of `new_name`, the calculation of the parent directory, the check that the parent exists and is a directory, and the construction of the new relative path that combines the parent with the chosen name:",
    {
      "type": "image",
      "src": "go_pics/cloud_rename_handler_mid.png",
      "alt": "Editor screenshot of the middle part of apiRenameHandler showing validation of new_name, computation of the parent directory from the old relative path, and checking that the parent directory exists and is a directory before building the new relative path"
    },
    "After that, the handler builds the full destination path on disk by joining the relative target path with `storageRoot`. A final `os.Stat` call checks whether something already exists at that location. If there is already a file or folder with the chosen name, the handler responds with `409 Conflict` to signal that the rename cannot proceed without overwriting.",
    "",
    "---",
    "### 6. Performing the Rename with `os.Rename`",
    "If all validations pass — valid session, valid JSON body, safe old path, existing source, valid new name, existing parent directory, and non-existing target — the actual work is almost anticlimactic: the handler calls Go’s `os.Rename` function with the source and destination paths.",
    "If `os.Rename` fails for some reason (for example due to permission issues or a transient filesystem error), the handler logs the error and returns `500 Internal Server Error`. Otherwise it responds with `204 No Content`, indicating that the rename succeeded and that there is no response body to parse.",
    "The final screenshot shows this last part of the handler: the existence check for the target path, the call to `os.Rename`, error logging, and the `204` status being written to the response:",
    {
      "type": "image",
      "src": "go_pics/cloud_rename_handler_bottom.png",
      "alt": "Editor screenshot of the lower part of apiRenameHandler where the target path is checked for conflicts, os.Rename is called to perform the rename, and a 204 No Content status is written on success"
    },
    "",
    "---",
    "### 7. Wiring It into the Frontend",
    "On the frontend side I kept the interaction deliberately simple for now. Each file or folder card in the grid listens to a contextmenu event (right-click). When that event fires, the JavaScript:",
    "- prevents the default browser context menu,",
    "- opens a prompt dialog with the current name prefilled,",
    "- if the user enters a non-empty, changed name, sends a POST request to `/api/rename` with a JSON body containing `old_path` and `new_name`.",
    "If the server replies with `401 Unauthorized`, the script redirects back to `/login`. If the status code indicates an error (for example `400` or `409`), a small alert shows a generic error message. On success the script calls the same `loadFiles(currentPath)` function that the rest of the UI uses, so the list refreshes and the renamed entry appears immediately with its new name.",
    "This is intentionally a minimal first version: the browser prompt is not fancy, but it gets the job done and keeps the focus on the backend design. Later I can replace the prompt with a custom dialog or integrate renaming into a richer context menu.",
    "",
    "---",
    "### 8. Result and What Comes Next",
    "With /api/rename in place my Go cloud now supports three core write operations from the browser:",
    "- uploading files,",
    "- creating folders,",
    "- and renaming files and folders in place.",
    "All of these operations share the same underlying rules:",
    "- every path is treated as relative to a fixed storage root on the server,",
    "- every incoming path is normalized and checked for `..` segments,",
    "- and every handler enforces sessions via the same `session_id` cookie.",
    "The next logical step is to extend this model to moving entries between folders and, later on, to implement a trash system that moves items into a special area instead of deleting them outright. Thanks to the groundwork laid in the rename handler, those features will be mostly about combining the same validation and security checks with slightly different target paths."
  ],
  "date": "2025-12-17"
},
  {
  "title": "Moving Files Between Folders in My Go Cloud (`POST /api/move`)",
  "content": [
    "My Go cloud can now move files and folders between directories, similar to how Google Drive lets you reorganize your content.",
    "In this post I add a `POST /api/move` endpoint to the backend and wire it up to a new “Move” action in the card context menu in the UI."
  ],
  "images": [],
  "description": [
    "### 1. UX: Move from the Card Context Menu",
    "I already had a per-item context menu on each card (opened by the three-dot button in the bottom-right corner). To add moving, I simply inserted a new menu item called **Move** between **Download** and **Move to Trash (coming soon)**.",
    {
      "type": "image",
      "src": "go_pics/cloud_move_menu.png",
      "alt": "Cloud UI screenshot showing the context menu for an image card with the options Rename, Download, Move and Move to Trash (coming soon)"
    },
    "Clicking **Move** now opens a small browser prompt that asks for a destination folder. The prompt accepts simple, root-relative paths like `/`, `/photos` or `/code`. Under the hood the frontend sends these two pieces of information to the backend:",
    "- `source_path`: the current path of the selected file or folder, for example `/palmtrees.jpg` or `/code/snippets`,",
    "- `target_dir`: the folder where it should be moved to, for example `/photos`.",
    {
      "type": "image",
      "src": "go_pics/cloud_move_prompt.png",
      "alt": "Browser prompt asking for the target folder path with /photos filled in as an example"
    },
    "After confirming, the request goes to the new `POST /api/move` endpoint. If everything works, the UI refreshes the current directory and the moved item disappears from the old location. When I navigate into the destination folder, the file is there:",
    {
      "type": "image",
      "src": "go_pics/cloud_move_result.png",
      "alt": "Cloud UI screenshot of the /photos folder, now containing several image cards including palmtrees.jpg"
    },

    "---",
    "### 2. Request Shape: `moveRequest`",
    "On the Go side I introduced a small struct to describe the JSON body of the move request:",
    "- it has a `SourcePath` field for the original location,",
    "- and a `TargetDir` field for the destination folder.",
    "The frontend sends a JSON object with `source_path` and `target_dir` keys, and Go’s JSON decoder maps those into the struct fields. The first thing the handler does is:",
    "- enforce `POST` only,",
    "- check the `session_id` cookie and the in-memory `sessions` map (same as other API endpoints),",
    "- decode the JSON body into this `moveRequest` value.",
    "If decoding fails, the handler responds with **400 Bad Request** and a short error message.",

    "---",
    "### 3. Validating the Source Path",
    "Next, the handler validates the source path. It trims whitespace, rejects an empty value and normalizes the path using `filepath.Clean`. This keeps things predictable and removes redundant `.` segments.",
    "Because all paths in my cloud API are defined as **relative to the storage root but start with a leading slash**, the handler makes sure there is exactly one leading `/` before continuing. Root itself (`/` or `.`) is not allowed as a source, so the code explicitly rejects attempts to move the storage root.",
    "Then there is the usual security check against path traversal:",
    "- any `..` segments, or patterns like `../` or `/../`, cause the handler to return **400 Invalid source path**.",
    "Only after these checks does the handler join the relative path with `storageRoot` and call `os.Stat` on that absolute path to ensure that the source actually exists. If the file or folder is missing, the server returns **404 Source not found**.",
    {
      "type": "image",
      "src": "go_pics/cloud_move_handler_top.png",
      "alt": "Editor screenshot showing the upper part of apiMoveHandler: it checks the HTTP method and session, decodes the JSON body into moveRequest, validates and normalizes source_path, rejects .. segments and ensures the source exists with os.Stat"
    },

    "---",
    "### 4. Validating the Target Directory",
    "The target directory gets a similar treatment. The handler:",
    "- trims the `target_dir` string,",
    "- treats an empty value or `/` as the storage root,",
    "- passes it through `filepath.Clean`,",
    "- converts `/` back to `.` as the internal representation for the root folder,",
    "- and, if it is not `.` already, makes sure it starts with a single leading slash.",
    "Again, any `..` segments are rejected to prevent escaping from the configured storage root.",
    {
      "type": "image",
      "src": "go_pics/cloud_move_handler_middle.png",
      "alt": "Editor screenshot showing the middle part of apiMoveHandler: it normalizes target_dir, ensures it is either . or starts with a slash, rejects .. segments and computes the absolute target directory path"
    },
    "Once the relative target directory is considered safe, the handler builds its absolute path under `storageRoot` and calls `os.Stat` on it. Two more conditions must hold:",
    "- the target must exist; otherwise the handler returns **400 Target directory does not exist**,",
    "- the target must be a directory; if not, the handler returns **400 Target is not a directory**.",
    "Only if all of this passes is the move actually attempted.",

    "---",
    "### 5. Avoiding Overwrites and Performing the Move",
    "Before moving anything, the handler constructs the final destination path by combining:",
    "- the target directory path, and",
    "- the base name of the source entry (taken from the source’s `FileInfo.Name()`).",
    "That way the name of the file or folder stays the same; only its parent directory changes.",
    "To avoid silent overwrites, the handler calls `os.Stat` on the computed destination path:",
    "- if something already exists there, it returns **409 Destination already exists**,",
    "- if `os.Stat` fails with any other error, it returns a generic **500 Error checking destination**.",
    "Finally, the actual move is just a call to `os.Rename(srcFull, destFull)`. On success the handler writes **204 No Content** and the frontend refreshes the current directory.",
    {
      "type": "image",
      "src": "go_pics/cloud_move_handler_bottom.png",
      "alt": "Editor screenshot showing the lower part of apiMoveHandler: it checks the target directory, builds the destination path from baseName, ensures it does not exist yet and finally calls os.Rename before returning 204 No Content"
    },

    "---",
    "### 6. Limitations and Future Improvements",
    "The current move implementation already feels very usable: I can right-click or use the three-dot menu on any card, choose **Move**, type a target folder and watch the file jump to its new home.",
    "At the same time there are a few obvious limitations:",
    "- The path input is a raw text prompt; a dedicated move dialog with a clickable folder tree would be much nicer.",
    "- Moves are single-item only. Multi-select and bulk moves will come later.",
    "- There is still no trash system: a failed move is never destructive, but real deletions will need more care.",
    "Still, `POST /api/move` is a big step: my Go cloud is no longer just a static viewer. I can reorganize files and folders purely through my own backend and filesystem logic, without touching the server via SSH or a file manager."
  ],
  "date": "2025-12-18"
},
  {
  "title": "Soft delete for my Go cloud: a filesystem-based Trash folder",
  "content": [
    "My Go cloud lab now has basic file operations like New Folder, Upload, Download and Rename. The next step toward a real drive experience is a Trash feature instead of hard-deleting files.",
    "In this post I add a filesystem-based Trash folder under my storage root. Every file or folder that I delete is moved into /trash, similar to how Google Drive or most desktop file managers work.",
    "On the UI side I add a Move to Trash entry to the card context menu. If a name already exists in the Trash, the server automatically renames the new entry (foo (1).jpg, foo (2).jpg, …) instead of failing."
  ],
  "images": [
    "go_pics/cloud_trash_menu.png"
  ],
  "description": [
    "### 1. UX: Move to Trash in the context menu",
    "On the UI side this feature appears as an additional item in the card context menu. When I click the three dots on a file or folder, the menu now shows Download, Rename, Move and Move to Trash.",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_menu.png",
      "alt": "Cloud UI screenshot showing the card context menu with Download, Rename, Move and Move to Trash entries"
    },
    "When I choose Move to Trash, the browser sends a small JSON body to the Go server containing just one field:",
    "- path: the path of the selected entry (for example /leaf.jpg or /code/snippets).",
    "If the request succeeds, the item disappears from the current folder. I can still get it back later by browsing the Trash.",

    "---",
    "### 2. Representing the Trash in the filesystem",
    "I decided not to model Trash in PostgreSQL. Instead, the Trash is just another directory under my storage root:",
    "- storage root: `/home/fynn/cloud-storage`",
    "- Trash folder: `/home/fynn/cloud-storage/trash`",
    "The important part: the Trash directory is hidden from the normal root listing so it does not clutter the dashboard. You only see it if you explicitly browse `/trash`.",
    "The screenshot below shows my Trash view at `/trash`: one image and two folders that have been moved from other locations.",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_view.png",
      "alt": "Cloud UI screenshot showing the /trash path with one image and two folders inside the Trash directory"
    },

    "---",
    "### 3. Backend: POST `/api/trash`",
    "The core of this feature is a new HTTP handler: `apiTrashHandler`, mounted at `POST /api/trash`.",
    "The handler performs several steps:",
    "- method check – only POST is allowed, and the request must carry a valid session_id cookie (same mechanism as all other authenticated endpoints),",
    "- cache headers – it sets Cache-Control: no-store, no-cache, must-revalidate so browsers do not cache responses,",
    "- JSON decode – it decodes a JSON body like `{ \"path\": \"/something\" }` into a small `trashRequest` struct,",
    "- sanitize the path – trims spaces, normalizes it with filepath.Clean, enforces a leading slash, and then converts it to a safe relative path under the storage root,",
    "- rejects root or invalid paths – refuses `..` segments and forbids trashing the storage root itself.",
    "The upper half of the handler, with the method check, cookie lookup, JSON decoding and path validation, looks like this in my editor:",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_handler_top.png",
      "alt": "Editor screenshot of the upper part of apiTrashHandler showing the POST check, session validation, JSON body decoding and path validation"
    },
    "Once the path is validated, the handler calls `os.Stat` on the full source path. If the file or folder does not exist, it returns 404. Otherwise it remembers the `os.FileInfo` so it can later read the original base name.",
    "Then it prepares the Trash root (`storageRoot + \"/trash\"`) and calls `os.MkdirAll` with mode 0755 so the Trash directory is created on demand if it does not exist yet. Any error here becomes a 500.",
    "The lower half of the handler shows this logic plus the move step:",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_handler_bottom.png",
      "alt": "Editor screenshot of the lower part of apiTrashHandler showing stat on the source path, creation of the trash directory, the call to uniqueTrashPath and the final os.Rename"
    },

    "---",
    "### 4. Avoiding name collisions with `uniqueTrashPath`",
    "A real Trash folder needs to handle collisions gracefully: if I delete `leaf.jpg` twice, the second delete should not fail just because `leaf.jpg` is already in the Trash.",
    "To solve that, I wrote a helper called `uniqueTrashPath(trashRoot, baseName string) (string, error)`. It takes the Trash directory and the original file or folder name and returns a unique path inside `/trash`.",
    "The helper works in two steps:",
    "1. It splits the base name into name and extension using `filepath.Ext` and `strings.TrimSuffix`. For example:",
    "   - baseName = `leaf.jpg` → nameOnly = `leaf`, ext = `.jpg`",
    "2. It first checks if `/trash/leaf.jpg` exists. If not, it returns that path immediately.",
    "3. If it does exist, it loops i = 1..9999 and synthesizes alternative names like `leaf (1).jpg`, `leaf (2).jpg`, … using `fmt.Sprintf(\"%s (%d)%s\", nameOnly, i, ext)`. For each candidate it checks with `os.Stat` whether the file exists. The first free name is returned.",
    "The screenshot below shows the full helper function in my editor:",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_unique_name.png",
      "alt": "Editor screenshot of the uniqueTrashPath helper that uses filepath.Ext, TrimSuffix, a for loop and os.Stat to find a free name like leaf (1).jpg in the trash directory"
    },

    "---",
    "### 5. Putting it all together",
    "The control flow of `apiTrashHandler` looks like this:",
    "1. Decode JSON `{ \"path\": \"...\" }` into `trashRequest`.",
    "2. Clean and validate the path, reject root and any `..` tricks.",
    "3. `os.Stat` the source; fail with 404 if it does not exist.",
    "4. Ensure the `/trash` directory exists with `os.MkdirAll`.",
    "5. Call `uniqueTrashPath` to compute a free destination path inside `/trash`.",
    "6. Call `os.Rename(srcFull, dstFull)` to move the file or folder in one step.",
    "7. Reply with HTTP 204 No Content on success.",
    "From the user’s perspective this feels like a soft delete:",
    "- The card disappears from the current folder as soon as Move to Trash completes.",
    "- Navigating to `/trash` via the path bar shows all trashed items. Folders inside the Trash can still be opened and navigated like normal folders.",
    "- If I delete the same name twice, the Trash automatically creates numbered duplicates instead of failing.",
    "Right now there is no dedicated Trash UI (like buttons for restore or delete permanently) and no expiry timers. But even this simple version already feels much safer than hard deletes and brings my Go cloud closer to the behavior of mature file managers like Google Drive or Finder.",
    "In future iterations I plan to:",
    "- add a context menu in `/trash` for Restore and Delete permanently,",
    "- expose Trash in the planned sidebar explorer under the storage root,",
    "- and maybe add automatic cleanup rules for very old entries."
  ],
  "date": "2025-12-19"
},
  {
  "title": "Completing the Trash in My Go Cloud: Restore, Delete Forever, and Empty Trash",
  "content": [
    "My Go cloud already supported soft delete by moving files into a filesystem-based /trash directory. The next step was making that Trash usable: restoring items, deleting them permanently, and emptying the entire Trash.",
    "In this post I add three new backend endpoints (/api/trash/restore, /api/trash/delete, /api/trash/empty) and wire them into the UI so the same /cloud page can act as both the normal drive view and the Trash view.",
    "Trash stays “hidden” and is reachable only via URL (/cloud?path=/trash), while the UI automatically switches to Trash-specific actions when you’re inside that path."
  ],
  "images": [],
  "description": [
    {
      "type": "image",
      "src": "go_pics/cloud_trash_empty_button.png",
      "alt": "Browser screenshot of the Go cloud UI on the /trash path showing a red 'Empty Trash' button next to '+ New' and 'Logout', and one image card inside the trash"
    },
    "### 1. Context: Soft delete is nice, but Trash needs actions",
    "In the previous step I implemented a simple Trash system by moving items into a `/trash` folder under my storage root. That already made delete much safer than calling `os.RemoveAll` directly on user content.",
    "But a Trash that only collects items is not enough — I needed the same three operations that every real drive has:",
    "- **Restore** a trashed item back into a normal folder,",
    "- **Delete forever** (permanently remove one entry),",
    "- **Empty Trash** (wipe everything in one click).",
    "I also wanted Trash to stay *hidden* in the normal UI: there is no Trash button in the dashboard yet. For now it’s reachable only via URL: `/cloud?path=/trash`.",
    "",
    "---",
    "### 2. UX: Same /cloud page, but Trash-only context menu",
    "To keep the frontend simple, I reuse the same `cloud.html` and `cloud.js` for both normal browsing and Trash browsing. The only trick is: if `currentPath` is `/trash` (or starts with it), the UI switches modes.",
    "In Trash mode the card context menu only shows **Restore** and **Delete forever**. Everything else (Download, Rename, Move, Move to Trash) is hidden so there is no confusion.",
    "Restore uses a deliberately minimal prompt: I type the destination folder as a cloud path like `/` or `/photos`.",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_restore_prompt.png",
      "alt": "Screenshot of the /trash view with the context menu open showing Restore and Delete forever, plus a browser prompt asking for the restore target folder with /photos filled in"
    },
    "",
    "---",
    "### 3. Backend: `POST /api/trash/restore`",
    "The restore endpoint takes two fields in a JSON body:",
    "- `path`: the trash entry path (must be inside `/trash/...`)",
    "- `target_dir`: the destination folder (like `/`, `/photos`, `/code/snippets`)",
    "Just like the rest of my cloud API it enforces:",
    "- **POST only**",
    "- a valid `session_id` cookie",
    "- strict path cleaning with `filepath.Clean`",
    "- rejection of `..` traversal patterns",
    "Here is the top part of my `apiTrashRestoreHandler`, showing the method/session checks, JSON decoding into `trashRestoreRequest`, and the validation that the source path is really in Trash:",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_restore_handler_top.png",
      "alt": "Editor screenshot of apiTrashRestoreHandler showing POST enforcement, session validation, JSON decode into trashRestoreRequest, and checks that the provided path is inside trash/"
    },
    "The middle part of the handler focuses on the destination folder: it normalizes `/` to the root, cleans the string, rejects traversal, and maps it to an absolute directory under `storageRoot`:",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_restore_handler_middle.png",
      "alt": "Editor screenshot of apiTrashRestoreHandler showing target_dir cleaning and validation, rejection of traversal patterns, and building the absolute destination directory path under the storage root"
    },
    "",
    "### 4. Avoiding overwrites on restore with `uniqueNameInDir`",
    "Restore has the same collision problem as moving to Trash: if the destination folder already contains a file called `leaf.jpg`, I don’t want to overwrite it silently.",
    "To solve that, restore uses a helper that finds a free name inside the destination directory (e.g. `leaf (1).jpg`, `leaf (2).jpg`, …). This is the helper function as it exists in my codebase:",
    {
      "type": "image",
      "src": "go_pics/cloud_unique_name_in_dir.png",
      "alt": "Editor screenshot of the uniqueNameInDir helper function which tries the original base name first and then loops to find a free name like 'name (1).ext' using os.Stat"
    },
    "After validating source + target and computing a collision-free destination path, the handler performs the restore with `os.Rename(srcFull, dstFull)` and returns `204 No Content`.",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_restore_handler_bottom.png",
      "alt": "Editor screenshot of the lower part of apiTrashRestoreHandler showing os.Stat checks for the target directory, calling uniqueNameInDir, then os.Rename to move the entry out of trash, followed by a 204 response"
    },
    "",
    "---",
    "### 5. Backend: `POST /api/trash/delete` (Delete forever)",
    "For permanent deletion I added a dedicated endpoint that only accepts entries inside the Trash. The request shape is the same as moving to Trash: a JSON body with `{ \"path\": \"/trash/...\" }`.",
    "The handler again enforces POST + session + path safety and rejects anything not under `/trash/`.",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_delete_handler_top.png",
      "alt": "Editor screenshot of apiTrashDeleteHandler showing POST enforcement, session validation, decoding trashRequest, cleaning the path, and rejecting requests that are not inside the trash"
    },
    "Once the entry is verified to exist, deletion is performed using `os.RemoveAll(full)`, which works for both files and directories. On success it returns `204 No Content`.",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_delete_handler_bottom.png",
      "alt": "Editor screenshot of apiTrashDeleteHandler showing os.Stat handling and os.RemoveAll(full) to permanently delete the trash entry, followed by a 204 response"
    },
    "",
    "---",
    "### 6. Backend: `POST /api/trash/empty` (Empty Trash)",
    "Empty Trash is basically a batch delete: it ensures the trash directory exists, reads all entries under `/trash`, and removes each entry recursively.",
    "In my handler the core loop iterates over `os.ReadDir(trashRoot)` and calls `os.RemoveAll` on every name in that directory.",
    {
      "type": "image",
      "src": "go_pics/cloud_trash_empty_handler.png",
      "alt": "Editor screenshot of apiTrashEmptyHandler showing POST enforcement, session validation, creating/accessing the trash directory, reading entries with os.ReadDir, and deleting each entry with os.RemoveAll before returning 204"
    },
    "",
    "---",
    "### 7. Frontend: showing 'Empty Trash' only in Trash mode",
    "Finally, I wired this into the UI without adding a permanent Trash button to the dashboard:",
    "- The Trash view is still accessed via `/cloud?path=/trash`.",
    "- The red **Empty Trash** button is present in the HTML but hidden by default.",
    "- When the UI detects `currentPath` is `/trash` (or starts with it), it reveals the button and binds it to `POST /api/trash/empty`.",
    "Together with the Trash-only context menu, this makes the `/trash` page feel like a dedicated mode while still reusing the same page and renderer logic as the rest of the cloud."
  ],
  "date": "2025-12-20"
},
  {
  "title": "Folder Upload with Preserved Subfolders (relpath) in My Go Cloud",
  "content": [
    "After building the Trash feature set, the next missing piece in my Go cloud was a proper **folder upload** — not just uploading the files, but keeping the complete directory structure (top-level folder + all nested subfolders).",
    "The UI already had an “Upload Folder” entry under “+ New”, so this step was mainly about wiring it up correctly and making sure the backend can reliably recreate the folder tree."
  ],
  "images": [],
  "description": [
    "### 1. Upload Folder in the “+ New” menu",
    "The entry was already there — now it’s connected to the hidden `<input webkitdirectory>` so selecting a folder triggers a real upload instead of a placeholder.",
    {
      "type": "image",
      "src": "go_pics/upload_folder_menu.png",
      "alt": "UI screenshot of the + New dropdown showing New Folder, Upload File, and Upload Folder"
    },
    "",
    "---",
    "### 2. Result in the dashboard: the new top-level folder appears",
    "After selecting a folder from my PC, the cloud shows the uploaded directory as a normal folder at the current path. In my test upload, the top-level folder is called `layer1`.",
    {
      "type": "image",
      "src": "go_pics/upload_folder_result_root.png",
      "alt": "Cloud root view showing folders like code, layer1, and photos"
    },
    "",
    "---",
    "### 3. Inside `layer1`: files + the next subfolder",
    "Opening `layer1` shows that the upload wasn’t flattened — the folder content is preserved, including subfolders.",
    {
      "type": "image",
      "src": "go_pics/upload_folder_result_layer1.png",
      "alt": "Cloud view inside /layer1 showing an uploaded image file and a subfolder named layer2"
    },
    "",
    "---",
    "### 4. Inside `layer2`: deeper nesting still intact",
    "Going one level deeper (`/layer1/layer2`) confirms that nested folders are also recreated correctly (here: `layer3`), alongside files stored in that same directory.",
    {
      "type": "image",
      "src": "go_pics/upload_folder_result_layer2.png",
      "alt": "Cloud view inside /layer1/layer2 showing a folder named layer3 and an image file named plants.jpg"
    },
    "",
    "---",
    "### 5. The backend change: `relpath` is the reliable key",
    "My first attempt tried to encode the relative path in the multipart filename (so Go could read it from `fh.Filename`). In practice that can be unreliable, and it caused uploads to lose the folder structure in some cases.",
    "The fix is simple: send the relative path as its own field (`relpath`) next to each file. The backend then processes both arrays in order (`files[i]` belongs to `relpaths[i]`), cleans/validates the path, creates the needed subdirectories with `os.MkdirAll`, and saves the file into the correct location.",
    {
      "type": "image",
      "src": "go_pics/upload_folder_relpaths_handler.png",
      "alt": "Code screenshot from uploadHandler showing preserve_paths switch, reading relpaths from r.MultipartForm.Value[\"relpath\"], cleaning/validating relName, creating subdirectories with os.MkdirAll, and building dstPath"
    }
  ],
  "date": "2025-12-21"
}







]
